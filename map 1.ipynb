{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to map project structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Structure:\n",
      "backend\\\n",
      "frontend\\\n",
      "jre\\\n",
      "utils\\\n",
      ".gitignore\n",
      ".gitlab-ci.yml\n",
      "coordinates.py\n",
      "docker-compose.yml\n",
      "ISSUES_UPLOAD_FILE.xlsx\n",
      "LICENCE.txt\n",
      "map.ipynb\n",
      "producer.ipynb\n",
      "README.md\n",
      "spark.ipynb\n",
      "test.ipynb\n",
      "wait-for-it.sh\n",
      "backend\\api\\\n",
      "backend\\config\\\n",
      "backend\\data\\\n",
      "backend\\models\\\n",
      "backend\\simulator-data\\\n",
      "backend\\tests\\\n",
      "backend\\app.py\n",
      "backend\\Dockerfile\n",
      "backend\\requirements.txt\n",
      "backend\\api\\get_historical_stats.py\n",
      "backend\\api\\get_live_stats.py\n",
      "backend\\api\\kafka_topics.py\n",
      "backend\\api\\register_device.py\n",
      "backend\\api\\send_stream.py\n",
      "backend\\config\\config.py\n",
      "backend\\data\\device_schemas\\\n",
      "backend\\data\\historical\\\n",
      "backend\\data\\device_schemas\\gps_1.json\n",
      "backend\\data\\device_schemas\\gps_10.json\n",
      "backend\\data\\device_schemas\\gps_11.json\n",
      "backend\\data\\device_schemas\\gps_2.json\n",
      "backend\\data\\device_schemas\\gps_3.json\n",
      "backend\\data\\device_schemas\\gps_4.json\n",
      "backend\\data\\device_schemas\\gps_5.json\n",
      "backend\\data\\device_schemas\\gps_6.json\n",
      "backend\\data\\device_schemas\\gps_7.json\n",
      "backend\\data\\device_schemas\\gps_8.json\n",
      "backend\\data\\device_schemas\\gps_9.json\n",
      "backend\\data\\device_schemas\\player_heart_rate_1.json\n",
      "backend\\data\\device_schemas\\player_heart_rate_10.json\n",
      "backend\\data\\device_schemas\\player_heart_rate_11.json\n",
      "backend\\data\\device_schemas\\player_heart_rate_2.json\n",
      "backend\\data\\device_schemas\\player_heart_rate_3.json\n",
      "backend\\data\\device_schemas\\player_heart_rate_4.json\n",
      "backend\\data\\device_schemas\\player_heart_rate_5.json\n",
      "backend\\data\\device_schemas\\player_heart_rate_6.json\n",
      "backend\\data\\device_schemas\\player_heart_rate_7.json\n",
      "backend\\data\\device_schemas\\player_heart_rate_8.json\n",
      "backend\\data\\device_schemas\\player_heart_rate_9.json\n",
      "backend\\data\\device_schemas\\player_temperature_1.json\n",
      "backend\\data\\device_schemas\\player_temperature_10.json\n",
      "backend\\data\\device_schemas\\player_temperature_11.json\n",
      "backend\\data\\device_schemas\\player_temperature_2.json\n",
      "backend\\data\\device_schemas\\player_temperature_3.json\n",
      "backend\\data\\device_schemas\\player_temperature_4.json\n",
      "backend\\data\\device_schemas\\player_temperature_5.json\n",
      "backend\\data\\device_schemas\\player_temperature_6.json\n",
      "backend\\data\\device_schemas\\player_temperature_7.json\n",
      "backend\\data\\device_schemas\\player_temperature_8.json\n",
      "backend\\data\\device_schemas\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\\n",
      "backend\\data\\historical\\devices\\accel_1\\\n",
      "backend\\data\\historical\\devices\\accel_10\\\n",
      "backend\\data\\historical\\devices\\accel_2\\\n",
      "backend\\data\\historical\\devices\\accel_3\\\n",
      "backend\\data\\historical\\devices\\accel_4\\\n",
      "backend\\data\\historical\\devices\\accel_5\\\n",
      "backend\\data\\historical\\devices\\accel_6\\\n",
      "backend\\data\\historical\\devices\\accel_7\\\n",
      "backend\\data\\historical\\devices\\accel_8\\\n",
      "backend\\data\\historical\\devices\\accel_9\\\n",
      "backend\\data\\historical\\devices\\gps_1\\\n",
      "backend\\data\\historical\\devices\\gps_10\\\n",
      "backend\\data\\historical\\devices\\gps_2\\\n",
      "backend\\data\\historical\\devices\\gps_3\\\n",
      "backend\\data\\historical\\devices\\gps_4\\\n",
      "backend\\data\\historical\\devices\\gps_5\\\n",
      "backend\\data\\historical\\devices\\gps_6\\\n",
      "backend\\data\\historical\\devices\\gps_7\\\n",
      "backend\\data\\historical\\devices\\gps_8\\\n",
      "backend\\data\\historical\\devices\\gps_9\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\\n",
      "backend\\data\\historical\\devices\\speed_1\\\n",
      "backend\\data\\historical\\devices\\speed_2\\\n",
      "backend\\data\\historical\\devices\\injuries_summary.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_001\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_002\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_003\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_004\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_005\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_006\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_007\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_008\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_009\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_010\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_011\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_012\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_013\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_014\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_015\\\n",
      "backend\\data\\historical\\devices\\accel_1\\run_001\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_002\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_003\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_004\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_005\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_006\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_007\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_008\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_009\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_010\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_011\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_012\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_013\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_014\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_1\\run_015\\accel_1.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_001\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_002\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_003\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_004\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_005\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_006\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_007\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_008\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_009\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_010\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_011\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_012\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_013\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_014\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_015\\\n",
      "backend\\data\\historical\\devices\\accel_10\\run_001\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_002\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_003\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_004\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_005\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_006\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_007\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_008\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_009\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_010\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_011\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_012\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_013\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_014\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_10\\run_015\\accel_10.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_001\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_002\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_003\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_004\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_005\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_006\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_007\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_008\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_009\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_010\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_011\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_012\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_013\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_014\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_015\\\n",
      "backend\\data\\historical\\devices\\accel_2\\run_001\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_002\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_003\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_004\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_005\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_006\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_007\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_008\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_009\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_010\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_011\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_012\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_013\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_014\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_2\\run_015\\accel_2.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_001\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_002\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_003\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_004\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_005\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_006\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_007\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_008\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_009\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_010\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_011\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_012\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_013\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_014\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_015\\\n",
      "backend\\data\\historical\\devices\\accel_3\\run_001\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_002\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_003\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_004\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_005\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_006\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_007\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_008\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_009\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_010\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_011\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_012\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_013\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_014\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_3\\run_015\\accel_3.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_001\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_002\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_003\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_004\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_005\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_006\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_007\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_008\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_009\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_010\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_011\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_012\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_013\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_014\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_015\\\n",
      "backend\\data\\historical\\devices\\accel_4\\run_001\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_002\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_003\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_004\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_005\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_006\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_007\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_008\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_009\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_010\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_011\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_012\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_013\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_014\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_4\\run_015\\accel_4.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_001\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_002\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_003\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_004\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_005\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_006\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_007\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_008\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_009\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_010\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_011\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_012\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_013\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_014\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_015\\\n",
      "backend\\data\\historical\\devices\\accel_5\\run_001\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_002\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_003\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_004\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_005\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_006\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_007\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_008\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_009\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_010\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_011\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_012\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_013\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_014\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_5\\run_015\\accel_5.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_001\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_002\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_003\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_004\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_005\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_006\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_007\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_008\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_009\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_010\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_011\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_012\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_013\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_014\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_015\\\n",
      "backend\\data\\historical\\devices\\accel_6\\run_001\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_002\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_003\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_004\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_005\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_006\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_007\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_008\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_009\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_010\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_011\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_012\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_013\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_014\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_6\\run_015\\accel_6.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_001\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_002\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_003\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_004\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_005\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_006\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_007\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_008\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_009\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_010\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_011\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_012\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_013\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_014\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_015\\\n",
      "backend\\data\\historical\\devices\\accel_7\\run_001\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_002\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_003\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_004\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_005\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_006\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_007\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_008\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_009\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_010\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_011\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_012\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_013\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_014\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_7\\run_015\\accel_7.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_001\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_002\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_003\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_004\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_005\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_006\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_007\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_008\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_009\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_010\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_011\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_012\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_013\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_014\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_015\\\n",
      "backend\\data\\historical\\devices\\accel_8\\run_001\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_002\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_003\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_004\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_005\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_006\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_007\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_008\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_009\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_010\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_011\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_012\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_013\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_014\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_8\\run_015\\accel_8.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_001\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_002\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_003\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_004\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_005\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_006\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_007\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_008\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_009\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_010\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_011\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_012\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_013\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_014\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_015\\\n",
      "backend\\data\\historical\\devices\\accel_9\\run_001\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_002\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_003\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_004\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_005\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_006\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_007\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_008\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_009\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_010\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_011\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_012\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_013\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_014\\accel_9.json\n",
      "backend\\data\\historical\\devices\\accel_9\\run_015\\accel_9.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_001\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_002\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_003\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_004\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_005\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_006\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_007\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_008\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_009\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_010\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_011\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_012\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_013\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_014\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_015\\\n",
      "backend\\data\\historical\\devices\\gps_1\\run_001\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_002\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_003\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_004\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_005\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_006\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_007\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_008\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_009\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_010\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_011\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_012\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_013\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_014\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_1\\run_015\\gps_1.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_001\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_002\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_003\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_004\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_005\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_006\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_007\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_008\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_009\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_010\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_011\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_012\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_013\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_014\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_015\\\n",
      "backend\\data\\historical\\devices\\gps_10\\run_001\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_002\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_003\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_004\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_005\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_006\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_007\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_008\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_009\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_010\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_011\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_012\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_013\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_014\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_10\\run_015\\gps_10.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_001\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_002\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_003\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_004\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_005\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_006\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_007\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_008\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_009\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_010\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_011\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_012\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_013\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_014\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_015\\\n",
      "backend\\data\\historical\\devices\\gps_2\\run_001\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_002\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_003\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_004\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_005\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_006\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_007\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_008\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_009\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_010\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_011\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_012\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_013\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_014\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_2\\run_015\\gps_2.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_001\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_002\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_003\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_004\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_005\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_006\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_007\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_008\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_009\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_010\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_011\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_012\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_013\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_014\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_015\\\n",
      "backend\\data\\historical\\devices\\gps_3\\run_001\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_002\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_003\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_004\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_005\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_006\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_007\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_008\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_009\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_010\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_011\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_012\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_013\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_014\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_3\\run_015\\gps_3.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_001\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_002\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_003\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_004\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_005\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_006\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_007\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_008\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_009\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_010\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_011\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_012\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_013\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_014\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_015\\\n",
      "backend\\data\\historical\\devices\\gps_4\\run_001\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_002\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_003\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_004\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_005\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_006\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_007\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_008\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_009\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_010\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_011\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_012\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_013\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_014\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_4\\run_015\\gps_4.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_001\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_002\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_003\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_004\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_005\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_006\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_007\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_008\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_009\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_010\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_011\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_012\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_013\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_014\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_015\\\n",
      "backend\\data\\historical\\devices\\gps_5\\run_001\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_002\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_003\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_004\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_005\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_006\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_007\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_008\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_009\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_010\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_011\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_012\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_013\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_014\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_5\\run_015\\gps_5.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_001\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_002\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_003\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_004\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_005\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_006\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_007\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_008\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_009\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_010\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_011\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_012\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_013\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_014\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_015\\\n",
      "backend\\data\\historical\\devices\\gps_6\\run_001\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_002\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_003\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_004\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_005\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_006\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_007\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_008\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_009\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_010\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_011\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_012\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_013\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_014\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_6\\run_015\\gps_6.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_001\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_002\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_003\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_004\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_005\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_006\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_007\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_008\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_009\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_010\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_011\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_012\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_013\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_014\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_015\\\n",
      "backend\\data\\historical\\devices\\gps_7\\run_001\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_002\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_003\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_004\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_005\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_006\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_007\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_008\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_009\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_010\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_011\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_012\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_013\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_014\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_7\\run_015\\gps_7.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_001\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_002\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_003\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_004\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_005\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_006\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_007\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_008\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_009\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_010\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_011\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_012\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_013\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_014\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_015\\\n",
      "backend\\data\\historical\\devices\\gps_8\\run_001\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_002\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_003\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_004\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_005\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_006\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_007\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_008\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_009\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_010\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_011\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_012\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_013\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_014\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_8\\run_015\\gps_8.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_001\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_002\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_003\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_004\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_005\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_006\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_007\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_008\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_009\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_010\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_011\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_012\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_013\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_014\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_015\\\n",
      "backend\\data\\historical\\devices\\gps_9\\run_001\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_002\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_003\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_004\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_005\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_006\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_007\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_008\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_009\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_010\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_011\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_012\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_013\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_014\\gps_9.json\n",
      "backend\\data\\historical\\devices\\gps_9\\run_015\\gps_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_001\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_002\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_003\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_004\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_005\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_006\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_007\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_008\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_009\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_010\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_011\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_012\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_013\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_014\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_1\\run_015\\player_heart_rate_1.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_001\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_002\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_003\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_004\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_005\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_006\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_007\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_008\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_009\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_010\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_011\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_012\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_013\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_014\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_10\\run_015\\player_heart_rate_10.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_001\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_002\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_003\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_004\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_005\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_006\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_007\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_008\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_009\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_010\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_011\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_012\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_013\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_014\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_2\\run_015\\player_heart_rate_2.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_001\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_002\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_003\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_004\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_005\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_006\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_007\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_008\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_009\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_010\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_011\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_012\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_013\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_014\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_3\\run_015\\player_heart_rate_3.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_001\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_002\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_003\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_004\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_005\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_006\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_007\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_008\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_009\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_010\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_011\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_012\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_013\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_014\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_4\\run_015\\player_heart_rate_4.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_001\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_002\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_003\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_004\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_005\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_006\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_007\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_008\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_009\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_010\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_011\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_012\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_013\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_014\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_5\\run_015\\player_heart_rate_5.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_001\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_002\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_003\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_004\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_005\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_006\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_007\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_008\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_009\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_010\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_011\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_012\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_013\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_014\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_6\\run_015\\player_heart_rate_6.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_001\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_002\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_003\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_004\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_005\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_006\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_007\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_008\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_009\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_010\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_011\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_012\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_013\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_014\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_7\\run_015\\player_heart_rate_7.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_001\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_002\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_003\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_004\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_005\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_006\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_007\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_008\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_009\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_010\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_011\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_012\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_013\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_014\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_8\\run_015\\player_heart_rate_8.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_001\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_002\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_003\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_004\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_005\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_006\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_007\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_008\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_009\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_010\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_011\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_012\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_013\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_014\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_heart_rate_9\\run_015\\player_heart_rate_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_001\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_002\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_003\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_004\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_005\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_006\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_007\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_008\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_009\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_010\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_011\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_012\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_013\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_014\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_1\\run_015\\player_temperature_1.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_001\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_002\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_003\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_004\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_005\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_006\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_007\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_008\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_009\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_010\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_011\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_012\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_013\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_014\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_10\\run_015\\player_temperature_10.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_001\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_002\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_003\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_004\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_005\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_006\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_007\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_008\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_009\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_010\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_011\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_012\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_013\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_014\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_2\\run_015\\player_temperature_2.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_001\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_002\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_003\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_004\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_005\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_006\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_007\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_008\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_009\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_010\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_011\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_012\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_013\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_014\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_3\\run_015\\player_temperature_3.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_001\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_002\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_003\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_004\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_005\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_006\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_007\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_008\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_009\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_010\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_011\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_012\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_013\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_014\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_4\\run_015\\player_temperature_4.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_001\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_002\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_003\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_004\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_005\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_006\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_007\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_008\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_009\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_010\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_011\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_012\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_013\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_014\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_5\\run_015\\player_temperature_5.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_001\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_002\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_003\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_004\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_005\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_006\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_007\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_008\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_009\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_010\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_011\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_012\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_013\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_014\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_6\\run_015\\player_temperature_6.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_001\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_002\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_003\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_004\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_005\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_006\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_007\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_008\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_009\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_010\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_011\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_012\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_013\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_014\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_7\\run_015\\player_temperature_7.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_001\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_002\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_003\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_004\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_005\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_006\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_007\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_008\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_009\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_010\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_011\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_012\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_013\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_014\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_8\\run_015\\player_temperature_8.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_001\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_002\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_003\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_004\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_005\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_006\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_007\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_008\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_009\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_010\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_011\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_012\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_013\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_014\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_015\\\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_001\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_002\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_003\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_004\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_005\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_006\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_007\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_008\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_009\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_010\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_011\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_012\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_013\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_014\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\player_temperature_9\\run_015\\player_temperature_9.json\n",
      "backend\\data\\historical\\devices\\speed_1\\run_001\\\n",
      "backend\\data\\historical\\devices\\speed_1\\run_002\\\n",
      "backend\\data\\historical\\devices\\speed_1\\run_003\\\n",
      "backend\\data\\historical\\devices\\speed_1\\run_001\\speed_1.json\n",
      "backend\\data\\historical\\devices\\speed_1\\run_002\\speed_1.json\n",
      "backend\\data\\historical\\devices\\speed_1\\run_003\\speed_1.json\n",
      "backend\\data\\historical\\devices\\speed_2\\run_001\\\n",
      "backend\\data\\historical\\devices\\speed_2\\run_002\\\n",
      "backend\\data\\historical\\devices\\speed_2\\run_003\\\n",
      "backend\\data\\historical\\devices\\speed_2\\run_001\\speed_2.json\n",
      "backend\\data\\historical\\devices\\speed_2\\run_002\\speed_2.json\n",
      "backend\\data\\historical\\devices\\speed_2\\run_003\\speed_2.json\n",
      "backend\\models\\schemas.py\n",
      "backend\\simulator-data\\MockData-2.csv\n",
      "backend\\simulator-data\\wearables-mock-data.csv\n",
      "backend\\tests\\streaming\\\n",
      "backend\\tests\\streaming\\stream.py\n",
      "frontend\\src\\\n",
      "frontend\\src\\App.js\n",
      "frontend\\src\\index.js\n",
      "utils\\file_management.py\n",
      "utils\\kafka_producer.py\n",
      "utils\\maths_functions.py\n",
      "utils\\spark_processor.py\n",
      "utils\\__init__.py\n",
      "\n",
      "File Details:\n",
      "File_Name: app.py\n",
      "File_Path: backend\\app.py\n",
      "Code_contents:\n",
      "from fastapi import FastAPI\n",
      "from backend.api.register_device import router as register_device_router\n",
      "from backend.api.send_stream import router as send_stream_router\n",
      "from backend.api.get_live_stats import router as get_live_stats_router\n",
      "from backend.api.get_historical_stats import router as get_historical_stats_router\n",
      "from backend.api.kafka_topics import router as kafka_topics_router\n",
      "from backend.tests.streaming.stream import router as test_streaming_router\n",
      "\n",
      "app = FastAPI()\n",
      "\n",
      "# Include all routers\n",
      "app.include_router(register_device_router)\n",
      "app.include_router(send_stream_router)\n",
      "app.include_router(get_live_stats_router)\n",
      "app.include_router(get_historical_stats_router)\n",
      "app.include_router(kafka_topics_router)\n",
      "app.include_router(test_streaming_router)\n",
      "\n",
      "\n",
      "@app.get(\"/\")\n",
      "def read_root():\n",
      "    return {\"message\": \"Sports Streaming API is running.\"}\n",
      "\n",
      "----------------\n",
      "\n",
      "File_Name: Dockerfile\n",
      "File_Path: backend\\Dockerfile\n",
      "Code_contents:\n",
      "# Base Image\n",
      "FROM python:3.9-slim\n",
      "\n",
      "# Set working directory\n",
      "WORKDIR /app\n",
      "\n",
      "# Copy requirements first for better layer caching\n",
      "COPY backend/requirements.txt .\n",
      "\n",
      "# Install Python dependencies\n",
      "RUN pip install --no-cache-dir -r requirements.txt\n",
      "\n",
      "# Install OS-level dependencies\n",
      "RUN apt-get update && apt-get install -y procps default-jdk && \\\n",
      "    apt-get clean && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "# Dynamically set JAVA_HOME after installation\n",
      "ENV JAVA_HOME=\"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
      "ENV PATH=\"$JAVA_HOME/bin:$PATH\"\n",
      "\n",
      "# Copy the rest of the application files\n",
      "COPY . .\n",
      "\n",
      "# Expose the FastAPI port\n",
      "EXPOSE 8000\n",
      "\n",
      "# Set the default command\n",
      "CMD [\"uvicorn\", \"backend.app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
      "\n",
      "----------------\n",
      "\n",
      "File_Name: requirements.txt\n",
      "File_Path: backend\\requirements.txt\n",
      "Code_contents:\n",
      "# Backend Dependencies\n",
      "fastapi\n",
      "pydantic\n",
      "uvicorn\n",
      "python-dotenv\n",
      "pyspark\n",
      "pytest\n",
      "jsonschema\n",
      "websockets\n",
      "timedelta\n",
      "requests\n",
      "sse_starlette\n",
      "starlette\n",
      "pandas\n",
      "aiokafka\n",
      "confluent_kafka\n",
      "pydantic\n",
      "kafka-python==2.0.2\n",
      "----------------\n",
      "\n",
      "File_Name: get_historical_stats.py\n",
      "File_Path: backend\\api\\get_historical_stats.py\n",
      "Code_contents:\n",
      "import json\n",
      "import os\n",
      "import datetime\n",
      "import math\n",
      "from datetime import datetime\n",
      "from fastapi import APIRouter, HTTPException\n",
      "\n",
      "from backend.config.config import HISTORICAL_DATA_PATH\n",
      "from utils.maths_functions import haversine_distance\n",
      "\n",
      "router = APIRouter()\n",
      "\n",
      "# Endpoint 1: Team Statistics (Line Chart)\n",
      "@router.get(\"/team-statistics\")\n",
      "def get_team_statistics():\n",
      "    \"\"\"\n",
      "    Endpoint to fetch team statistics (Line Chart Data).\n",
      "    \"\"\"\n",
      "    try:\n",
      "        metrics = calculate_metrics()\n",
      "        return {\n",
      "            \"Total Distance Per Game\": metrics[\"Team Metrics\"][\"Total Distance Per Game\"],\n",
      "            \"Average Speed Per Game\": metrics[\"Team Metrics\"][\"Average Team Speed\"],\n",
      "            \"Max Speed Per Game\": metrics[\"Team Metrics\"][\"Max Team Speed\"],\n",
      "        }\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=str(e))\n",
      "\n",
      "\n",
      "# Endpoint 2: Wins/Losses/Draws\n",
      "@router.get(\"/game-statistics\")\n",
      "def get_game_statistics():\n",
      "    \"\"\"\n",
      "    Endpoint to fetch wins, losses, and draws.\n",
      "    \"\"\"\n",
      "    # dummy data for wins losses and draws can be adjusted\n",
      "    game_statistics = {\n",
      "        \"Wins\": 12,\n",
      "        \"Losses\": 5,\n",
      "        \"Draws\": 3,\n",
      "    }\n",
      "    return game_statistics\n",
      "\n",
      "\n",
      "# Endpoint 3: Total Distance/Game and Recovery\n",
      "@router.get(\"/team-metrics\")\n",
      "def get_team_metrics():\n",
      "    \"\"\"\n",
      "    Endpoint to fetch total distance per game and recovery metrics.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        metrics = calculate_metrics()\n",
      "        return {\n",
      "            \"Total Distance Per Game\": metrics[\"Team Metrics\"][\"Average Distance Per Game\"],\n",
      "            \"Average Team Recovery Rate\": metrics[\"Team Metrics\"][\"Average Team Recovery Rate\"],\n",
      "        }\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=str(e))\n",
      "\n",
      "\n",
      "# Endpoint 4: Player Overview Table\n",
      "@router.get(\"/player-overview/{player_id}\")\n",
      "def get_player_overview(player_id: int):\n",
      "    \"\"\"\n",
      "    Endpoint to fetch player-specific metrics for the overview table.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        metrics = calculate_metrics()\n",
      "        player_metrics = metrics[\"Player Metrics\"].get(player_id, None)\n",
      "        if not player_metrics:\n",
      "            raise HTTPException(status_code=404, detail=\"Player data not found.\")\n",
      "        return player_metrics\n",
      "    except Exception as e:\n",
      "\n",
      "        raise HTTPException(status_code=500, detail=str(e))\n",
      "\n",
      "\n",
      "# Endpoint 5: Fatigue Level Distribution\n",
      "@router.get(\"/fatigue-distribution\")\n",
      "def get_fatigue_distribution():\n",
      "    \"\"\"\n",
      "    Endpoint to fetch fatigue level distribution across players.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        metrics = calculate_metrics()\n",
      "        fatigue_levels = metrics[\"Recommendations\"][\"Player Recommendations\"]\n",
      "        distribution = {\n",
      "            \"Low Fatigue\": sum(1 for recs in fatigue_levels.values() if \"Low\" in recs),\n",
      "            \"Medium Fatigue\": sum(1 for recs in fatigue_levels.values() if \"Medium\" in recs),\n",
      "            \"High Fatigue\": sum(1 for recs in fatigue_levels.values() if \"High\" in recs),\n",
      "        }\n",
      "        return distribution\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=str(e))\n",
      "\n",
      "\n",
      "# Endpoint 6: All Players Recommendations\n",
      "@router.get(\"/recommendations\")\n",
      "def get_recommendations():\n",
      "    \"\"\"\n",
      "    Endpoint to fetch recommendations for all players and the team.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        metrics = calculate_metrics()\n",
      "        return metrics[\"Recommendations\"]\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=str(e))\n",
      "\n",
      "\n",
      "def calculate_metrics():\n",
      "    \"\"\"\n",
      "\n",
      "    It calculates all required metrics and then adds recommendations for players\n",
      "    \n",
      "    returns:\n",
      "        Dictionary: A dictionary containing all calculated metrics and recommendations\n",
      "\n",
      "    \"\"\"\n",
      "    # Team-related metrics\n",
      "    team_distance = c_team_distance()  # Total and average distance per game\n",
      "    average_team_speed, max_team_speed = team_speeds()  # Speed metrics\n",
      "    player_heart_rate_recovery, average_team_recovery_rate = heart_rate_recovery()  # Recovery metrics\n",
      "    fatigue_levels = calculate_fatigue_levels()  # Fatigue levels for players and team\n",
      "    injury_data = injuries()  # Injury data (total and per player)\n",
      "\n",
      "    # Player-specific metrics\n",
      "    player_metrics = {}  # Store individual player metrics\n",
      "    for player_id, recovery_data in player_heart_rate_recovery.items():\n",
      "        # Combine recovery data with other metrics\n",
      "        player_metrics[player_id] = {\n",
      "            \"Heart Rate Recovery Rate\": recovery_data.get(\"Recovery Rate (BPM/Sec)\", None),\n",
      "            \"Fatigue Level\": fatigue_levels[\"Fatigue Levels Per Player\"][player_id][\"Fatigue Level\"],\n",
      "            \"Injuries\": injury_data[\"Injuries Per Player\"][player_id][\"Total Injuries\"],\n",
      "        }\n",
      "\n",
      "    # Recommendations\n",
      "    player_recommendations = {}\n",
      "    team_recommendations = []\n",
      "\n",
      "    for player_id, metrics in player_metrics.items():\n",
      "        recommendations = []\n",
      "\n",
      "        # Fatigue level recommendations\n",
      "        if metrics[\"Fatigue Level\"] == \"High\":\n",
      "            recommendations.append(\"It's Recommended to rest or lighter training to reduce fatigue.\")\n",
      "        elif metrics[\"Fatigue Level\"] == \"Medium\":\n",
      "            recommendations.append(\"Please Monitor workload and adjust training intensity if needed.\")\n",
      "\n",
      "\n",
      "\n",
      "        # Heart rate recovery recommendations\n",
      "        if metrics.get(\"Heart Rate Recovery Rate\") and metrics[\"Heart Rate Recovery Rate\"] > 0.5:\n",
      "            recommendations.append(\"Improve cardiovascular fitness with aerobic training.\")\n",
      "\n",
      "\n",
      "        # Injuries recommendations\n",
      "        if metrics.get(\"Injuries\", 0) > 3:\n",
      "            recommendations.append(\"High injury count - please consider medical check-up or reduced workload.\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        # Distance trend recommendations\n",
      "        if metrics.get(\"Average Distance Trend\") == \"Decreasing\":\n",
      "            recommendations.append(\"Endurance training recommended to improve distance trends.\")\n",
      "\n",
      "        player_recommendations[player_id] = recommendations\n",
      "\n",
      "    # Generate team-wide recommendations\n",
      "    fatigue_counts = fatigue_levels[\"Total Fatigue Levels\"]\n",
      "    if fatigue_counts[\"High\"] > 3:  # Threshold: more than 3 players with high fatigue\n",
      "        team_recommendations.append(\"Reduce overall training intensity due to high team fatigue.\")\n",
      "\n",
      "    if injury_data[\"Total Injuries\"] > 5:  # Threshold: more than 5 injuries in total\n",
      "        team_recommendations.append(\"Focus on medical assessment and injury prevention strategies.\")\n",
      "\n",
      "    if average_team_recovery_rate > 0.5:\n",
      "        team_recommendations.append(\"Team-wide cardiovascular training recommended to improve recovery rates.\")\n",
      "\n",
      "    # all metrics and recommendations\n",
      "    return {\n",
      "        \"Team Metrics\": {\n",
      "            \"Total Distance Per Game\": team_distance[\"Total Distance Per Game\"],\n",
      "            \"Average Distance Per Game\": team_distance[\"Average Distance Per Game\"],\n",
      "            \"Average Team Speed\": average_team_speed,\n",
      "            \"Max Team Speed\": max_team_speed,\n",
      "            \"Average Team Recovery Rate\": average_team_recovery_rate,\n",
      "        },\n",
      "        \"Player Metrics\": player_metrics,\n",
      "        \"Recommendations\": {\n",
      "            \"Player Recommendations\": player_recommendations,\n",
      "            \"Team Recommendations\": team_recommendations,\n",
      "        },\n",
      "    }\n",
      "\n",
      "\n",
      "def c_team_distance():\n",
      "    \"\"\"\n",
      "\n",
      "    It calculates the total and average distance run per game as well as for all players\n",
      "\n",
      "    \"\"\"\n",
      "    game_distances = {}  \n",
      "\n",
      "    for player_id in range(1, 11):  # for 10 players\n",
      "        gps_path = os.path.join(HISTORICAL_DATA_PATH, f\"gps_{player_id}\")\n",
      "        for run_path in os.listdir(gps_path):  # loop all games\n",
      "            if run_path == '.DS_Store':  # Skip system files\n",
      "                continue\n",
      "            run_file_path = os.path.join(gps_path, run_path, f\"gps_{player_id}.json\")\n",
      "            with open(run_file_path, 'r') as file:\n",
      "                data = json.load(file)\n",
      "            run_distance = 0\n",
      "            for i in range(len(data) - 1):\n",
      "                point1 = data[i]\n",
      "                point2 = data[i + 1]\n",
      "                run_distance += haversine_distance(\n",
      "                    lat1=point1[\"latitude\"],\n",
      "                    lon1=point1[\"longitude\"],\n",
      "                    lat2=point2[\"latitude\"],\n",
      "                    lon2=point2[\"longitude\"],\n",
      "                )\n",
      "\n",
      "\n",
      "\n",
      "            if run_path not in game_distances:\n",
      "                game_distances[run_path] = 0\n",
      "            game_distances[run_path] += run_distance\n",
      "\n",
      "    total_games = len(game_distances)\n",
      "    average_distances_per_game = {\n",
      "        game: round(total_distance / 10, 2)  # Divide by # of players\n",
      "        for game, total_distance in game_distances.items()\n",
      "    }\n",
      "\n",
      "    return {\n",
      "        \"Total Distance Per Game\": {game: round(distance, 2) for game, distance in game_distances.items()},\n",
      "        \"Average Distance Per Game\": average_distances_per_game,\n",
      "    }\n",
      "\n",
      "def team_speeds():\n",
      "    \"\"\"\n",
      "\n",
      "    It calculates average speed (km/h) and max team speed taking into account x,y,z coordinates\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "    total_speeds = []\n",
      "    for player_id in range(1, 2):  # for 10 players\n",
      "        speed_path = os.path.join(HISTORICAL_DATA_PATH, f\"speed_{player_id}\")\n",
      "        for run_path in os.listdir(speed_path):  # loop 15 games\n",
      "            run_file_path = os.path.join(speed_path, run_path, f\"speed_{player_id}.json\")\n",
      "            with open(run_file_path, 'r') as file:\n",
      "                data = json.load(file)\n",
      "            for entry in data:\n",
      "                speed_x = entry[\"schema\"][\"speed_x\"]\n",
      "                speed_y = entry[\"schema\"][\"speed_y\"]\n",
      "                speed_z = entry[\"schema\"][\"speed_z\"]\n",
      "\n",
      "                # Calculate the final vector of speed\n",
      "                speed_magnitude = math.sqrt(speed_x**2 + speed_y**2 + speed_z**2)\n",
      "                total_speeds.append(speed_magnitude)\n",
      "\n",
      "    if total_speeds:\n",
      "        average_speed = round(sum(total_speeds) / len(total_speeds), 2)\n",
      "        max_speed = round(max(total_speeds), 2)\n",
      "    else:\n",
      "        average_speed = 0\n",
      "        max_speed = 0\n",
      "\n",
      "    return average_speed, max_speed\n",
      "\n",
      "def parse_timestamp(timestamp):\n",
      "    \"\"\"\n",
      "    Parse a simpling timestamp string into a datetime object, supporting both formats\n",
      "    with and without microseconds.\n",
      "\n",
      "\n",
      "    \"\"\"\n",
      "    try:\n",
      "        return datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S.%f\")\n",
      "    except ValueError:\n",
      "        return datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S\")\n",
      "\n",
      "\n",
      "def heart_rate_recovery():\n",
      "    \"\"\"\n",
      "\n",
      "    It calculates the average heart rate recovery (beats per min) per player and for team\n",
      "    Returns average player recovery rate and also team recovery rate.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    player_averages = {} \n",
      "    total_team_recovery_rate = 0\n",
      "    team_recovery_count = 0\n",
      "\n",
      "    for player_id in range(1, 11): # for 10 players\n",
      "        heart_rate_path = os.path.join(HISTORICAL_DATA_PATH, f\"player_heart_rate_{player_id}\")\n",
      "        \n",
      "        # initialize metrics for players\n",
      "        total_heart_rate = 0\n",
      "        absolute_max_heart_rate = 0\n",
      "        total_recovery_rate = 0\n",
      "        run_count = 0\n",
      "        heart_rate_count = 0\n",
      "        \n",
      "        for run_path in os.listdir(heart_rate_path):\n",
      "            if run_path == '.DS_Store':  # Skip system files\n",
      "                continue\n",
      "            run_file_path = os.path.join(heart_rate_path, run_path, f\"player_heart_rate_{player_id}.json\")\n",
      "            with open(run_file_path, 'r') as file:\n",
      "                data = json.load(file)\n",
      "\n",
      "            max_heart_rate = 0\n",
      "            max_heart_rate_timestamp = None\n",
      "            heart_rate_drop_60s = None\n",
      "\n",
      "            run_total_heart_rate = 0\n",
      "            run_heart_rate_count = 0\n",
      "\n",
      "            for entry in data:\n",
      "                heart_rate = entry[\"schema\"][\"heart_rate\"]\n",
      "                run_total_heart_rate += heart_rate\n",
      "                run_heart_rate_count += 1\n",
      "                \n",
      "\n",
      "\n",
      "                timestamp = parse_timestamp(entry[\"schema\"][\"timestamp\"])\n",
      "                if heart_rate > max_heart_rate:\n",
      "                    max_heart_rate = heart_rate\n",
      "                    max_heart_rate_timestamp = timestamp\n",
      "                \n",
      "                # Update absolute max if this heart rate is higher\n",
      "                if heart_rate > absolute_max_heart_rate:\n",
      "                    absolute_max_heart_rate = heart_rate\n",
      "\n",
      "            # heart rate drop after 60s\n",
      "            if max_heart_rate_timestamp:\n",
      "                for entry in data:\n",
      "                    heart_rate = entry[\"schema\"][\"heart_rate\"]\n",
      "                    timestamp = parse_timestamp(entry[\"schema\"][\"timestamp\"])\n",
      "                    time_diff = (timestamp - max_heart_rate_timestamp).total_seconds()\n",
      "\n",
      "                    if 1 <= time_diff <= 60:  # Check if within 60 seconds\n",
      "                        heart_rate_drop_60s = max_heart_rate - heart_rate\n",
      "\n",
      "            # Accumulate totals for this run\n",
      "            if run_heart_rate_count > 0:\n",
      "                total_heart_rate += run_total_heart_rate\n",
      "                heart_rate_count += run_heart_rate_count\n",
      "                \n",
      "                if heart_rate_drop_60s is not None:\n",
      "                    recovery_rate = round(heart_rate_drop_60s / 60, 2)\n",
      "                    total_recovery_rate += recovery_rate\n",
      "                    total_team_recovery_rate += recovery_rate\n",
      "                    team_recovery_count += 1\n",
      "                \n",
      "                run_count += 1\n",
      "\n",
      "        # Calculate averages for this player\n",
      "        if run_count > 0:\n",
      "            player_averages[player_id] = {\n",
      "                \"Average Heart Rate\": round(total_heart_rate / heart_rate_count, 2),\n",
      "                \"Overall Maximum Heart Rate\": absolute_max_heart_rate,\n",
      "                \"Average Recovery Rate (BPM/Sec)\": round(total_recovery_rate / run_count, 2),\n",
      "            }\n",
      "\n",
      "    average_team_recovery_rate = round(total_team_recovery_rate / team_recovery_count, 2) if team_recovery_count > 0 else None\n",
      "\n",
      "    return player_averages, average_team_recovery_rate\n",
      "\n",
      "def calculate_average_heart_rate():\n",
      "    \"\"\"\n",
      "    \n",
      "    It calculates average heart rate for every player overall and for each game\n",
      "    \n",
      "\n",
      "\n",
      "    \"\"\"\n",
      "    player_heart_rate_data = {}  # Store data for each player\n",
      "    for player_id in range(1, 11):  # Loop over 10 players\n",
      "        heart_rate_path = os.path.join(HISTORICAL_DATA_PATH, f\"player_heart_rate_{player_id}\")\n",
      "        total_heart_rate = 0\n",
      "        total_readings = 0\n",
      "        game_heart_rates = {}\n",
      "\n",
      "        for run_path in os.listdir(heart_rate_path):  # Loop over runs\n",
      "            if run_path == '.DS_Store':\n",
      "                continue\n",
      "            run_file_path = os.path.join(heart_rate_path, run_path, f\"player_heart_rate_{player_id}.json\")\n",
      "            with open(run_file_path, 'r') as file:\n",
      "                data = json.load(file)\n",
      "\n",
      "            game_total = 0\n",
      "            game_count = 0\n",
      "            for entry in data:\n",
      "                heart_rate = entry[\"schema\"][\"heart_rate\"]\n",
      "                game_total += heart_rate\n",
      "                total_heart_rate += heart_rate\n",
      "                game_count += 1\n",
      "                total_readings += 1\n",
      "\n",
      "            # Average for this game\n",
      "            game_heart_rates[run_path] = round(game_total / game_count, 2) if game_count > 0 else 0\n",
      "\n",
      "        # Average for this player for all the games\n",
      "        player_heart_rate_data[player_id] = {\n",
      "            \"Total Average Heart Rate\": round(total_heart_rate / total_readings, 2) if total_readings > 0 else 0,\n",
      "            \"Per Game Average Heart Rate\": game_heart_rates,\n",
      "        }\n",
      "\n",
      "\n",
      "\n",
      "    return player_heart_rate_data\n",
      "\n",
      "def injuries():\n",
      "    \"\"\"\n",
      "    \n",
      "    It calculates the number of injuries per player\n",
      "    \n",
      "    Returns:\n",
      "        Dictionary: Team injuries and injuries for each player\n",
      "\n",
      "    \"\"\"\n",
      "    # Define the path to the injury table JSON file\n",
      "    injury_path_table = os.path.join(HISTORICAL_DATA_PATH, \"injuries_summary.json\")\n",
      "\n",
      "    # Check if the file exists\n",
      "    if not os.path.exists(injury_path_table):\n",
      "        raise FileNotFoundError(f\"Injury table file not found at path: {injury_path_table}\")\n",
      "\n",
      "    with open(injury_path_table, 'r') as file:\n",
      "        injury_table = json.load(file)\n",
      "\n",
      "    total_injuries = 0\n",
      "    player_injury_data = {}\n",
      "\n",
      "\n",
      "    # Process the injury table\n",
      "    for player_id, games in injury_table[\"players\"].items():  # Assuming \"players\" is the top parent\n",
      "        player_total = 0\n",
      "        per_game_injuries = {}\n",
      "\n",
      "        for game_id, game_data in games.items():\n",
      "            injuries = game_data.get(\"injuries\", 0)  # Extract the \"injuries\" key\n",
      "            player_total += injuries\n",
      "            per_game_injuries[game_id] = injuries\n",
      "\n",
      "        player_injury_data[int(player_id)] = {\n",
      "            \"Total Injuries\": player_total,\n",
      "            \"Per Game Injuries\": per_game_injuries,\n",
      "        }\n",
      "        total_injuries += player_total\n",
      "\n",
      "\n",
      "\n",
      "    return {\n",
      "        \"Total Injuries\": total_injuries,\n",
      "        \"Injuries Per Player\": player_injury_data,\n",
      "    }\n",
      "\n",
      "def calculate_fatigue_levels():\n",
      "    \"\"\"\n",
      "    It calculates the fatigue levels for each player if there is a decreasing distance trend in games.\n",
      "    \n",
      "\n",
      "    Returns:\n",
      "        Dictionary: Fatigue levels for each player and overall totals.\n",
      "    \"\"\"\n",
      "    fatigue_levels = {\"Low\": 0, \"Medium\": 0, \"High\": 0}  # Overall fatigue levels\n",
      "    player_fatigue_data = {}  # Fatigue levels per player\n",
      "\n",
      "    for player_folder in os.listdir(HISTORICAL_DATA_PATH):  # Loop through all player folders\n",
      "        if not player_folder.startswith(\"gps_\"):  # Skip non-GPS folders\n",
      "            continue\n",
      "\n",
      "        player_id = int(player_folder.split(\"_\")[1])  # Extract player ID\n",
      "        distances = []  # List to store total distances per game\n",
      "\n",
      "        # Loop through game or run the folders for each player\n",
      "        for run_path in os.listdir(os.path.join(HISTORICAL_DATA_PATH, player_folder)):\n",
      "            if run_path == '.DS_Store':\n",
      "                continue\n",
      "            gps_file_path = os.path.join(HISTORICAL_DATA_PATH, player_folder, run_path, f\"{player_folder}.json\")\n",
      "            with open(gps_file_path, 'r') as file:\n",
      "                data = json.load(file)\n",
      "\n",
      "            # Calculate total distance for the game\n",
      "            total_distance = 0\n",
      "            for i in range(len(data) - 1):\n",
      "                point1 = data[i]\n",
      "                point2 = data[i + 1]\n",
      "                total_distance += haversine_distance(\n",
      "                    lat1=point1[\"latitude\"],\n",
      "                    lon1=point1[\"longitude\"],\n",
      "                    lat2=point2[\"latitude\"],\n",
      "                    lon2=point2[\"longitude\"],\n",
      "                )\n",
      "            distances.append(total_distance)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        # Check for decreasing distance trends across games\n",
      "        trend_fatigue = 0\n",
      "        for i in range(1, len(distances)):\n",
      "            if distances[i] < distances[i - 1]:  # Decreasing trend\n",
      "                trend_fatigue += 1\n",
      "\n",
      "        # Determine fatigue level\n",
      "        if trend_fatigue <= 3:  # Low fatigue\n",
      "            fatigue_level = \"Low\"\n",
      "        elif 4 <= trend_fatigue <= 6:  # Medium fatigue\n",
      "            fatigue_level = \"Medium\"\n",
      "        else:  # High fatigue\n",
      "            fatigue_level = \"High\"\n",
      "\n",
      "        # Update player fatigue data\n",
      "        player_fatigue_data[player_id] = {\n",
      "            \"Fatigue Level\": fatigue_level,\n",
      "        }\n",
      "\n",
      "\n",
      "        fatigue_levels[fatigue_level] += 1  # Update overall counts\n",
      "\n",
      "    return {\n",
      "        \"Fatigue Levels Per Player\": player_fatigue_data,\n",
      "        \"Total Fatigue Levels\": fatigue_levels,\n",
      "    }\n",
      "\n",
      "\n",
      "# Call the main function to calculate team metrics\n",
      "# team_metrics = calculate_team_metrics()\n",
      "# print(team_metrics)\n",
      "\n",
      "# print(team_distance())\n",
      "# print(team_speeds())\n",
      "# print(heart_rate_recovery())\n",
      "# print(calculate_fatigue_levels())\n",
      "# print(calculate_metrics())\n",
      "----------------\n",
      "\n",
      "File_Name: get_live_stats.py\n",
      "File_Path: backend\\api\\get_live_stats.py\n",
      "Code_contents:\n",
      "from typing import Dict, List, Optional, Union\n",
      "\n",
      "from starlette.responses import StreamingResponse\n",
      "from sse_starlette.sse import EventSourceResponse\n",
      "from fastapi import APIRouter, HTTPException, Query, Body\n",
      "import asyncio\n",
      "\n",
      "from utils.spark_processor import (\n",
      "    get_latest_stats,\n",
      "    check_if_session_exists,\n",
      "    get_aggregated_stats,\n",
      "    initialize_streaming\n",
      ")\n",
      "from utils.file_management import kafka_topic_name\n",
      "from utils.maths_functions import calculate_speed_from_messages, calculate_acceleration_from_messages\n",
      "from .kafka_topics import get_topic_messages\n",
      "from backend.config.config import SCHEMA_DATA_PATH\n",
      "\n",
      "router = APIRouter()\n",
      "\n",
      "GET_STATS_ENDPOINT: str = \"/get-stats/{device_id}/{run_id}\"\n",
      "GET_INSTANT_SPEED_ACCEL_ENDPOINT: str = \"/get-speed/{device_id}/{run_id}\"\n",
      "START_STREAM_ENDPOINT: str = \"/start-stream/{device_id}/{run_id}\"\n",
      "ALARM_ENDPOINT: str = \"/get-notification/{device_id}/{run_id}\"\n",
      "\n",
      "DEVICE_SCHEMA_PATH: str = SCHEMA_DATA_PATH\n",
      "\n",
      "\n",
      "@router.post(START_STREAM_ENDPOINT)\n",
      "async def start_stream(\n",
      "    device_id: str,\n",
      "    run_id: str,\n",
      "    triggers: Dict[str, List[float]] = Body(..., description=\"Dictionary with column names and min/max values\", embed=True),\n",
      "    window_seconds: int = Body(5, embed=True),\n",
      "    table_preappend: Optional[str] = Body(None, embed=True),\n",
      "    exclude_normal: Optional[bool] = Body(False, embed=True)\n",
      "\n",
      ") -> Dict[str, str]:\n",
      "    \"\"\"\n",
      "    Endpoint to start the streaming job for a device and run.\n",
      "\n",
      "    Args:\n",
      "        device_id (str): ID of the device.\n",
      "        run_id (str): ID of the run.\n",
      "        triggers (Dict[str, List[float]]): Dictionary with column names and min/max values.\n",
      "        window_seconds (int): The window duration in seconds.\n",
      "        table_preappend (Optional[str]): String to prepend to the table name for the streaming view.\n",
      "\n",
      "    Returns:\n",
      "        Dict[str, str]: A message indicating whether the streaming was started or is already running.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        spark = check_if_session_exists()\n",
      "        if spark is not None:\n",
      "            kafka_topic = kafka_topic_name(device_id, run_id)\n",
      "            view_name = f\"{table_preappend}_{kafka_topic}\" if table_preappend else kafka_topic\n",
      "\n",
      "            if spark.catalog.tableExists(view_name):\n",
      "                return {\"message\": f\"Streaming already running for device {device_id} and run {run_id}.\"}\n",
      "            else:\n",
      "                initialize_streaming(device_id, run_id, triggers, window_seconds, table_preappend, exclude_normal)\n",
      "\n",
      "        initialize_streaming(device_id, run_id, triggers, window_seconds, table_preappend, exclude_normal)\n",
      "        return {\"message\": f\"Streaming started for device {device_id} and run {run_id}.\"}\n",
      "\n",
      "    except HTTPException as http_ex:\n",
      "        raise http_ex\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=f\"Failed to start streaming: {str(e)}\")\n",
      "\n",
      "\n",
      "# @router.get(QUERY_VIEW)\n",
      "# async def QUERY_VIEW(\n",
      "#     device_id: str,\n",
      "#     run_id: str,\n",
      "#     query: str = Query(default=\"SELECT * FROM {table}\", description=\"SQL query to filter or select data from the streaming view\"),\n",
      "#     table_preappend: Optional[str] = Query(None)\n",
      "# ) -> Dict[str, Union[str, List[Dict]]]:\n",
      "#     \"\"\"\n",
      "#     Endpoint to fetch the latest stats from the streaming view for a device and run.\n",
      "\n",
      "#     Args:\n",
      "#         device_id (str): ID of the device.\n",
      "#         run_id (str): ID of the run.\n",
      "#         query (str): SQL query to filter or select data from the streaming view.\n",
      "#         table_preappend (Optional[str]): Optional prefix for the streaming view table name.\n",
      "\n",
      "#     Returns:\n",
      "#         Dict[str, Union[str, List[Dict]]]: A dictionary containing device_id and the retrieved stats as a list of dictionaries.\n",
      "#     \"\"\"\n",
      "#     try:\n",
      "#         kafka_topic = kafka_topic_name(device_id, run_id)\n",
      "#         view_name = f\"{table_preappend}_{kafka_topic}\" if table_preappend else kafka_topic\n",
      "\n",
      "#         spark = check_if_session_exists()\n",
      "#         if spark is None or not spark.catalog.tableExists(view_name):\n",
      "#             raise HTTPException(status_code=400, detail=f\"Streaming not running for device {device_id} and run {run_id}. Please start the stream first.\")\n",
      "\n",
      "#         stats = get_latest_stats(view_name, query)\n",
      "#         return {\"device_id\": f'{device_id}_{run_id}', \"stats\": [row.asDict() for row in stats]}\n",
      "\n",
      "#     except HTTPException as http_ex:\n",
      "#         raise http_ex\n",
      "#     except Exception as e:\n",
      "#         raise HTTPException(status_code=500, detail=f\"Failed to fetch latest stats: {str(e)}\")\n",
      "\n",
      "\n",
      "@router.get(GET_STATS_ENDPOINT)\n",
      "async def get_stats(\n",
      "    device_id: str,\n",
      "    run_id: str,\n",
      "    agg_type: str = Query(\"average\", enum=[\"average\", \"max\", \"min\", \"sum\"])\n",
      ") -> Dict:\n",
      "    \"\"\"\n",
      "    Endpoint to fetch aggregated stats for a device and run.\n",
      "\n",
      "    Args:\n",
      "        device_id (str): ID of the device.\n",
      "        run_id (str): ID of the run.\n",
      "        agg_type (str): Type of aggregation (average, max, min, sum). Defaults to \"average\".\n",
      "\n",
      "    Returns:\n",
      "        Dict[str, Union[str, List[Dict]]]: A dictionary containing the device_id and the aggregated stats.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        return await get_aggregated_stats(device_id, run_id, agg_type)\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=f\"Failed to get aggregated stats: {str(e)}\")\n",
      "\n",
      "\n",
      "@router.get(GET_INSTANT_SPEED_ACCEL_ENDPOINT)\n",
      "async def get_metric(\n",
      "    device_id: str,\n",
      "    run_id: str,\n",
      "    type: str  # \"speed\" or \"acceleration\"\n",
      ") -> Dict[str, Union[str, float]]:\n",
      "    \"\"\"\n",
      "    Endpoint to fetch either instantaneous speed or acceleration for a device and run.\n",
      "\n",
      "    Args:\n",
      "        device_id (str): ID of the device.\n",
      "        run_id (str): ID of the run.\n",
      "        type (str): Type of metric to calculate (\"speed\" or \"acceleration\").\n",
      "\n",
      "    Returns:\n",
      "        Dict[str, Union[str, float]]: A dictionary containing the device_id, run_id, and the calculated metric.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        # Fetch the latest 3 messages from Kafka for acceleration or 2 for speed\n",
      "        limit = 3 if type == \"acceleration\" else 2\n",
      "        response = await get_topic_messages(device_id, run_id, limit=limit)\n",
      "\n",
      "        # Extract the messages from the response\n",
      "        messages = response.get(\"messages\", [])\n",
      "\n",
      "        # Validate data availability\n",
      "        if (type == \"speed\" and len(messages) < 2) or (type == \"acceleration\" and len(messages) < 3):\n",
      "            raise HTTPException(status_code=400, detail=f\"Not enough data to calculate {type}. Please ensure there are active sensors producing data.\")\n",
      "\n",
      "        # Sort messages by timestamp to ensure they are in chronological order\n",
      "        sorted_messages = sorted(messages, key=lambda msg: msg[\"timestamp\"])\n",
      "\n",
      "        # Calculate the requested metric\n",
      "        if type == \"speed\":\n",
      "            metric = calculate_speed_from_messages(sorted_messages)\n",
      "        elif type == \"acceleration\":\n",
      "            metric = calculate_acceleration_from_messages(sorted_messages)\n",
      "        else:\n",
      "            raise HTTPException(status_code=400, detail=f\"Invalid type '{type}'. Must be 'speed' or 'acceleration'.\")\n",
      "\n",
      "        return {\n",
      "            \"device_id\": device_id,\n",
      "            \"run_id\": run_id,\n",
      "            type: metric\n",
      "        }\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=f\"Failed to get {type}: {str(e)}\")\n",
      "    \n",
      "\n",
      "@router.get(ALARM_ENDPOINT)\n",
      "async def get_notification(device_id: str, run_id: str, window: int = 1, table_preappend: Union[str, None] = None) -> StreamingResponse:\n",
      "    \"\"\"\n",
      "    Endpoint to provide live notifications while the stream is active for a device and run.\n",
      "\n",
      "    Args:\n",
      "        device_id (str): ID of the device.\n",
      "        run_id (str): ID of the run.\n",
      "        window (int): Interval in seconds between data fetch attempts.\n",
      "        table_preappend (Optional[str]): Optional prefix for the streaming view table name.\n",
      "\n",
      "    Returns:\n",
      "        StreamingResponse: A live streaming response with data updates.\n",
      "    \"\"\"\n",
      "    kafka_topic = kafka_topic_name(device_id, run_id)\n",
      "    view_name = f\"{table_preappend}_{kafka_topic}\" if table_preappend else kafka_topic\n",
      "\n",
      "    async def event_generator():\n",
      "        try:\n",
      "            spark = check_if_session_exists()\n",
      "            if spark is None:\n",
      "                raise HTTPException(status_code=400, detail=\"Spark session not available\")\n",
      "\n",
      "            # Variable to keep track of the last processed timestamp\n",
      "            last_processed_timestamp = None\n",
      "\n",
      "            while True:\n",
      "                # Check if the view exists\n",
      "                if not spark.catalog.tableExists(view_name):\n",
      "                    # If the view is gone, close the connection\n",
      "                    break\n",
      "\n",
      "                # Fetch the latest data from the view\n",
      "                try:\n",
      "                    # Query the view and order by timestamp descending to get the latest row\n",
      "                    query = f\"SELECT * FROM {view_name} ORDER BY timestamp DESC LIMIT 1\"\n",
      "                    data_df = spark.sql(query)\n",
      "\n",
      "                    # Convert the DataFrame to a dictionary\n",
      "                    data = [row.asDict() for row in data_df.collect()]\n",
      "\n",
      "                    if data:\n",
      "                        latest_row = data[0]\n",
      "                        current_timestamp = latest_row.get(\"timestamp\")\n",
      "\n",
      "                        # Only yield if the current timestamp is newer than the last processed timestamp\n",
      "                        if last_processed_timestamp is None or current_timestamp > last_processed_timestamp:\n",
      "                            # Update the last processed timestamp\n",
      "                            last_processed_timestamp = current_timestamp\n",
      "                            # Yield the latest data as an SSE message\n",
      "                            yield {\n",
      "                                \"event\": \"update\",\n",
      "                                \"data\": {\"device_id\": f\"{device_id}_{run_id}\", \"updates\": [latest_row]}\n",
      "                            }\n",
      "\n",
      "                except Exception as e:\n",
      "                    # Log or handle error\n",
      "                    print(f\"Error fetching data from view {view_name}: {str(e)}\")\n",
      "\n",
      "                # Wait for the specified interval before checking again\n",
      "                await asyncio.sleep(window)\n",
      "\n",
      "        except Exception as e:\n",
      "            raise HTTPException(status_code=500, detail=f\"An error occurred: {str(e)}\")\n",
      "\n",
      "    # Return the event stream response\n",
      "    return EventSourceResponse(event_generator())\n",
      "\n",
      "----------------\n",
      "\n",
      "File_Name: kafka_topics.py\n",
      "File_Path: backend\\api\\kafka_topics.py\n",
      "Code_contents:\n",
      "import os\n",
      "from typing import Optional, List, Dict, Union\n",
      "\n",
      "from fastapi import APIRouter, HTTPException\n",
      "from confluent_kafka.admin import AdminClient\n",
      "\n",
      "from utils.file_management import device_exists, kafka_topic_name\n",
      "from utils.kafka_producer import get_kafka_messages\n",
      "from backend.config.config import KAFKA_BROKER_URL, SCHEMA_DATA_PATH\n",
      "\n",
      "router = APIRouter()\n",
      "\n",
      "SCHEMA_SAVE_PATH: str = SCHEMA_DATA_PATH\n",
      "\n",
      "GET_TOPIC_MESSAGES_ENDPOINT: str = \"/get-topic-messages/{device_id}/{run_id}\"\n",
      "DELETE_TOPIC_ENDPOINT: str = \"/delete-topic/{device_id}/{run_id}\"\n",
      "DELETE_ALL_TOPICS_ENDPOINT: str = \"/delete-all-topics\"\n",
      "LIST_TOPICS_ENDPOINT: str = \"/list-topics\"\n",
      "\n",
      "\n",
      "# Kafka Admin client\n",
      "admin_client = AdminClient({'bootstrap.servers': KAFKA_BROKER_URL})\n",
      "\n",
      "@router.get(GET_TOPIC_MESSAGES_ENDPOINT)\n",
      "async def get_topic_messages(\n",
      "    device_id: str,\n",
      "    run_id: str,\n",
      "    limit: Optional[int] = None\n",
      ") -> Dict[str, Union[str, List[Dict[str, Union[str, int, float, bool]]]]]:\n",
      "    \"\"\"\n",
      "    Endpoint to asynchronously retrieve Kafka messages for a given device_id and run_id.\n",
      "    If 'limit' is provided, it limits the number of messages retrieved.\n",
      "\n",
      "    Args:\n",
      "        device_id (str): The ID of the device.\n",
      "        run_id (str): The ID of the run associated with the device.\n",
      "        limit (Optional[int], optional): The maximum number of messages to retrieve. Defaults to None.\n",
      "\n",
      "    Returns:\n",
      "        Dict[str, Union[str, List[Dict[str, Union[str, int, float, bool]]]]]: \n",
      "        A dictionary containing device_id, run_id, and the retrieved messages.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        device_schema = device_exists(SCHEMA_SAVE_PATH, device_id, raise_error_if_not_found=True)\n",
      "        schema_fields = device_schema[\"schema\"]\n",
      "\n",
      "        messages = await get_kafka_messages(device_id, run_id, schema_fields, limit)\n",
      "\n",
      "        # If no messages were retrieved, return an empty list\n",
      "        if not messages or not isinstance(messages, list):\n",
      "            messages = []\n",
      "\n",
      "        # Ensure each message is a dictionary with the expected types\n",
      "        validated_messages = []\n",
      "        for msg in messages:\n",
      "            if isinstance(msg, dict):\n",
      "                validated_msg = {k: v for k, v in msg.items() if isinstance(v, (str, int, float, bool))}\n",
      "                validated_messages.append(validated_msg)\n",
      "\n",
      "        response = {\"device_id\": device_id, \"run_id\": run_id, \"messages\": validated_messages}\n",
      "\n",
      "        return response\n",
      "\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=f\"Failed to get messages: {str(e)}\")\n",
      "\n",
      "\n",
      "@router.delete(DELETE_TOPIC_ENDPOINT)\n",
      "async def delete_topic_by_device_name(device_id: str, run_id: str) -> Dict[str, str]:\n",
      "    \"\"\"\n",
      "    Endpoint to delete a Kafka topic based on the device_id and run_id.\n",
      "\n",
      "    Args:\n",
      "        device_id (str): The ID of the device.\n",
      "        run_id (str): The ID of the run associated with the device.\n",
      "\n",
      "    Returns:\n",
      "        Dict[str, str]: A message indicating the result of the topic deletion.\n",
      "    \"\"\"\n",
      "    topic: str = kafka_topic_name(device_id, run_id)\n",
      "    try:\n",
      "        future = admin_client.delete_topics([topic])\n",
      "        result = future[topic].result()\n",
      "\n",
      "        if result is None:\n",
      "            return {\"message\": f\"Topic {topic} deleted successfully\"}\n",
      "\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=f\"Failed to delete topic: {str(e)}\")\n",
      "\n",
      "\n",
      "@router.delete(DELETE_ALL_TOPICS_ENDPOINT)\n",
      "async def delete_all_topics() -> Dict[str, Union[str, Dict[str, Optional[None]]]]:\n",
      "    \"\"\"\n",
      "    Endpoint to delete all Kafka topics in the cluster.\n",
      "\n",
      "    Returns:\n",
      "        Dict[str, Union[str, Dict[str, Optional[None]]]]: \n",
      "        A message indicating the result of the deletion operation for each topic.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        metadata = admin_client.list_topics(timeout=10)\n",
      "        topics = list(metadata.topics.keys())\n",
      "\n",
      "        future = admin_client.delete_topics(topics)\n",
      "        results = {topic: future[topic].result() for topic in topics}\n",
      "\n",
      "        return {\"message\": \"All topics deleted successfully\", \"results\": results}\n",
      "\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=f\"Failed to delete all topics: {str(e)}\")\n",
      "\n",
      "\n",
      "@router.get(LIST_TOPICS_ENDPOINT)\n",
      "async def list_topics() -> Dict[str, Union[str, List[str]]]:\n",
      "    \"\"\"\n",
      "    Endpoint to retrieve all Kafka topics.\n",
      "\n",
      "    Returns:\n",
      "        Dict[str, Union[str, List[str]]]: A message and a list of all Kafka topics.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        # Get metadata for all topics\n",
      "        metadata = admin_client.list_topics(timeout=10)\n",
      "        topics = list(metadata.topics.keys())\n",
      "\n",
      "        return {\"message\": \"Topics retrieved successfully\", \"topics\": topics}\n",
      "\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=f\"Failed to list topics: {str(e)}\")\n",
      "\n",
      "----------------\n",
      "\n",
      "File_Name: register_device.py\n",
      "File_Path: backend\\api\\register_device.py\n",
      "Code_contents:\n",
      "import json\n",
      "import os\n",
      "from typing import Dict, List, Optional\n",
      "\n",
      "from fastapi import APIRouter, HTTPException\n",
      "\n",
      "from backend.models.schemas import RegisterDeviceRequest\n",
      "from utils.file_management import (\n",
      "    create_folder,\n",
      "    save_json_file,\n",
      "    convert_model_to_json,\n",
      "    device_exists,\n",
      "    validate_schema_not_empty\n",
      ")\n",
      "from backend.config.config import SCHEMA_DATA_PATH\n",
      "\n",
      "router = APIRouter()\n",
      "\n",
      "\n",
      "# Set the path where schemas will be saved\n",
      "SCHEMA_SAVE_PATH = SCHEMA_DATA_PATH  # Join with data/device_schemas path\n",
      "\n",
      "REGISTER_DEVICE_ENDPOINT: str = \"/register-device\"\n",
      "UPDATE_DEVICE_ENDPOINT: str = \"/update-device\"\n",
      "DELETE_DEVICE_ENDPOINT: str = \"/delete-device/{device_id}\"\n",
      "ALL_DEVICE_ENDPOINT: str = \"/devices\"\n",
      "GET_DEVICE_ENDPOINT: str = \"/device/{device_id}\"\n",
      "\n",
      "\n",
      "@router.post(REGISTER_DEVICE_ENDPOINT)\n",
      "async def register_device_schema(\n",
      "    device: RegisterDeviceRequest,\n",
      ") -> Dict[str, str]:\n",
      "    \"\"\"\n",
      "    Endpoint allows the registration of a new device schema. It ensures that the schema directory exists,\n",
      "    checks for existing devices, and saves the new schema if it doesn't already exist.\n",
      "\n",
      "    Args:\n",
      "        device (RegisterDeviceRequest): The device registration request containing device details and schema.\n",
      "\n",
      "    Returns:\n",
      "        Dict[str, str]: A message indicating the result of the registration process.\n",
      "\n",
      "    Raises:\n",
      "        HTTPException: If the device already exists with a different schema or if saving the schema fails.\n",
      "    \"\"\"\n",
      "    # Ensure the schema directory exists\n",
      "    create_folder(SCHEMA_SAVE_PATH)\n",
      "\n",
      "    # Check if the device already exists\n",
      "    existing_device_schema: Optional[Dict] = device_exists(\n",
      "        SCHEMA_SAVE_PATH, device.device_name\n",
      "    )\n",
      "\n",
      "    if existing_device_schema:\n",
      "        # Check if the existing schema matches the new schema\n",
      "        if existing_device_schema == convert_model_to_json(device):\n",
      "            return {\n",
      "                \"message\": f\"Device '{device.device_name}' already exists with the same schema.\"\n",
      "            }\n",
      "        else:\n",
      "            raise HTTPException(\n",
      "                status_code=400,\n",
      "                detail=\"Existing device with different schema, use update endpoint.\",\n",
      "            )\n",
      "\n",
      "    # Save the new device schema\n",
      "    schema_file_path: str = os.path.join(\n",
      "        SCHEMA_SAVE_PATH, f\"{device.device_name}.json\"\n",
      "    )\n",
      "    try:\n",
      "        device_schema = convert_model_to_json(device)\n",
      "        validate_schema_not_empty(device_schema)\n",
      "        save_json_file(schema_file_path, device_schema)\n",
      "    except Exception as e:\n",
      "        raise HTTPException(\n",
      "            status_code=500, detail=f\"Failed to save device schema: {e}\"\n",
      "        )\n",
      "\n",
      "    return {\"message\": f\"Schema for {device.device_name} saved successfully!\"}\n",
      "\n",
      "\n",
      "@router.put(UPDATE_DEVICE_ENDPOINT)\n",
      "async def update_device_schema(\n",
      "    device: RegisterDeviceRequest,\n",
      ") -> Dict[str, str]:\n",
      "    \"\"\"\n",
      "    Endpoint updates the schema of an existing device. It ensures the schema directory exists,\n",
      "    verifies the device's existence, and updates the schema accordingly.\n",
      "\n",
      "    Args:\n",
      "        device (RegisterDeviceRequest): The device update request containing updated device details and schema.\n",
      "\n",
      "    Returns:\n",
      "        Dict[str, str]: A message indicating the result of the update process.\n",
      "\n",
      "    Raises:\n",
      "        HTTPException: If the device does not exist or if updating the schema fails.\n",
      "    \"\"\"\n",
      "    # Ensure the schema directory exists\n",
      "    create_folder(SCHEMA_SAVE_PATH)\n",
      "\n",
      "    # Check if the device exists\n",
      "    existing_device_schema: Optional[Dict] = device_exists(\n",
      "        SCHEMA_SAVE_PATH, device.device_name\n",
      "    )\n",
      "\n",
      "    if not existing_device_schema:\n",
      "        raise HTTPException(\n",
      "            status_code=400,\n",
      "            detail=\"Device not found. Use /register-device to create a new device.\",\n",
      "        )\n",
      "\n",
      "    # Update the existing device schema\n",
      "    schema_file_path: str = os.path.join(\n",
      "        SCHEMA_SAVE_PATH, f\"{device.device_name}.json\"\n",
      "    )\n",
      "    try:\n",
      "        device_schema = convert_model_to_json(device)\n",
      "        validate_schema_not_empty(device_schema)\n",
      "\n",
      "        save_json_file(schema_file_path, device_schema)\n",
      "    except Exception as e:\n",
      "        raise HTTPException(\n",
      "            status_code=500, detail=f\"Failed to update device schema: {e}\"\n",
      "        )\n",
      "\n",
      "    return {\"message\": f\"Schema for {device.device_name} updated successfully!\"}\n",
      "\n",
      "\n",
      "@router.delete(DELETE_DEVICE_ENDPOINT)\n",
      "async def delete_device(device_id: str) -> Dict[str, str]:\n",
      "    \"\"\"\n",
      "    Endpoint deletes the schema of a specified device. It verifies the device's existence before deletion.\n",
      "\n",
      "    Args:\n",
      "        device_id (str): The ID of the device to be deleted.\n",
      "\n",
      "    Returns:\n",
      "        Dict[str, str]: A message indicating the result of the deletion process.\n",
      "\n",
      "    Raises:\n",
      "        HTTPException: If the device does not exist or if deletion fails.\n",
      "    \"\"\"\n",
      "    # Verify the device exists\n",
      "    device_exists(SCHEMA_SAVE_PATH, device_id, raise_error_if_not_found=True)\n",
      "\n",
      "    # Construct the file path and delete the schema file\n",
      "    schema_file_path: str = os.path.join(SCHEMA_SAVE_PATH, f\"{device_id}.json\")\n",
      "    try:\n",
      "        os.remove(schema_file_path)\n",
      "    except Exception as e:\n",
      "        raise HTTPException(\n",
      "            status_code=500, detail=f\"Failed to delete device schema: {e}\"\n",
      "        )\n",
      "\n",
      "    return {\"message\": f\"Device '{device_id}' deleted successfully.\"}\n",
      "\n",
      "\n",
      "@router.get(ALL_DEVICE_ENDPOINT)\n",
      "async def get_all_devices() -> Dict[str, List[str]]:\n",
      "    \"\"\"\n",
      "    Endpoint fetches and returns all device names stored in the schema directory.\n",
      "\n",
      "    Returns:\n",
      "        Dict[str, List[str]]: A dictionary containing a list of all device names.\n",
      "\n",
      "    Raises:\n",
      "        HTTPException: If listing devices fails.\n",
      "    \"\"\"\n",
      "    # Ensure the schema directory exists\n",
      "    create_folder(SCHEMA_SAVE_PATH)\n",
      "\n",
      "    devices: List[str] = []\n",
      "    try:\n",
      "        for filename in os.listdir(SCHEMA_SAVE_PATH):\n",
      "            if filename.endswith(\".json\"):\n",
      "                devices.append(filename.replace(\".json\", \"\"))  # Remove .json extension\n",
      "    except Exception as e:\n",
      "        raise HTTPException(\n",
      "            status_code=500, detail=f\"Failed to list devices: {e}\"\n",
      "        )\n",
      "\n",
      "    return {\"devices\": devices}\n",
      "\n",
      "\n",
      "@router.get(GET_DEVICE_ENDPOINT)\n",
      "async def get_device_schema(device_id: str) -> Dict[str, object]:\n",
      "    \"\"\"\n",
      "    Endpoint fetches and returns the schema of the specified device.\n",
      "\n",
      "    Args:\n",
      "        device_id (str): The ID of the device whose schema is to be retrieved.\n",
      "\n",
      "    Returns:\n",
      "        Dict[str, object]: A dictionary containing the device name and its schema.\n",
      "\n",
      "    Raises:\n",
      "        HTTPException: If the device does not exist or if retrieval fails.\n",
      "    \"\"\"\n",
      "    # Retrieve the device schema\n",
      "    device_schema: Dict = device_exists(\n",
      "        SCHEMA_SAVE_PATH, device_id, raise_error_if_not_found=True\n",
      "    )\n",
      "\n",
      "    return {\"device_name\": device_id, \"schema\": device_schema}\n",
      "----------------\n",
      "\n",
      "File_Name: send_stream.py\n",
      "File_Path: backend\\api\\send_stream.py\n",
      "Code_contents:\n",
      "import os\n",
      "import json\n",
      "from typing import List, Dict\n",
      "\n",
      "from fastapi import APIRouter, WebSocket, WebSocketDisconnect\n",
      "\n",
      "from utils.kafka_producer import KafkaProducerWrapper, send_data_to_kafka\n",
      "from utils.file_management import (\n",
      "    create_folder,\n",
      "    save_json_file,\n",
      "    device_exists,\n",
      "    validate_data\n",
      ")\n",
      "\n",
      "from backend.config.config import HISTORICAL_DATA_PATH, SCHEMA_DATA_PATH\n",
      "router = APIRouter()\n",
      "\n",
      "# Constants\n",
      "SCHEMA_SAVE_PATH: str = SCHEMA_DATA_PATH\n",
      "ENDPOINT_WEBSOCKET: str = \"/send-stream/{device_id}/{run_id}\"\n",
      "\n",
      "\n",
      "@router.websocket(ENDPOINT_WEBSOCKET)\n",
      "async def send_stream(\n",
      "    websocket: WebSocket,\n",
      "    device_id: str,\n",
      "    run_id: str\n",
      ") -> None:\n",
      "    \"\"\"\n",
      "    WebSocket endpoint to send a stream of data for a device and run.\n",
      "\n",
      "    This endpoint listens for data from the WebSocket, validates it, and sends it to Kafka.\n",
      "    It also handles disconnections and stores historical data upon WebSocket closure.\n",
      "\n",
      "    Args:\n",
      "        websocket (WebSocket): The WebSocket connection.\n",
      "        device_id (str): The ID of the device.\n",
      "        run_id (str): The ID of the run associated with the device.\n",
      "\n",
      "    Returns:\n",
      "        None\n",
      "    \"\"\"\n",
      "    await websocket.accept()\n",
      "    data_list: List[Dict] = []\n",
      "    producer: KafkaProducerWrapper = None\n",
      "\n",
      "    try:\n",
      "        device_schema = device_exists(SCHEMA_SAVE_PATH, device_id, raise_error_if_not_found=True)\n",
      "        schema_fields = device_schema[\"schema\"]\n",
      "        producer = KafkaProducerWrapper()\n",
      "\n",
      "        while True:\n",
      "            data_text = await websocket.receive_text()\n",
      "            data = json.loads(data_text)\n",
      "\n",
      "            valid = await process_received_data(websocket, device_id, run_id, data, schema_fields, producer, data_list)\n",
      "\n",
      "            if not valid:\n",
      "                await websocket.send_text(\"Closing connection due to validation error.\")\n",
      "                await websocket.close(code=1003)\n",
      "                break\n",
      "\n",
      "    except WebSocketDisconnect:\n",
      "        print(f\"WebSocket disconnected for device '{device_id}'.\")\n",
      "    except Exception as e:\n",
      "        print(f\"Error in send_stream: {e}\")\n",
      "        await websocket.close(code=1006)\n",
      "    finally:\n",
      "        if producer:\n",
      "            producer.flush()\n",
      "            producer.close()\n",
      "        await handle_websocket_disconnect(device_id, run_id, data_list)\n",
      "\n",
      "\n",
      "async def handle_websocket_disconnect(\n",
      "    device_id: str,\n",
      "    run_id: str,\n",
      "    data_list: List[Dict]\n",
      ") -> None:\n",
      "    \"\"\"\n",
      "    Handles WebSocket disconnection, including saving historical data.\n",
      "    \"\"\"\n",
      "    device_run_path: str = os.path.join(HISTORICAL_DATA_PATH, device_id, run_id)\n",
      "    create_folder(device_run_path)\n",
      "    historical_file: str = os.path.join(device_run_path, f\"{device_id}.json\")\n",
      "\n",
      "    try:\n",
      "        if os.path.exists(historical_file):\n",
      "            with open(historical_file, \"r\") as file:\n",
      "                existing_data = json.load(file)\n",
      "            existing_data.extend(data_list)\n",
      "            save_json_file(historical_file, existing_data)\n",
      "        else:\n",
      "            save_json_file(historical_file, data_list)\n",
      "        print(f\"Historical data saved for device '{device_id}'.\")\n",
      "    except Exception as e:\n",
      "        print(f\"Failed to save historical data: {e}\")\n",
      "\n",
      "\n",
      "async def process_received_data(\n",
      "    websocket: WebSocket,\n",
      "    device_id: str,\n",
      "    run_id: str,\n",
      "    data: Dict,\n",
      "    schema_fields: Dict,\n",
      "    producer: KafkaProducerWrapper,\n",
      "    data_list: List[Dict]\n",
      ") -> bool:\n",
      "    \"\"\"\n",
      "    Processes the data received from the WebSocket, validates it, and sends it to Kafka if valid.\n",
      "    \"\"\"\n",
      "    if not validate_data(data, schema_fields):\n",
      "        await websocket.send_text(\"Validation failed. Data does not match the schema.\")\n",
      "        print(f\"Validation failed for device {device_id}, run {run_id}. Data: {data}\")\n",
      "        return False\n",
      "\n",
      "    kafka_topic: str = f\"{device_id}_{run_id}\"\n",
      "    send_data_to_kafka(producer, kafka_topic, data)\n",
      "    data_list.append(data)\n",
      "\n",
      "    return True\n",
      "\n",
      "----------------\n",
      "\n",
      "File_Name: config.py\n",
      "File_Path: backend\\config\\config.py\n",
      "Code_contents:\n",
      "import os\n",
      "\n",
      "# Update default values to use Docker network service names\n",
      "def is_running_in_docker():\n",
      "    \"\"\"Check if the application is running in a Docker container.\"\"\"\n",
      "    try:\n",
      "        with open('/proc/1/cgroup', 'rt') as f:\n",
      "            return 'docker' in f.read()\n",
      "    except FileNotFoundError:\n",
      "        return False\n",
      "\n",
      "# Set KAFKA_BROKER_URL based on environment\n",
      "if is_running_in_docker():\n",
      "    KAFKA_BROKER_URL = os.getenv(\"KAFKA_BROKER_URL\", \"kafka:9092\")\n",
      "    SPARK_MASTER_URL = os.getenv(\"SPARK_MASTER_URL\", \"spark://spark-master:7077\")\n",
      "    HADOOP_URL = os.getenv(\"HADOOP_URL\", \"hdfs://hadoop:9000\")\n",
      "    \n",
      "else:\n",
      "    KAFKA_BROKER_URL = os.getenv(\"KAFKA_BROKER_URL\", \"localhost:9092\")\n",
      "    SPARK_MASTER_URL = os.getenv(\"SPARK_MASTER_URL\", \"local[*]\")\n",
      "    HADOOP_URL = os.getenv(\"HADOOP_URL\", \"hdfs://localhost:9000\")\n",
      "\n",
      "MAX_WORKERS = int(os.getenv(\"MAX_WORKERS\", 16))\n",
      "\n",
      "SPARK_APP_NAME = os.getenv(\"SPARK_APP_NAME\", \"Kafka Streaming Stats\")\n",
      "\n",
      "HISTORICAL_DATA_PATH = os.getenv(\"HISTORICAL_DATA_PATH\", \"backend/data/historical/devices\")\n",
      "SCHEMA_DATA_PATH = os.getenv(\"HISTORICAL_DATA_PATH\", \"backend/data/device_schemas\")\n",
      "----------------\n",
      "\n",
      "File_Name: schemas.py\n",
      "File_Path: backend\\models\\schemas.py\n",
      "Code_contents:\n",
      "from pydantic import BaseModel\n",
      "from typing import Dict\n",
      "\n",
      "# Schema for registering a device\n",
      "class RegisterDeviceRequest(BaseModel):\n",
      "    device_name: str\n",
      "    schema: Dict\n",
      "----------------\n",
      "\n",
      "File_Name: MockData-2.csv\n",
      "File_Path: backend\\simulator-data\\MockData-2.csv\n",
      "Code_contents:\n",
      "﻿player_id,sensor_id,team_id,datestamp,country,abbrevation,latitude,longitude\n",
      "1,61,1,2024-05-05 14:01:54,France,FR,45.765224,4.982131\n",
      "2,52,1,2024-05-05 15:12:09,France,FR,45.13307521,4.734670628\n",
      "3,74,1,2024-05-05 16:19:59,France,FR,44.95857214,4.015915593\n",
      "4,24,1,2024-05-05 16:10:40,France,FR,45.03208245,4.630483439\n",
      "5,5,1,2024-05-05 14:27:58,France,FR,44.79745966,4.658441914\n",
      "6,59,1,2024-05-05 15:17:18,France,FR,45.18191736,4.429332891\n",
      "7,95,1,2024-05-05 14:30:00,France,FR,45.0983526,4.092610449\n",
      "8,24,1,2024-05-05 14:58:49,France,FR,45.06159633,4.974532206\n",
      "9,71,1,2024-05-05 15:21:31,France,FR,45.61535906,4.455432512\n",
      "10,97,1,2024-05-05 14:53:43,France,FR,44.90200808,4.695390559\n",
      "11,96,1,2024-05-05 15:10:43,France,FR,45.13371857,4.372668744\n",
      "12,29,2,2024-05-05 14:56:46,France,FR,44.78837326,4.485135683\n",
      "13,35,2,2024-05-05 15:41:09,France,FR,45.36073251,4.618568372\n",
      "14,81,2,2024-05-05 14:24:14,France,FR,45.38852829,4.706865797\n",
      "15,93,2,2024-05-05 14:23:27,France,FR,45.37388581,4.961566347\n",
      "16,54,2,2024-05-05 14:52:43,France,FR,45.52513952,4.820297684\n",
      "17,51,2,2024-05-05 16:09:33,France,FR,45.62660283,4.623027599\n",
      "18,39,2,2024-05-05 14:10:37,France,FR,45.35305139,4.592131429\n",
      "19,96,2,2024-05-05 14:23:51,France,FR,44.79367597,4.615529181\n",
      "20,29,2,2024-05-05 15:54:47,France,FR,45.18612909,4.16149624\n",
      "21,65,2,2024-05-05 15:19:36,France,FR,45.4710336,4.006138322\n",
      "22,5,2,2024-05-05 14:39:55,France,FR,45.05220177,4.422065103\n",
      "1,76,1,2024-05-06 14:01:54,France,FR,45.67974536,4.898572975\n",
      "2,7,1,2024-05-05 14:40:28,France,FR,45.74637299,4.962185144\n",
      "3,0,1,2024-05-05 16:20:38,France,FR,45.70473688,4.917109616\n",
      "4,61,1,2024-05-05 14:45:14,France,FR,45.74331219,4.953777141\n",
      "5,58,1,2024-05-05 14:58:11,France,FR,45.6672029,4.927738612\n",
      "6,42,1,2024-05-05 16:13:33,France,FR,45.72739282,4.917746646\n",
      "7,72,1,2024-05-05 15:21:24,France,FR,45.73387581,4.95058871\n",
      "8,87,1,2024-05-05 15:13:13,France,FR,45.73364385,4.899155678\n",
      "9,34,1,2024-05-05 14:40:52,France,FR,45.74195775,4.911586704\n",
      "10,40,1,2024-05-05 15:49:16,France,FR,45.70052011,4.938225885\n",
      "11,11,1,2024-05-05 16:22:21,France,FR,45.67145939,4.942414882\n",
      "12,6,2,2024-05-05 14:15:37,France,FR,45.70904162,4.900750295\n",
      "13,88,2,2024-05-05 15:45:55,France,FR,45.75947718,4.90052285\n",
      "14,19,2,2024-05-05 14:08:38,France,FR,45.72589461,4.97430737\n",
      "15,20,2,2024-05-05 16:03:19,France,FR,45.71373458,4.964301595\n",
      "16,21,2,2024-05-05 14:13:45,France,FR,45.69157743,4.914677642\n",
      "17,41,2,2024-05-05 14:16:36,France,FR,45.75744835,4.945492491\n",
      "18,86,2,2024-05-05 16:02:21,France,FR,45.66959175,4.892045462\n",
      "19,54,2,2024-05-05 16:14:35,France,FR,45.67347731,4.927342603\n",
      "20,44,2,2024-05-05 14:39:39,France,FR,45.6700854,4.891005434\n",
      "21,82,2,2024-05-05 15:51:03,France,FR,45.72952073,4.89563403\n",
      "22,26,2,2024-05-05 14:21:48,France,FR,45.66530636,4.882567473\n",
      "\n",
      "----------------\n",
      "\n",
      "File_Name: wearables-mock-data.csv\n",
      "File_Path: backend\\simulator-data\\wearables-mock-data.csv\n",
      "Code_contents:\n",
      "player_id,heart_rate,steps,calories_burned,distance_covered,sleep_quality,injury_status,workout_duration,body_fat_percentage,muscle_mass,device_id,datestamp\n",
      "17,54,16180,975,18,poor,major injury,8.63,24.1,54.05,21e643a0-0cfe-45ab-9fcc-3e58524b7ffe,2024-03-17 03:06:25\n",
      "19,198,14005,1029,19,fair,healthy,208.76,18.06,150.78,fd96392b-5568-4afd-a722-43610928ee75,2024-10-01 16:07:24\n",
      "5,90,8498,3493,14,fair,minor injury,14.38,25.84,96.43,e8f7f5cd-b38c-4041-9e33-aea82cca4ead,2024-07-08 09:57:43\n",
      "1,190,8132,1753,12,poor,minor injury,142.98,15.69,89.79,95a118a3-66d9-409f-b741-3f6bcefb1bde,2024-08-07 22:36:06\n",
      "6,88,6472,3386,0,good,healthy,179.64,21.44,119.65,237eeb9a-32fb-4fb1-bee2-df98e14b1030,2024-05-23 23:05:37\n",
      "20,99,17952,4259,17,excellent,minor injury,74.22,19.55,188.93,b8883ca4-5a45-48ec-b749-0c881a178adc,2024-07-14 06:07:05\n",
      "20,61,15610,336,6,excellent,major injury,188.25,9.08,183.63,9252f4f1-b5ce-4baa-9df9-83b9dca09f6b,2023-11-24 09:48:41\n",
      "22,72,1889,4753,12,excellent,healthy,136.98,26.5,162.24,71563065-e876-4c26-80c2-ffe927a86578,2024-06-03 20:53:25\n",
      "15,170,6201,3343,8,poor,healthy,74.99,11.46,71.86,6e75c700-7eb2-4afe-9ea1-36b1b1d7e462,2024-01-18 15:36:42\n",
      "11,65,13068,4604,8,excellent,major injury,69.04,17.31,57.67,fd6e7969-ae72-4df7-98e8-594ca35e6a7f,2024-03-21 09:06:42\n",
      "3,132,7292,1643,3,good,healthy,172.34,19.29,177.83,2654b218-1c19-4527-8b19-4f6b68be3f04,2024-08-08 22:16:54\n",
      "20,186,2459,4885,0,fair,minor injury,54.25,23.41,155.2,0aa107ab-c3c5-4b7a-83d1-68be47d47ed6,2024-06-08 20:42:57\n",
      "2,188,3202,3151,2,good,healthy,89.18,14.61,76.28,d43ce580-e407-4d2b-b4c8-49b030732c3e,2024-01-12 17:26:37\n",
      "19,105,8777,3512,5,fair,major injury,216.23,26.26,83.2,892551f6-34d4-4f87-926f-e304744f44f6,2024-05-29 22:07:16\n",
      "13,105,14158,3165,7,poor,healthy,106.9,17.62,193.49,4bc54147-2b78-4815-9bbf-d200c663d211,2024-01-17 19:47:23\n",
      "2,88,15526,3302,9,excellent,healthy,174.68,16.74,126.0,65048e50-e3c7-4671-bc84-5970060bfefc,2024-09-27 11:45:14\n",
      "11,60,13881,2804,7,poor,minor injury,158.92,19.59,135.89,8facb239-41ed-4872-b03f-de297e8bfbe7,2024-03-15 00:29:45\n",
      "10,75,13761,1661,16,fair,major injury,199.14,27.47,84.94,81cde0a3-da86-46a6-b903-b223e262acad,2024-07-05 04:05:30\n",
      "20,75,1621,4994,13,good,healthy,183.26,29.13,50.0,2986d155-b948-41f3-ad30-f27d39b42fea,2024-08-05 17:47:37\n",
      "19,101,15353,698,1,poor,healthy,108.41,21.73,85.95,ccf48bbe-6840-4fa3-956f-43a824de9e45,2024-03-16 13:08:13\n",
      "5,140,14045,4250,5,excellent,minor injury,175.2,14.59,145.52,09a80995-1aa0-4ae7-922c-30b98ff3dcdf,2024-09-02 05:45:42\n",
      "21,67,11212,1390,2,poor,major injury,170.37,13.45,193.95,bbfcb55d-cbae-4dcd-b127-a90a4426eef4,2024-02-24 20:45:34\n",
      "7,140,14638,320,6,good,minor injury,132.22,8.13,76.38,c608d2c4-9e9f-469e-ad4d-eaeb95af85da,2024-07-14 03:24:42\n",
      "7,168,19292,3160,4,excellent,minor injury,92.67,21.48,138.45,2a967b01-9da2-4ded-9743-b0ce031a0cb9,2024-10-13 12:57:50\n",
      "7,85,15949,51,15,fair,major injury,80.96,12.43,182.19,ae9e9329-54b1-456e-9291-4c83f9e19198,2023-10-22 04:12:12\n",
      "12,136,14549,273,6,poor,major injury,12.17,24.33,53.02,e2ccc654-d4bb-4fd5-bead-8167aa90c107,2024-07-28 09:13:27\n",
      "1,81,12856,233,20,fair,healthy,94.58,20.48,166.28,32cc84e6-7c8e-4272-8a5b-9c982f5f171f,2024-04-20 13:29:12\n",
      "10,158,4040,4861,0,excellent,healthy,159.85,12.73,63.54,826d5b62-a12b-4b90-81c9-97f6b9824694,2023-11-04 18:57:55\n",
      "9,53,4444,3191,14,excellent,healthy,34.59,13.93,73.57,1cf8c43f-50b8-403e-b4e9-f9f16937596e,2023-10-15 07:10:59\n",
      "1,59,11881,247,7,fair,major injury,66.01,19.41,94.2,bf71cc7b-9886-4e20-997f-a7657260b3a5,2024-01-01 15:41:26\n",
      "18,98,11292,4954,20,excellent,healthy,161.43,20.98,103.02,73dcb0e2-d63e-4369-83c4-0fa65d5164d0,2024-08-07 04:26:29\n",
      "7,126,17921,432,20,good,healthy,147.53,8.1,141.53,89d1478c-548c-4b55-ac48-727db4391672,2024-08-23 06:37:49\n",
      "18,169,8893,1118,18,poor,major injury,180.59,24.32,103.97,84952fd0-0453-46af-a46c-1c93abb33ce6,2024-04-18 23:20:02\n",
      "12,137,11126,818,11,excellent,major injury,129.66,8.43,157.7,36cb5076-87ba-4332-aa9c-1a392c3674ff,2023-12-25 21:50:12\n",
      "9,116,15612,1755,14,good,major injury,123.95,19.96,100.74,b98f6b42-2035-4645-9165-6dd34613f64e,2023-12-23 14:23:13\n",
      "11,151,4009,1128,1,poor,healthy,68.31,5.51,88.92,758a4738-0a86-4020-8d80-a8436bca5878,2024-05-15 18:52:47\n",
      "13,174,2661,2794,13,good,minor injury,215.78,7.67,190.81,cadb18a0-4f1a-4570-aaa1-d5e0b4ed0c09,2024-01-28 07:58:35\n",
      "18,191,6272,41,2,excellent,minor injury,66.92,18.97,161.44,a3bf5ca1-9989-437a-94bf-f1030780fc40,2023-10-23 12:10:30\n",
      "14,156,7118,3538,3,fair,minor injury,159.69,11.84,112.94,efa57af8-76ab-4dcf-bdf9-af915d577bfc,2024-09-17 23:59:07\n",
      "18,119,13359,1670,5,good,major injury,117.56,11.14,165.28,1e6dad69-682b-463f-8af1-3ff781da6359,2024-08-19 16:51:40\n",
      "1,147,10288,3997,4,good,healthy,130.73,10.71,81.19,a0bbc589-fdb1-4c0d-8ac1-b64fd9b337e7,2024-07-03 18:51:27\n",
      "12,57,10292,4183,17,excellent,healthy,40.64,5.35,88.21,a0ae42ae-96ae-46b6-bc4b-dc58d145a915,2023-12-01 18:35:47\n",
      "8,136,11616,2996,14,excellent,minor injury,239.72,7.32,65.52,41a68bf6-525a-4521-8c33-ec0ac47bcfa7,2023-11-01 14:01:02\n",
      "7,149,8069,3815,4,good,healthy,100.65,15.87,142.22,69749170-24df-4541-a6d4-58667fed8059,2024-04-21 01:55:32\n",
      "20,126,1477,1700,20,excellent,major injury,80.47,6.26,147.11,f6da84e4-566b-40e6-adce-4d8ea95942a0,2024-07-14 23:46:46\n",
      "6,106,1359,4126,16,poor,minor injury,174.17,16.57,187.15,7fb17a82-3bf9-4990-9884-51be3d2e3f1b,2024-09-23 22:47:59\n",
      "1,131,7516,4516,19,fair,major injury,68.05,7.27,189.69,99ccbe7e-595f-4df1-b793-f83455d6c22e,2024-07-21 05:15:12\n",
      "18,122,14520,1674,12,poor,healthy,221.21,12.66,61.58,ba9f3530-5fb3-470c-9256-080c88cb5429,2024-03-18 16:45:45\n",
      "21,83,16986,1131,11,fair,healthy,59.54,5.16,66.38,c0ac3c04-0fcb-4035-a26a-7d11dbe7abbe,2023-11-10 15:18:37\n",
      "16,119,752,1288,7,good,healthy,158.67,6.25,83.52,de01f72d-5aac-4497-b050-36286cf0b6d7,2024-07-17 20:42:37\n",
      "8,187,15707,819,9,excellent,minor injury,64.6,26.02,107.35,29ec2e17-ee60-4eae-9086-039acba7006e,2023-10-17 07:31:26\n",
      "2,176,15526,2428,13,fair,minor injury,2.59,24.67,68.75,bdca4691-83c7-4042-9477-aa241e0d4107,2024-05-17 09:33:14\n",
      "17,68,13769,3263,11,fair,major injury,106.66,12.75,158.52,185170e3-edba-4662-a267-96a20d57c224,2024-04-06 23:56:27\n",
      "19,183,8653,4473,3,fair,major injury,181.34,24.72,167.71,999caf4e-8943-4fcc-b8a1-445b3dc44887,2024-03-21 12:57:04\n",
      "16,121,12803,3459,16,excellent,major injury,81.54,5.06,190.48,ac9ee01c-8b5e-493c-af55-ea4880ae0421,2024-09-20 06:05:57\n",
      "8,185,13965,3262,8,fair,major injury,174.53,26.49,130.35,fb13fd19-4643-49e0-af85-6341536c2c4a,2024-08-09 17:02:48\n",
      "3,162,4544,539,20,good,minor injury,228.1,29.38,81.72,dcaced3f-c2fe-46b5-9f94-6fdeb2494e10,2024-06-30 00:07:57\n",
      "22,101,870,3057,13,fair,healthy,139.3,6.08,194.37,cc18f4f8-db7b-4a61-8c44-f027638e9377,2024-07-22 02:47:48\n",
      "4,132,8947,3314,19,fair,major injury,70.02,24.82,63.95,be95150a-bc87-4998-be6a-d1a614754018,2024-08-30 08:35:31\n",
      "11,102,386,4354,20,fair,major injury,69.86,8.93,191.98,ac874f56-f0a7-4626-8b6d-7cedfd056355,2024-08-17 03:20:28\n",
      "4,145,16291,4722,9,good,major injury,45.55,17.31,140.79,e9c6123c-29d6-4799-aa86-2aef3d57c29b,2023-11-04 20:49:51\n",
      "13,60,1784,1338,0,excellent,minor injury,47.89,5.44,196.37,e8cf5e54-4a3e-4d70-8789-c5f83824dd06,2024-07-09 00:15:41\n",
      "13,137,14862,702,18,fair,healthy,33.94,12.9,165.83,3e99c45b-62fa-49fd-8645-7a89b535b40f,2024-02-03 10:03:43\n",
      "17,142,8244,184,6,fair,healthy,96.45,26.99,127.17,a954f643-6942-46f5-9012-a25102c00106,2024-02-26 11:06:20\n",
      "6,85,1280,1807,9,good,major injury,98.02,25.22,144.08,e39e6456-d30f-4038-8fc8-5b532e40d801,2023-11-05 01:54:30\n",
      "12,132,14241,154,6,poor,minor injury,154.34,5.14,140.35,529a0447-87b4-4bdd-a715-32231de672c6,2023-12-01 12:27:34\n",
      "19,95,3300,4652,15,excellent,minor injury,140.37,15.78,105.0,f6a5e706-3281-4fde-8126-d6b6a0c4d749,2024-04-05 11:04:09\n",
      "10,173,5482,2607,18,good,major injury,10.54,12.0,77.44,ba6ba1c1-403c-4904-accd-25478771982b,2024-05-17 11:06:53\n",
      "14,66,3351,4731,14,fair,minor injury,22.97,7.89,83.38,1e8be719-3fb5-485e-ac2c-01befaada0c7,2024-04-14 02:49:58\n",
      "1,120,17130,835,15,fair,healthy,148.45,26.94,84.3,046be4c6-e8d0-4438-95cb-92547a3dd203,2024-07-19 20:46:45\n",
      "13,71,18116,3382,18,poor,major injury,48.83,16.11,191.33,f4fc16d2-092c-4259-90ff-5c658607924c,2023-12-11 12:06:22\n",
      "4,161,11839,1232,14,excellent,major injury,177.74,22.58,83.35,54319935-94ea-4876-ad8e-6a4d2baacbed,2024-06-10 18:16:16\n",
      "17,63,14619,1830,2,excellent,healthy,185.45,5.9,199.44,455a5339-5167-4fbe-9d35-6a566e0bb322,2023-12-26 01:19:23\n",
      "5,105,2799,4622,6,poor,healthy,180.17,25.23,133.72,a4f6c0b8-3f6f-4465-96a9-2dc617f7ac87,2024-06-03 07:20:50\n",
      "22,157,16058,4696,6,poor,minor injury,97.98,22.71,113.04,0f7e432e-3b15-425b-b0e1-94598330b8e7,2024-06-12 07:27:59\n",
      "3,165,16120,2518,15,excellent,healthy,119.81,9.89,66.45,9a484a0b-3226-4602-a900-1fd2ba467a3a,2023-11-03 09:15:53\n",
      "7,186,18749,1616,12,fair,minor injury,41.42,9.42,154.21,1c7b397e-4857-4515-9870-4e221b67612b,2024-05-24 13:34:20\n",
      "5,64,7245,2585,12,fair,major injury,77.44,24.03,176.44,5d6776c6-bc47-4e55-86b6-739d357228a2,2024-01-28 22:36:19\n",
      "14,191,701,272,17,fair,minor injury,46.79,25.37,170.52,13f5aa97-cea7-4eb7-bb73-117665022e06,2023-10-27 21:17:44\n",
      "5,157,5544,1813,16,excellent,healthy,33.55,15.24,101.73,940c354a-1168-4f63-876e-1c294e15e298,2023-11-22 09:04:58\n",
      "19,51,7262,287,2,excellent,healthy,133.4,12.68,97.93,5348d5bc-391d-414a-8142-4f4bc43ceea2,2023-12-02 11:14:10\n",
      "14,143,11108,2935,20,fair,minor injury,112.16,14.25,84.54,0fab1048-c7b2-4d8b-8a74-2d36559f0a2c,2024-10-09 23:35:31\n",
      "5,116,2342,699,19,excellent,major injury,201.42,29.71,195.51,55b720d0-cc6d-49d8-a055-e7dccdc6cbfe,2024-06-24 14:33:42\n",
      "2,149,14421,4390,3,poor,healthy,15.02,8.92,70.85,8d2790ef-19f1-4ed1-8933-7c0ca751d900,2024-08-10 15:59:39\n",
      "7,195,19606,2530,20,good,healthy,202.1,10.95,125.19,53fafdb8-d9cd-4b25-b4a6-7809f31bf069,2024-09-21 07:12:26\n",
      "15,118,5945,360,18,fair,healthy,116.17,12.87,153.85,4f584a9f-d519-40ec-8e7f-a55940e0d8bb,2024-09-02 05:35:19\n",
      "15,176,6075,2729,6,excellent,minor injury,82.85,17.72,86.23,81c19974-8a12-4b9d-b14e-86e00fa8ae4e,2024-01-23 09:45:41\n",
      "19,125,12378,1536,13,good,minor injury,205.8,21.02,160.33,945b6f68-33ef-4340-8fac-55ac5ad6d784,2023-10-21 17:51:42\n",
      "5,193,16471,1824,8,poor,major injury,43.33,9.88,55.21,d56cd740-c3df-46d8-8429-82d3b8e71795,2024-06-23 09:32:37\n",
      "13,166,4515,4298,1,fair,minor injury,175.48,15.17,130.52,d436a1dc-326f-4823-a715-35e9047a9562,2024-02-04 16:35:24\n",
      "5,180,17886,2040,12,poor,minor injury,99.36,24.9,66.38,f03ee1e8-0558-459e-ba32-50d3e986c66d,2024-01-25 04:11:01\n",
      "20,142,19570,2799,18,excellent,minor injury,106.26,19.75,128.75,0fe8e17e-9748-4b32-a2b8-98babee344c6,2024-04-12 19:47:19\n",
      "8,187,2695,1921,5,excellent,healthy,97.95,7.39,92.81,5d70f974-ca1a-4387-9e2d-c8d3dee496b9,2024-06-18 05:31:10\n",
      "6,56,6183,3276,6,excellent,minor injury,64.95,17.1,167.42,36313dac-7ead-4932-8154-1496c0e5a067,2024-06-09 14:03:28\n",
      "15,67,4257,4028,5,excellent,minor injury,189.98,18.93,73.48,2146baa6-37bb-4584-ac59-229d8dba5528,2024-08-15 08:01:33\n",
      "16,125,2277,2463,18,good,major injury,79.12,28.99,119.01,33910be3-8e09-4e94-b614-4090f3cf85a5,2024-06-03 10:58:14\n",
      "16,123,9,4129,13,poor,minor injury,198.43,24.09,169.91,18ec8ad2-4a50-45ef-a80b-4a30d763b687,2024-01-30 09:00:44\n",
      "17,70,14344,1582,3,poor,minor injury,23.1,25.33,94.21,5aa9d5a3-3d93-4c3c-a3ab-cf549aa7a61e,2023-12-03 12:18:08\n",
      "6,156,10132,514,4,good,healthy,21.39,21.62,55.74,3dfdc263-295a-472f-a75b-87a140b438d9,2024-09-24 22:45:01\n",
      "16,65,11915,3810,0,good,major injury,87.66,28.36,53.46,8cf95b44-1432-4b56-a959-ecf59fd15329,2024-01-10 19:29:02\n",
      "22,68,14138,2792,2,excellent,healthy,118.58,9.24,172.27,1bedfa10-20d4-4ec9-96b1-6db7bd680ca3,2024-10-11 06:49:01\n",
      "5,155,8036,2228,2,poor,minor injury,2.57,20.49,129.21,9773b0c0-944c-4aee-9ece-11b776517a55,2024-08-15 02:37:34\n",
      "22,73,14469,1278,13,good,healthy,236.83,24.83,97.57,2a76f1c6-eab2-407f-a54f-25039eaa1376,2024-03-02 17:17:13\n",
      "12,93,10823,887,14,good,major injury,75.4,25.27,163.15,f7937dc9-273c-4749-bf5e-2e5f117c1b7b,2024-07-15 09:03:48\n",
      "13,107,10802,631,8,good,minor injury,115.15,17.16,90.99,3ba9600d-6045-4f71-b969-cac705d10076,2024-02-14 19:03:18\n",
      "17,89,19155,2748,18,poor,minor injury,201.1,12.44,132.88,81fe4ea7-e7bd-487d-9314-aaeef93104b0,2024-07-21 08:23:29\n",
      "8,111,6666,4392,0,good,minor injury,76.74,9.86,121.42,f8915bec-0107-484a-aa6e-c2541016ec4d,2023-12-13 14:28:55\n",
      "4,83,6549,1536,4,fair,healthy,198.83,7.79,53.14,269a7d3b-a7c0-406c-8dae-2aeebbde05e3,2024-07-17 14:53:04\n",
      "14,64,10739,2879,3,poor,healthy,224.03,26.94,52.25,6df8882c-5645-4484-948f-91fe050eaec8,2024-04-30 05:29:30\n",
      "22,146,17542,1488,4,fair,minor injury,149.9,20.71,189.44,5e291f8a-25d3-4837-bc6d-a9736416530a,2024-08-01 14:04:35\n",
      "8,137,17428,785,7,excellent,major injury,133.87,5.66,82.5,78e3a829-fdca-4a4d-8c6d-c3f3ca00b371,2024-04-16 15:59:27\n",
      "5,73,4204,2442,13,excellent,major injury,144.4,11.92,63.2,97a46ead-3513-4bc3-83ca-acb37c52360f,2024-04-22 16:49:16\n",
      "8,75,9876,4079,5,good,minor injury,53.33,15.84,92.08,fad8d3b0-bf63-479f-aa11-21ba3bb7fc17,2024-05-30 19:46:24\n",
      "21,188,17148,1406,0,good,healthy,161.29,6.71,182.27,2c5cd727-aa1e-46b7-aa14-a291cdb9056c,2024-04-03 20:10:30\n",
      "3,177,9090,1501,11,poor,healthy,53.04,25.32,70.56,b3df6394-7727-4adb-a8b1-0d2818120241,2024-04-04 12:16:26\n",
      "18,123,19358,1444,17,poor,minor injury,231.28,10.91,148.46,47fdfcbb-68e3-48c9-af33-ce0dd0384cb8,2024-04-17 02:18:05\n",
      "3,186,5500,3066,6,poor,major injury,100.0,6.27,59.84,fc4688b0-5eea-4e82-a5e7-b3120fff1129,2024-04-23 11:28:31\n",
      "19,50,13811,2693,12,good,healthy,176.97,26.35,144.29,35f857c0-d8a0-4d6f-8b98-b6c30f1a56d6,2024-04-08 22:31:12\n",
      "7,65,16743,4498,12,good,major injury,131.11,21.18,109.89,be1262b6-77b7-4dea-a516-eb7c45b729e3,2024-08-30 07:08:41\n",
      "17,149,17672,1984,17,excellent,minor injury,215.2,25.32,173.62,f190eea3-afa9-4613-84a1-29ca7f48ef72,2024-08-24 19:47:30\n",
      "6,52,9360,4584,11,good,healthy,229.95,26.61,162.69,4e9106a4-f2d7-45fb-8a34-7bb0fe4144d7,2024-07-04 00:34:14\n",
      "12,155,13633,2541,10,excellent,major injury,69.8,10.49,108.44,8b94d1e9-55e1-46c0-86e8-11b3023a1afc,2024-04-16 19:32:19\n",
      "7,55,15987,4233,0,good,minor injury,142.34,24.0,55.63,17cb2692-5c7d-4cf2-8969-8df57b476672,2023-12-16 07:43:20\n",
      "20,188,13737,3811,8,good,healthy,72.71,26.18,128.26,828f1451-db15-4270-8b72-322ecb4452ee,2024-07-06 06:36:28\n",
      "13,151,16043,1507,1,fair,minor injury,106.87,18.61,116.84,7f4efec9-8cbe-4205-8af2-951ca2ca4211,2023-12-16 02:02:35\n",
      "7,148,1444,2413,13,good,major injury,221.74,8.07,98.95,a584ed78-d3ee-4e67-ae2a-11ba3c8b2195,2024-09-26 02:35:57\n",
      "3,103,11139,1967,20,fair,healthy,139.93,12.38,143.69,d6af6ad0-640f-42e8-a5f0-727bdd23836e,2023-12-13 23:19:03\n",
      "2,182,9656,3386,5,excellent,healthy,139.84,29.58,164.69,45a25df7-7f9c-4c37-a215-9b135436915f,2024-04-15 02:45:27\n",
      "7,96,564,1448,12,poor,healthy,98.35,29.02,130.59,2625679c-0a3c-4df9-bed0-351b3776272f,2024-05-09 23:07:30\n",
      "15,161,4306,812,3,fair,minor injury,189.84,13.42,145.28,e69e6291-d62d-47c9-b6db-25b4cfe462d0,2024-05-10 23:35:50\n",
      "7,120,8161,23,2,good,minor injury,30.5,16.01,127.24,e99d5f44-efc0-4e19-8793-47228f14d23f,2024-03-27 20:20:25\n",
      "18,146,5604,2896,11,excellent,healthy,54.38,16.75,83.57,428a45c0-5d44-4905-a926-7f5ba9483249,2024-03-23 07:41:42\n",
      "21,179,18554,4172,15,poor,minor injury,14.84,21.94,77.51,b9789d39-6a7e-43a5-b2a4-15af391e294b,2023-12-29 08:05:48\n",
      "16,106,15398,2972,8,fair,minor injury,51.62,10.99,118.69,6b3d550c-5f4b-49dd-b957-7834aa1ddadb,2024-08-19 05:53:08\n",
      "21,95,10034,1610,15,excellent,minor injury,214.86,23.36,194.15,881d9372-ae2d-408a-81f3-7ebc0f806034,2024-04-09 11:59:12\n",
      "20,140,3292,1532,4,good,major injury,179.54,28.9,151.42,0a73078b-5826-40b3-980d-a9e4e29fc8dc,2024-03-08 23:34:37\n",
      "12,60,464,2620,13,excellent,minor injury,24.18,12.39,155.25,d7737349-ab3c-4db1-9102-ccbad89f9777,2024-09-14 22:34:16\n",
      "10,151,3910,1003,14,excellent,major injury,174.89,13.02,189.05,3233cb1d-fe2f-4214-9e00-43f67d05a4c7,2024-08-13 20:17:34\n",
      "8,158,15222,3015,18,poor,minor injury,34.38,15.41,178.97,8309486a-1f87-4c54-afd8-054d022848f7,2024-09-20 13:45:32\n",
      "10,152,12649,3360,12,poor,major injury,238.21,12.41,73.63,6ea51d8d-f400-41c6-9e22-50401a1476cf,2023-12-28 14:21:51\n",
      "16,144,13664,790,10,poor,major injury,158.73,17.21,127.24,4288116c-1382-442e-92ab-3cc13b50aa1f,2023-11-01 10:22:03\n",
      "5,79,17522,3039,1,good,minor injury,148.44,28.25,79.52,1173c243-772d-4e91-a0cc-0a5604c0cc08,2024-03-17 23:27:14\n",
      "3,171,1153,1119,12,poor,major injury,129.06,17.73,85.23,e39a9892-eaf2-48bc-a499-7e235bc77ed5,2023-12-23 15:11:27\n",
      "17,153,4841,461,10,good,minor injury,193.99,14.97,85.75,e46b95c5-c655-40fb-bc11-4b7f719d3ca9,2024-04-17 09:39:11\n",
      "6,119,4101,1817,7,good,minor injury,113.19,24.03,70.03,9c418682-c053-4f91-b6b5-ba89ae5d6d5d,2024-01-13 20:47:55\n",
      "18,166,13659,200,16,poor,major injury,195.83,12.94,137.59,d147dc73-0d48-49a8-97aa-f846075153bc,2023-11-14 03:04:04\n",
      "1,196,2693,4760,5,good,healthy,82.58,14.32,175.46,e59756c7-9748-442c-9ae9-3de5e8bf359c,2024-06-16 08:34:30\n",
      "7,50,14066,3725,19,fair,healthy,110.97,20.15,86.7,394790d9-2b9f-41cb-96b6-8b244818e630,2024-07-24 07:57:50\n",
      "15,139,13647,3412,12,excellent,healthy,88.95,14.58,176.42,069a6d87-0fa8-491f-a08e-2971b2497ab9,2024-02-23 17:40:30\n",
      "1,195,5763,896,3,fair,major injury,80.93,24.28,63.26,66c1258e-fbec-490b-b283-1083f5183725,2024-06-19 13:03:44\n",
      "12,100,5595,2296,8,fair,healthy,93.81,29.25,134.58,c39a2d89-b367-4ad4-9f69-8a5cd9b8d7e1,2024-01-15 06:16:31\n",
      "2,144,13733,4242,17,poor,minor injury,121.47,6.03,188.21,696763eb-91e9-42ad-99be-f98513be17a5,2024-10-04 10:14:26\n",
      "3,80,19677,4294,5,poor,major injury,72.64,11.44,199.6,643e1f68-ea53-4877-b477-03c803e87599,2024-01-08 18:45:40\n",
      "15,148,7605,1980,16,good,healthy,195.97,14.95,144.54,63cea2ca-6cba-4c3b-ab72-3adf91023260,2024-03-08 07:14:17\n",
      "7,188,19595,3789,16,fair,minor injury,65.03,8.15,158.94,c9450b2d-a165-450a-981b-2b9dd82479e5,2024-02-12 21:42:38\n",
      "7,168,15829,4597,8,fair,major injury,66.47,15.2,64.94,5aaa03b6-5574-447b-9cee-46e79ac70882,2024-10-10 13:00:15\n",
      "7,186,13121,2245,14,good,healthy,71.55,6.94,141.36,ef77f6e3-ad37-4f15-8d90-2d69a09f3f74,2023-12-10 13:57:38\n",
      "9,116,11977,3681,3,fair,major injury,130.29,8.51,114.83,dba1bf86-75fa-4679-848b-5a49534723bf,2024-05-24 13:33:38\n",
      "9,133,15448,708,3,poor,minor injury,125.14,7.7,160.2,d9142ac7-9dc2-484f-bb08-97d8899e57ce,2024-05-13 02:20:13\n",
      "15,106,10566,1729,20,poor,minor injury,97.49,25.94,140.97,ca2b5833-84d4-47b9-b259-88a0721b8a5a,2024-02-15 03:49:07\n",
      "8,108,8890,1035,2,fair,minor injury,12.11,11.37,75.24,b3f16e65-1a76-4dba-8213-b8145af2364f,2024-03-03 08:59:57\n",
      "9,66,447,3770,17,fair,healthy,212.66,16.54,118.18,a45f4a68-f064-4f69-89fa-b21566b68fe7,2024-09-11 04:22:21\n",
      "12,51,8134,2616,19,excellent,healthy,132.29,16.0,108.19,1b9f77a8-841f-4766-a19b-44b49e3fbe7b,2023-12-23 02:53:28\n",
      "18,171,739,3885,1,fair,minor injury,80.5,22.96,95.59,4ebba73a-b3dd-4aac-9b70-a0b71d33c4fe,2024-05-20 05:32:30\n",
      "1,140,15131,2171,8,fair,minor injury,135.06,16.58,113.55,641abbcb-8e22-427e-a8c0-d0b19431b9ea,2024-06-05 20:39:45\n",
      "2,65,4191,1057,1,excellent,major injury,139.96,11.18,182.45,3276631f-9042-406d-ab10-ebe4c9ca5ffc,2024-05-14 18:05:57\n",
      "16,186,6650,208,16,good,major injury,3.93,25.51,184.56,292ea8f5-0837-4ec4-a0ce-7ac3d088a447,2024-06-27 07:14:50\n",
      "4,89,13804,3141,19,fair,major injury,58.62,7.95,124.64,9c3eaf29-9086-4565-9956-2cfe84a21223,2024-03-12 05:50:54\n",
      "4,77,19909,2707,16,excellent,major injury,42.31,13.74,75.27,e3208ab3-4ee6-4977-8c5b-ecc9a3ef167a,2024-07-01 09:07:59\n",
      "13,119,4891,2116,19,poor,healthy,213.97,14.3,160.0,a8479393-af2e-4ca5-9a2f-f4a3bad08736,2023-11-07 19:27:48\n",
      "9,185,17306,1329,15,good,major injury,67.05,6.84,177.06,ebf0168f-7305-4337-9286-25b8296a36c3,2024-10-11 20:00:38\n",
      "3,157,14679,1864,6,fair,minor injury,222.88,15.38,132.22,9a245fcb-8877-4077-a97d-432ae253c317,2024-07-04 16:51:35\n",
      "19,157,15862,3765,4,excellent,major injury,8.17,6.58,76.22,9becc620-e50a-428d-a846-3fad01e784f3,2024-03-28 00:40:51\n",
      "16,185,14605,2170,0,good,healthy,44.29,6.26,114.62,22de1016-18bb-489c-8baf-c73028bcd82d,2024-10-13 08:56:46\n",
      "18,114,9543,3519,4,poor,minor injury,21.83,14.52,186.73,0efb3c58-cf8d-4bea-a041-6e4ff0879297,2024-02-26 16:43:01\n",
      "12,193,8627,4450,6,fair,minor injury,83.43,7.64,110.07,97385198-f314-475b-b0a8-1e53d75dc321,2023-10-20 17:18:04\n",
      "7,106,2635,2901,2,good,healthy,170.24,23.17,99.21,841f6568-13ea-45f2-aa47-21d01f6602ee,2024-06-07 01:03:28\n",
      "8,79,3609,1450,19,poor,minor injury,225.47,22.71,176.02,2960d64f-2aec-42f3-8f0c-9c5318dac072,2023-10-29 00:50:34\n",
      "17,103,17169,1015,10,fair,healthy,126.72,11.91,159.49,0ca4bc25-675f-42ca-a150-d6daa3c81b55,2024-02-14 12:06:36\n",
      "13,184,8052,2286,15,excellent,minor injury,178.72,22.81,171.43,1764bb5c-3dc4-4489-883a-40a0d43c1876,2024-05-13 04:05:31\n",
      "12,97,10968,4152,8,good,healthy,15.96,23.19,187.73,7801c16f-1216-44ab-85aa-82c2d4c81b9c,2023-11-24 17:19:12\n",
      "15,119,6054,2849,9,good,healthy,35.35,18.46,71.1,340b9298-1113-4146-9fba-3f8077085ed8,2023-10-15 08:18:59\n",
      "1,62,16543,4710,9,fair,minor injury,149.92,12.4,114.08,333a8bc6-5fd6-48d7-995d-273546a7b454,2024-04-12 07:42:52\n",
      "3,85,889,479,1,fair,major injury,104.79,11.98,134.39,8ff9b879-99f9-4270-8992-6280d9bbc94e,2024-08-28 06:34:02\n",
      "11,73,3838,1422,20,poor,healthy,224.38,11.72,199.11,42a84492-84ba-4a88-b9f9-91ce5909af3a,2024-07-04 22:08:57\n",
      "9,180,5061,1362,2,fair,minor injury,194.31,14.91,110.35,c3d0acaf-972c-48f4-b607-1334b24484ef,2024-09-30 23:06:23\n",
      "10,168,16791,3219,17,good,major injury,131.42,15.52,149.37,3f677af2-b75d-4e67-8b7e-4ff4e2ce7ea5,2024-04-21 19:37:13\n",
      "12,86,7315,1327,4,good,minor injury,203.03,22.65,57.29,1773a5db-df13-46a8-853c-3482292f3ac7,2024-02-10 19:09:09\n",
      "19,131,3911,2611,9,excellent,minor injury,137.44,11.68,199.65,d89d72cb-c139-4e71-a68c-499ff364b463,2024-06-23 22:26:10\n",
      "18,69,4128,669,7,good,minor injury,150.42,11.92,52.17,48ed6699-232a-4deb-929b-1924f2bc4360,2024-04-13 06:02:58\n",
      "6,145,3327,3069,0,poor,healthy,204.91,21.8,116.12,432dd6c9-b614-4da5-8302-745e3ee10b1d,2024-09-10 00:01:35\n",
      "1,73,19440,2765,9,fair,major injury,42.19,24.57,82.68,5a9bef0c-089e-46ca-b291-f150ca1d1e0e,2024-04-21 21:58:18\n",
      "2,179,3639,3802,16,fair,major injury,50.72,16.08,145.44,c31c7b82-cc4b-4dc7-a68c-fac2749c97bf,2024-01-08 11:34:19\n",
      "5,182,40,725,2,excellent,healthy,80.01,23.07,191.77,22db00e1-8434-4809-8b38-83ad2051d5bc,2024-05-21 23:40:24\n",
      "21,141,11729,4606,7,poor,healthy,148.91,21.49,58.82,c7e60b73-3f25-4eae-8c16-6dd0afc56f9f,2024-01-10 03:54:07\n",
      "4,161,6313,2057,14,fair,major injury,157.36,14.15,84.72,2fb7ef3d-47dc-4f48-ab91-447c8be0a775,2024-09-02 06:06:44\n",
      "20,71,4318,2364,3,poor,minor injury,83.93,9.98,86.19,49236b25-e0d7-4864-a040-578240c65076,2024-03-11 09:48:21\n",
      "8,168,15074,1033,3,good,major injury,41.59,28.09,150.25,bc0f3742-bba9-4e97-ac56-bb46bfbd6891,2024-09-07 12:16:58\n",
      "19,138,14391,865,19,poor,healthy,52.65,5.25,160.77,a5544bc9-10d5-4467-ac97-34782e50e211,2024-04-12 07:53:00\n",
      "10,156,1574,3987,17,excellent,minor injury,23.47,22.86,65.19,ae267e7c-6d51-4570-a1ad-1a926a7b9fdb,2024-08-05 09:02:49\n",
      "13,57,10195,4352,4,poor,minor injury,112.17,27.87,136.48,51747663-1656-4486-bea7-a23baf04ad8f,2024-09-17 23:54:37\n",
      "19,101,8255,3699,2,poor,healthy,223.68,19.43,129.28,dfa4f7cc-cef3-476d-81fd-12c1e6e054fb,2023-11-02 15:27:44\n",
      "1,141,17851,4821,5,excellent,major injury,196.79,11.03,158.55,fccc66fe-abd5-464d-af48-7644b6d0d727,2024-01-19 07:05:49\n",
      "16,167,4749,23,5,excellent,minor injury,145.85,24.33,91.07,2b13080f-d473-42c7-ae95-5a65f7c344e6,2024-05-15 21:58:17\n",
      "6,169,19510,3072,18,excellent,major injury,193.81,19.29,94.27,efa5ab35-01fd-4c08-8a21-9a24285b3d7d,2024-09-27 10:52:46\n",
      "7,110,13629,250,17,fair,major injury,35.61,16.54,67.69,b5fdb53d-5c87-4547-b31b-f930eafb7108,2024-05-11 12:48:22\n",
      "10,200,7051,4343,16,excellent,major injury,2.66,24.83,100.32,bae27a39-fe02-4789-a8cf-89c49ed7cd4f,2024-05-16 06:41:12\n",
      "6,83,6460,4281,7,poor,major injury,122.66,28.35,135.03,4d4befce-3985-4bdf-9be3-90a8834a8bb8,2023-11-29 09:07:24\n",
      "20,170,10682,1250,7,fair,minor injury,58.5,9.17,180.5,73fb9d87-b84a-430b-9872-e6296c29cb83,2024-08-21 01:27:29\n",
      "5,188,13732,4300,1,excellent,minor injury,223.65,12.81,64.94,ae78b9e5-2f23-4b3c-9077-360788468223,2024-03-28 22:45:50\n",
      "17,97,9912,1997,13,fair,minor injury,135.44,26.61,92.28,d5c9e0d2-2697-4e35-987d-71311c733d39,2024-02-20 19:33:28\n",
      "5,129,7327,2022,18,excellent,major injury,46.26,9.3,130.99,20072827-d2c3-452e-bbaa-98ad8d182a66,2024-03-12 03:41:16\n",
      "14,187,8665,1826,8,poor,healthy,28.02,15.32,57.07,2ad202d1-b738-4361-a498-97203331753d,2024-06-13 01:10:39\n",
      "16,128,12263,446,13,fair,major injury,60.56,20.27,105.66,edabaa22-d19d-42af-9469-54c788d5a578,2024-04-28 22:00:43\n",
      "12,98,14425,4137,19,excellent,healthy,214.73,8.49,110.15,1da86b96-9d7b-4e8a-ae28-9e21ae52e75f,2024-08-10 17:43:46\n",
      "14,87,14627,67,4,excellent,minor injury,104.05,20.68,154.05,35c8a0e5-59cc-4735-a94d-db35fc9cf331,2024-01-06 09:55:35\n",
      "19,74,11916,4904,9,poor,minor injury,191.58,24.59,64.08,b89cf86f-61ab-45e3-9489-092ac17c74a2,2024-09-25 09:43:07\n",
      "6,135,2511,2993,2,good,major injury,127.57,21.19,187.26,8a2851d3-2765-460b-b588-11789f992f5d,2023-11-01 23:40:04\n",
      "18,52,8966,3559,17,good,healthy,103.82,19.06,118.36,485c0f80-74cf-428a-afe0-c71933ba6fcd,2024-01-17 19:22:35\n",
      "13,105,14222,1738,7,poor,major injury,84.79,14.0,115.24,560d37b8-e2de-40dc-be78-dcfd10a9b5a7,2024-02-05 16:22:29\n",
      "2,93,5740,4341,17,good,major injury,20.67,8.3,162.01,91f97b18-d932-4fd7-91ab-a5488039b5d4,2024-02-21 01:10:26\n",
      "14,68,3784,3162,7,good,major injury,21.53,19.59,168.72,f13c57f2-a4c0-407a-908d-721335fccdb1,2024-09-17 01:20:02\n",
      "18,96,15731,2885,17,poor,minor injury,134.89,8.27,62.04,c294c312-d57c-42c5-9a9c-c83e17a465a5,2024-02-16 16:34:39\n",
      "12,109,18650,4061,11,excellent,healthy,122.63,15.69,114.15,d12290fd-9987-4c4f-ba4f-9036e1bfc815,2024-04-21 11:39:49\n",
      "1,173,1765,603,4,poor,healthy,218.23,25.16,149.04,df019ade-9e5a-45d8-bb96-9d43efcf0136,2024-09-06 16:15:24\n",
      "10,59,18584,3452,20,fair,minor injury,20.61,28.15,120.01,06edb4da-1bd5-44c5-a09f-fcdb9d63b0a8,2024-07-21 06:29:18\n",
      "4,69,3340,388,19,fair,major injury,178.46,26.27,123.34,aea0792d-1629-43c8-8056-6835203c4869,2023-12-27 10:26:22\n",
      "8,190,7265,611,1,fair,major injury,145.73,11.23,188.77,92588409-5f74-4626-a629-a530c08054b4,2023-12-18 14:21:38\n",
      "2,126,8809,4583,14,fair,minor injury,52.46,6.16,138.4,28555ba4-9af6-46eb-9700-156b095b0d6c,2023-10-26 16:32:31\n",
      "9,160,15251,2619,4,poor,minor injury,137.71,22.93,75.47,e5d6381b-e398-485f-9508-4b65afb9cf47,2024-09-06 03:15:59\n",
      "10,95,17210,2710,13,good,major injury,49.21,5.59,105.27,df56cfb5-da48-4067-b9c5-8f1fd819d531,2024-04-25 08:41:19\n",
      "13,109,15508,3752,16,excellent,healthy,99.58,20.4,75.31,c4017c8a-648e-49f1-83d5-c3a7af5e4a0b,2023-11-06 23:57:18\n",
      "21,170,2368,1973,6,excellent,major injury,142.34,11.99,189.36,e61e596a-2d88-4835-9167-195354d0180d,2024-09-12 20:24:14\n",
      "15,158,10448,1963,17,excellent,major injury,128.77,20.54,182.42,ad0e1351-f4a2-4a5f-9a7c-4290ce63cfec,2024-03-11 17:17:17\n",
      "1,162,17866,127,13,excellent,major injury,76.84,16.3,134.57,09d7b7d8-f8a6-445c-bd56-d1ca7f92ec71,2024-07-05 10:20:00\n",
      "6,84,5333,4927,8,excellent,minor injury,198.37,5.9,153.71,2f3f7414-10a4-4655-a462-9b73a3033330,2023-10-26 21:50:10\n",
      "9,100,9678,2364,13,excellent,major injury,143.26,5.44,95.75,91cc447f-e840-4ff2-a485-f42ab4b1b23d,2024-07-31 07:37:06\n",
      "14,196,15021,872,9,good,major injury,28.18,6.65,82.39,5da32217-457b-4459-a5f7-828a890cf35f,2024-01-06 14:21:53\n",
      "9,107,10904,4182,6,excellent,healthy,170.55,5.33,104.7,9cbb81f2-c6ab-40ab-acda-79cf0a77f63f,2024-05-17 04:52:35\n",
      "17,196,755,3666,5,excellent,healthy,133.71,16.55,121.22,caa92331-2c0e-4b0d-910e-ab3d01e5f1e0,2024-02-17 10:06:25\n",
      "20,76,14195,455,1,excellent,major injury,193.54,14.39,153.95,d216ce65-b30c-43bc-8c21-3238ad0bf10b,2024-01-15 15:27:55\n",
      "16,142,1343,3831,2,excellent,minor injury,192.54,29.33,184.84,70cdb679-6b01-4177-bafb-2b2b87c084ad,2024-10-03 07:21:59\n",
      "17,178,9093,1201,11,good,healthy,160.89,9.6,117.74,24ef2027-1047-422a-89e6-bfe151ae33cd,2024-04-23 09:56:21\n",
      "13,111,17421,3709,6,excellent,healthy,110.76,7.72,189.23,1f349476-601e-428b-aabb-4d7c3a4a1dd5,2024-08-01 07:52:47\n",
      "16,159,15104,1727,8,fair,major injury,56.84,6.47,57.62,778ba479-56d8-463a-b7d1-a23034d39691,2024-01-04 18:18:53\n",
      "22,97,7597,4341,2,fair,minor injury,52.25,14.86,195.33,0f4ab35c-7f71-4ed7-829c-a56deadf8f58,2024-03-23 06:28:36\n",
      "2,124,10727,2596,17,good,minor injury,148.28,8.09,157.89,97eb3ef7-8d3e-44c4-b0d5-85c3560744af,2024-04-05 23:39:34\n",
      "1,166,18640,3331,18,good,minor injury,142.6,28.14,90.06,40580413-1062-42a8-b1b8-8e427ec9be63,2024-04-09 00:04:00\n",
      "10,166,4004,833,6,excellent,healthy,111.2,11.08,50.3,e178f54f-f83c-4772-9b81-720ab2c16fe7,2024-05-02 17:17:22\n",
      "15,123,16488,1788,17,fair,minor injury,186.34,25.6,128.42,7da43944-be74-470c-ae28-79443a3f5b97,2024-05-28 15:14:10\n",
      "11,63,1637,3714,6,fair,healthy,238.8,21.74,102.25,e9645b8f-fdc1-4b41-8da9-2ae12cb7e89d,2024-06-23 01:01:10\n",
      "20,70,8457,4323,8,good,minor injury,229.95,11.85,55.79,d90533a1-58aa-418b-bda8-8f326f8970dd,2024-02-08 04:33:00\n",
      "20,132,5796,2372,3,fair,minor injury,191.05,14.81,128.05,a5460e3d-2ae9-4f90-adb6-54d0e0db941a,2024-04-04 18:47:24\n",
      "20,138,9871,3428,9,fair,minor injury,23.94,14.5,165.89,ce8d7015-cfa6-47c1-8d3d-d0d169ab57bc,2024-03-07 19:51:37\n",
      "5,72,19393,1319,2,excellent,major injury,232.63,9.3,119.78,4b29201b-982d-412b-b94d-d19b0d7ed8a1,2023-10-31 23:34:07\n",
      "21,87,10401,3745,3,excellent,minor injury,63.13,17.44,166.07,949baf70-80ce-43d0-8152-8af35fcd4f0a,2024-03-20 17:30:22\n",
      "13,95,17228,3160,20,good,healthy,108.83,7.06,82.98,1dc56a04-c0e1-44e3-a4ed-d6dd1123ed76,2024-05-02 05:30:04\n",
      "5,143,15440,2313,0,poor,healthy,108.33,16.98,97.71,af185060-8ecd-4e7a-af1c-28aa13c7a915,2023-10-15 00:49:32\n",
      "3,194,18635,4800,20,fair,healthy,87.41,28.08,83.71,6b8c73dd-1de1-4b85-8635-1684dd19a487,2024-02-19 02:05:20\n",
      "14,129,19726,536,11,excellent,major injury,229.39,17.2,50.13,6f6fe0fc-c702-44c3-bdb0-da72a9d9eb24,2024-05-04 04:08:02\n",
      "14,81,15645,1850,18,fair,major injury,96.55,28.4,65.7,ee7a4972-ba2f-40f4-b23b-a81f4003f9c8,2023-12-19 13:59:10\n",
      "6,195,16562,1050,2,good,minor injury,228.88,15.4,195.64,af46487c-4983-4ff3-af2f-7b511383a2ff,2023-12-16 05:03:04\n",
      "22,155,19332,4971,13,excellent,major injury,131.92,16.46,98.08,ed12c6d9-f12f-4f6b-a2bf-45d3ac0c5f06,2023-11-30 18:10:50\n",
      "16,111,1586,4353,14,excellent,minor injury,237.72,15.44,196.38,3e32305f-d481-41c8-ad55-3c967977539e,2024-06-27 21:54:39\n",
      "11,141,7720,3789,3,fair,major injury,140.82,10.66,95.53,ea36b14c-94e2-44bb-88bd-0efe216b52ed,2024-04-20 12:52:30\n",
      "18,72,14252,1137,6,good,minor injury,161.71,5.48,137.36,fd494a70-c22c-42fd-8bc9-e7d9b0abb53c,2024-03-24 20:27:48\n",
      "19,156,18843,1559,15,fair,healthy,177.61,13.46,159.75,214830e1-cd4f-4f39-a78a-8a28716054cd,2024-02-20 03:42:15\n",
      "20,155,8097,67,16,fair,minor injury,108.82,6.98,94.58,7f3d5c5a-2d50-4232-9b7b-9530c7271dac,2024-02-13 18:41:23\n",
      "9,158,15988,4439,0,excellent,major injury,214.61,13.94,144.0,8bbbbefc-48a5-4eda-8846-2dd1616b97ad,2024-10-01 00:08:42\n",
      "1,146,17003,4747,5,excellent,minor injury,106.09,8.39,105.43,c58720e6-3af1-4502-b340-d9cdf43749cc,2024-02-29 11:28:06\n",
      "12,147,5487,97,18,excellent,minor injury,15.39,23.08,103.63,ec8138f9-6240-49e0-8426-de19d883c0c2,2024-08-17 17:45:38\n",
      "6,61,5859,744,1,fair,healthy,15.05,13.35,117.6,bf875fa2-dfc3-4cf0-a999-4c3c19c4e429,2024-01-11 23:54:02\n",
      "6,181,341,3183,8,fair,minor injury,160.5,13.99,89.15,74788b97-1bad-48cf-96bc-8ccdf26b7b8e,2024-06-11 04:37:26\n",
      "22,160,11653,2732,15,fair,healthy,239.35,22.11,190.27,a44fc557-7dd3-47e7-a6ac-c84c14dd948c,2023-12-26 21:51:07\n",
      "7,50,14743,1379,12,good,minor injury,203.52,8.78,97.22,ddcc4cbc-6c42-4a8c-bf27-e4f83e620269,2024-07-03 15:10:07\n",
      "21,130,19597,3356,17,fair,healthy,65.3,9.79,178.48,40194290-acb4-4de9-b7e6-2face28ee91a,2024-03-10 07:26:56\n",
      "18,192,2262,3419,3,excellent,major injury,191.02,6.22,61.59,f9d0a5c6-76b3-484b-927c-ede2fc8b3a45,2024-02-01 09:19:38\n",
      "5,102,7186,3276,18,fair,major injury,65.13,17.95,131.3,73733d81-cd3a-4054-a225-4af55002768f,2023-11-06 10:24:07\n",
      "13,147,3133,4014,9,poor,minor injury,85.94,26.35,62.19,8af974f2-bdba-4815-b7ab-a2aac57e75f9,2024-03-13 00:54:02\n",
      "12,94,17891,3224,11,excellent,major injury,236.12,18.34,199.4,5ec2d8ac-6411-40a6-9eb5-877c07bb167c,2023-10-23 16:20:09\n",
      "18,88,18084,398,6,poor,major injury,115.39,18.94,186.15,9471f33a-11f4-4ae8-937f-02d2d487db2a,2024-10-12 08:15:16\n",
      "1,140,8325,4897,10,good,major injury,169.71,15.76,86.24,d1032d87-4b8a-4990-acaf-a48596e10676,2023-11-29 09:26:00\n",
      "19,156,7994,408,20,poor,healthy,122.88,28.56,145.47,adfdab3a-4d21-4530-9637-8d52849b8b26,2024-01-26 07:21:10\n",
      "12,199,18227,773,15,good,major injury,217.72,27.69,125.77,251276e5-5e1c-485f-bc41-29135436aa83,2024-06-20 04:41:15\n",
      "11,77,11987,2982,20,poor,healthy,205.64,25.65,153.35,1e117b5b-30c8-4c17-a319-760ffe52684e,2023-12-23 03:55:49\n",
      "13,77,3806,2727,15,fair,major injury,210.68,25.69,53.55,79d140de-88e0-4c68-a9c6-cd48815595e3,2024-05-15 20:50:28\n",
      "14,199,5899,2233,18,fair,healthy,145.53,20.67,97.25,7fe88973-a742-4b11-98f0-f30df8847fb0,2024-08-19 20:12:32\n",
      "8,138,18470,2288,4,good,healthy,207.45,14.42,193.8,37cd4123-335c-4b35-ad56-b34097149093,2023-12-03 15:27:30\n",
      "11,179,7202,443,2,fair,healthy,134.85,21.03,175.03,b1324705-190b-447e-974c-4c629c30c8ef,2024-06-15 01:12:22\n",
      "3,66,2413,3591,18,poor,minor injury,64.58,8.6,188.85,ecc93b02-f5e1-4abf-ad2d-b5ef1f84b87b,2024-03-28 07:10:58\n",
      "19,87,14181,3357,11,good,major injury,70.29,28.09,187.34,175c5bb0-9725-4e04-9839-56e6a3ae0241,2024-06-04 00:39:36\n",
      "4,99,18324,2661,19,good,minor injury,142.3,5.3,141.25,a33faab2-2f9b-4963-9a08-6208482e4193,2024-06-14 13:22:43\n",
      "17,82,16222,234,14,excellent,healthy,2.31,11.08,180.53,7b921c1b-bf81-4e24-94b6-5888638d2df7,2024-05-31 23:56:27\n",
      "1,149,15314,4155,3,poor,minor injury,55.03,19.85,127.61,d6c1cee4-7a7d-4682-8b35-4c39d64238c6,2024-02-10 01:21:50\n",
      "1,149,2828,1732,16,fair,minor injury,199.78,26.31,126.89,d5438f81-8c26-4485-8422-0b2eaa4a1337,2024-07-29 19:21:41\n",
      "1,132,3268,3596,12,fair,minor injury,65.03,13.91,95.82,16594f9f-e146-4c3b-8ce0-9c5fe24b3533,2024-01-18 06:38:13\n",
      "1,134,13142,3638,0,excellent,minor injury,123.8,28.86,81.91,322dc079-54ba-4c1e-949b-4e25c453cb52,2024-06-01 14:13:58\n",
      "12,69,5205,505,14,excellent,healthy,195.71,14.92,151.12,847048ee-7937-493f-8f51-f2e43ff1055c,2024-10-13 19:06:25\n",
      "1,128,13445,1485,3,poor,minor injury,158.99,25.67,75.33,98303df7-15a9-40d8-8625-751d5fb1aaaf,2024-07-17 14:17:04\n",
      "7,178,10205,2428,12,excellent,major injury,134.7,14.44,163.35,9d0074c3-3312-48da-8d87-18bdd9fda776,2024-02-26 12:10:31\n",
      "12,145,19812,2764,13,fair,major injury,119.04,11.65,118.98,69ca3ad2-8855-412b-a1e6-721e2e3609d7,2023-12-29 03:04:20\n",
      "17,138,12042,598,16,poor,healthy,131.7,17.61,72.84,f4b83ba8-df2f-4d52-81b0-77ec445465e0,2023-12-25 22:29:09\n",
      "16,76,15183,1697,0,fair,major injury,137.28,12.26,107.63,ba235213-db6b-4792-b95d-f24fd70662c7,2024-09-28 12:49:01\n",
      "3,98,18382,1633,13,excellent,healthy,128.57,7.89,79.85,2465f3ea-2da5-4a5a-885e-aa0d692fdfcb,2024-07-07 05:47:09\n",
      "12,102,11630,582,6,excellent,healthy,119.65,14.58,178.02,ecdccc4d-cc7b-4f93-a26e-07dbf32d4736,2024-06-08 07:43:03\n",
      "9,162,9367,2201,17,good,healthy,72.69,25.01,111.02,fc172175-05fb-46e3-8609-f7ebfd40792d,2024-03-17 10:49:40\n",
      "11,187,5529,2656,7,excellent,minor injury,107.08,20.7,79.88,3bb43d13-8764-462a-9935-3d4dfb8a38e9,2024-08-30 17:39:44\n",
      "22,113,6515,4103,11,good,minor injury,158.42,25.81,141.0,dcbcd17a-d38b-4fcd-8731-3981a2a6cb3b,2023-11-07 21:31:37\n",
      "16,76,15810,2407,4,fair,minor injury,124.61,19.91,167.94,dcc74a4a-f21d-4c00-b05d-4bdee96eb68d,2024-05-29 09:51:11\n",
      "16,98,10324,335,2,good,minor injury,32.72,26.06,142.08,980fb20a-2802-46e9-afcb-62e1fa51a78c,2024-01-07 17:32:12\n",
      "8,160,15307,4242,8,fair,minor injury,15.47,9.11,90.72,ea3b722e-fb5a-4387-b566-73bc9e4683c4,2024-01-30 19:03:27\n",
      "12,118,8519,3466,12,poor,healthy,226.67,14.94,192.04,6c1d9a59-f2a2-4d43-bb36-bd692758fd0c,2023-12-02 15:16:24\n",
      "12,143,5119,1101,5,good,healthy,81.21,23.81,134.9,1ca27da4-0a04-4e5b-a268-a6d80bb3328f,2024-03-11 23:01:57\n",
      "21,95,19433,1096,9,poor,minor injury,77.48,16.72,73.42,df1de56e-67bf-4e04-b14d-e8878176989e,2024-02-01 07:27:40\n",
      "21,126,4933,4340,6,good,major injury,177.72,7.03,53.22,ec3027d5-078e-422d-8a7a-47b09a37ece7,2024-06-15 23:36:10\n",
      "15,117,1144,3815,14,excellent,healthy,79.56,8.71,199.02,6be9bebb-c674-4c2c-808e-9fb967c2605b,2024-06-24 16:47:45\n",
      "9,169,7381,4425,19,poor,minor injury,134.22,25.4,115.26,642d2166-2ecf-45ca-8891-284af32a8976,2024-08-09 18:47:26\n",
      "5,156,7557,1104,14,good,major injury,82.74,8.77,105.37,4cde9f20-b892-4426-a7a2-1739e927c8f4,2024-04-11 00:26:04\n",
      "18,53,12046,3927,9,poor,minor injury,100.7,8.11,120.2,fc7b3c34-d008-4488-aadd-b0d03c1653a2,2024-01-07 03:25:54\n",
      "9,85,19951,4856,10,fair,minor injury,197.65,22.67,121.36,e0ebe632-99f7-4eef-bfea-178baac028a2,2024-06-17 01:25:52\n",
      "3,108,11411,764,6,good,healthy,80.94,17.06,85.61,3d4c6620-840d-483b-a42b-ab23882e32af,2023-11-16 00:28:29\n",
      "12,131,8065,2541,6,good,minor injury,157.61,15.95,109.08,2f66043d-fcb5-4954-ba10-251ad13e114e,2024-08-14 02:37:12\n",
      "9,176,12812,3549,6,excellent,major injury,122.1,9.06,128.78,c4eaf079-57ae-4ba0-9e2e-fc911b68e5ed,2023-10-16 02:53:42\n",
      "20,168,7628,4529,18,excellent,minor injury,93.84,19.77,127.75,621a2549-0563-4e0a-b31e-5f76bb4b2687,2024-04-21 07:01:37\n",
      "10,149,8406,863,8,fair,major injury,107.92,19.0,51.67,35e4f33e-835e-4b21-8c36-6b178d6f4313,2024-04-10 11:48:54\n",
      "11,85,7456,1862,9,fair,healthy,22.15,10.6,174.72,582731f0-2a86-4f63-80bd-763c906f7522,2024-04-17 11:18:20\n",
      "2,185,1233,662,7,excellent,minor injury,99.45,13.86,59.32,ae5a411c-2edc-44a5-b63b-b43ef5116f6b,2024-09-23 18:57:23\n",
      "16,82,2167,2806,19,good,healthy,6.72,19.67,69.7,d3aa7418-df3e-4b22-aa29-c072505f7e6b,2023-12-20 12:56:19\n",
      "6,70,13621,1370,13,poor,major injury,137.37,11.23,162.94,a3432f43-c39a-403d-a608-9ad21eca16c4,2023-10-31 00:36:56\n",
      "10,122,1890,866,0,good,minor injury,60.87,23.91,143.8,1f589624-970d-4596-bd69-28616beeccba,2024-09-29 06:11:23\n",
      "4,184,8448,3120,6,excellent,healthy,165.53,22.68,80.32,e9ebbdff-9803-41e9-9e9f-e45a066f7850,2024-10-03 12:56:47\n",
      "6,178,2895,2415,13,fair,major injury,132.96,22.86,154.75,831b3670-e1b3-4324-9737-f62078b86796,2023-12-12 18:38:17\n",
      "18,181,11087,3463,13,good,minor injury,120.06,21.09,179.61,21754c19-affb-446b-9072-11355b5a8101,2024-07-28 15:10:26\n",
      "17,157,10632,2004,1,fair,healthy,125.01,22.45,143.23,9420c9f8-db8a-4361-ac76-bf7959b36498,2024-09-23 09:40:34\n",
      "19,194,3961,4677,19,good,major injury,110.77,16.27,58.51,5731b8a3-977f-42cf-90c3-6fa814462b2e,2024-04-20 14:44:50\n",
      "10,56,17850,1349,12,fair,major injury,164.24,22.19,182.84,ec50a258-d5d6-4bd3-85d9-7c6c00949152,2024-08-11 16:00:21\n",
      "9,141,14129,403,3,excellent,minor injury,193.23,27.34,174.58,f7797cca-2819-4add-8425-59be464c9b8e,2024-06-23 15:10:59\n",
      "16,194,17494,1045,6,poor,major injury,10.19,17.04,90.92,072ad9d5-b899-4909-bb5d-c33458b63624,2024-01-05 23:10:31\n",
      "17,103,17708,749,13,excellent,healthy,163.34,23.77,117.58,187e045b-7db5-45c0-9efb-30581b51fb93,2024-02-17 20:45:42\n",
      "5,133,14869,4496,3,good,minor injury,35.62,27.69,174.0,a6c7e213-03e9-4ce9-82ef-cc3fc0a468ea,2024-06-25 20:30:30\n",
      "18,185,3195,183,12,fair,major injury,24.88,20.03,72.86,a655e03c-8c72-4296-9f8a-c5a745da9489,2024-03-08 09:55:40\n",
      "10,165,13233,612,5,good,minor injury,66.2,5.33,57.5,f62d1b1f-a100-4f48-91cf-4628c2ea0d0e,2024-07-09 18:28:35\n",
      "6,125,10840,1244,16,fair,minor injury,85.9,9.54,171.56,5507f617-538a-4c5e-a2a9-1acc8a584ca8,2024-09-08 01:08:56\n",
      "10,163,14524,4337,2,fair,healthy,71.41,29.23,164.88,47a6c890-69d2-4879-991b-060def89971f,2024-05-19 17:18:22\n",
      "6,71,14460,4741,1,good,healthy,198.89,13.35,126.53,22e4e5c3-bc9d-4f1c-a06b-3f6f06e7be37,2024-10-13 03:51:11\n",
      "18,107,13776,2752,3,excellent,healthy,31.08,13.67,154.81,8bdcc784-f6f2-44ff-ba2c-f69782e8403a,2024-04-29 19:08:33\n",
      "15,144,12577,2786,18,fair,minor injury,88.1,25.54,58.86,86275f38-13e2-49cc-aa89-acf9ca841bc1,2024-03-10 15:04:47\n",
      "15,175,10584,3264,2,good,major injury,238.55,16.81,75.69,4f78717f-18df-4c15-a2a0-0a36e50dfeae,2024-02-26 12:51:08\n",
      "9,50,947,1994,17,fair,minor injury,60.79,15.07,196.9,2a84d593-2c8a-402d-931e-fd193330be63,2024-05-14 03:38:34\n",
      "2,76,10068,2398,9,good,minor injury,229.35,16.56,196.41,98ed0925-a735-43b7-84c6-361f2fdda3c7,2024-06-30 05:26:48\n",
      "19,71,6639,3453,16,excellent,major injury,203.28,16.91,193.03,a8eb2613-9652-4885-8a30-cd78e8a26306,2024-07-01 05:21:08\n",
      "17,84,1550,1663,16,poor,major injury,162.27,16.78,140.61,2853a392-cc15-4bcd-b671-54cc7e8fae42,2024-04-15 14:05:27\n",
      "11,52,16727,2049,10,poor,major injury,138.62,19.83,168.92,2665891c-5920-445b-918c-605776213e2a,2024-02-06 02:36:29\n",
      "17,58,17724,4751,15,excellent,healthy,60.25,15.71,88.21,f7e93662-7f4f-4ade-9412-371afd197cd7,2024-01-22 03:10:41\n",
      "4,137,13265,1914,2,fair,major injury,45.2,16.34,72.74,19589ebf-c72c-480f-ba89-51a0bbe02522,2023-11-19 15:01:51\n",
      "14,158,1794,3156,14,good,major injury,35.49,7.12,66.52,1edb75a9-7fbc-4b64-a4bc-0d744aa75b1b,2023-12-13 20:30:54\n",
      "15,190,4348,4752,6,poor,major injury,166.89,16.04,190.43,af89c19e-b3a5-492e-be33-5e72719641f1,2024-07-31 02:37:50\n",
      "19,75,11375,4787,16,excellent,major injury,11.25,10.53,183.61,1db640ae-f647-490e-abda-00d2fe5476fe,2024-05-30 06:36:30\n",
      "13,137,19383,805,9,good,major injury,154.64,17.2,146.03,73a8e1ba-d4ab-403e-a6d6-253255a35c3e,2024-04-23 04:50:04\n",
      "18,78,18982,2446,6,fair,major injury,122.37,10.91,81.16,3c294e09-fab3-4990-b1bf-7aa5c1304a31,2024-05-26 02:15:17\n",
      "17,162,13864,2423,20,excellent,major injury,202.39,8.58,143.85,dbdcb2cc-438e-4001-b801-c6ad7ae3699d,2024-02-27 16:27:29\n",
      "7,52,9185,4279,16,poor,minor injury,47.43,5.54,176.2,d77fb4ad-1c4c-472f-9c0e-597e89529a6c,2023-11-05 03:47:03\n",
      "19,142,7978,4071,3,good,healthy,185.69,13.16,54.52,b50e7d91-9fff-46c8-9bf7-e56bdb1c4b7e,2024-02-27 17:51:27\n",
      "2,107,7705,3855,19,excellent,healthy,147.45,9.22,116.22,f8a627ee-e6f8-4f21-8e21-75b0be98ef43,2024-01-08 19:19:46\n",
      "8,67,12245,4493,7,excellent,healthy,130.24,18.31,95.78,06d3f153-8958-4c5a-b16f-e420f0fee81b,2024-04-24 08:42:04\n",
      "11,70,5698,4030,4,poor,healthy,107.54,15.45,173.45,d102be4e-3cfd-4f7b-b226-305519f74f71,2024-01-08 16:24:10\n",
      "15,66,6452,1455,0,poor,major injury,146.39,21.35,123.48,491feaca-9d93-4366-bf3e-1754f2fba55c,2023-12-16 20:42:14\n",
      "8,171,5070,3757,14,fair,major injury,68.48,11.06,86.96,381c80f2-fe3c-402d-a8c7-c30cce775082,2024-10-13 14:43:28\n",
      "17,108,18428,239,17,good,healthy,219.69,24.19,149.27,2f3390c1-3ef4-4a48-a377-f537243e98d9,2024-01-14 13:01:24\n",
      "10,110,10193,4553,5,poor,minor injury,228.81,5.57,69.6,f4e6283b-d79e-4ebc-8dc0-e5a008a25004,2023-12-22 22:28:23\n",
      "21,51,5255,4600,8,poor,healthy,100.77,6.7,166.77,5cb3eda4-b21a-4daf-94ae-f48223824111,2023-12-06 04:17:16\n",
      "16,88,15365,1121,13,fair,healthy,217.71,19.04,75.22,dcdff09e-8610-47c3-a4fd-9315f649e74a,2024-02-19 14:20:13\n",
      "20,137,10941,3093,18,fair,minor injury,139.22,12.56,119.8,4fcd475a-d031-41eb-b041-f4a85e883b39,2024-03-06 02:48:14\n",
      "19,180,8174,3242,17,poor,minor injury,38.64,17.21,101.49,8d66884c-1622-48a3-a5ee-8c3bb9f28982,2024-06-23 19:13:11\n",
      "4,160,4882,3082,4,poor,healthy,93.87,26.02,173.25,13e14b2a-0e92-4f2e-9d8c-6b787cf2ae66,2024-08-09 00:25:50\n",
      "12,182,3543,1849,9,good,healthy,68.6,21.12,52.51,33f3e01a-2bc4-4756-b795-12b3ab29eb3a,2023-11-01 05:59:19\n",
      "9,89,17961,4585,19,fair,healthy,183.33,16.23,145.89,04d959ad-a94c-4ff9-9bbb-5d4d23b136b1,2024-05-23 08:15:05\n",
      "20,185,134,3209,3,excellent,major injury,229.38,25.11,160.43,bedb5b5a-eb99-4adf-ade1-51d74cbcaa22,2024-04-05 18:33:31\n",
      "11,117,356,1245,1,good,healthy,192.25,18.88,116.3,c2b6c802-3023-46b8-adde-c79d0788a415,2023-10-17 14:29:59\n",
      "13,142,8045,4555,8,excellent,major injury,2.74,10.52,97.66,87c26422-1814-465d-b4a8-9abf78f1e5e9,2024-09-09 17:19:20\n",
      "14,181,11022,4042,7,good,major injury,96.68,19.14,124.72,c03af11f-c6b3-4320-ba48-078e032fb853,2024-01-21 12:53:05\n",
      "12,120,2478,1150,5,good,minor injury,116.37,11.06,64.29,1dd1a184-47d0-4642-bc8d-7e6eec638920,2024-06-20 10:31:05\n",
      "20,73,17183,3317,13,poor,healthy,70.84,28.45,137.72,b0271649-6b5a-4397-861c-5b62f8873e65,2024-02-01 14:46:04\n",
      "8,61,5959,1032,11,fair,minor injury,167.06,7.84,116.98,288f8c7d-ca3b-485a-adcb-dc60b83f5a16,2024-01-17 11:19:27\n",
      "5,190,8917,2969,13,excellent,major injury,43.62,10.96,107.78,78643090-484a-46aa-9ebb-76991410cb6a,2024-10-07 04:30:27\n",
      "12,124,17139,4378,20,excellent,major injury,113.52,5.39,88.32,7cf3cd25-647b-4fdb-a3af-17591e09eb91,2024-02-14 07:01:33\n",
      "11,88,6005,3146,4,good,healthy,106.28,18.47,95.38,9088d437-2a54-47a4-83cc-77dbea03fd18,2024-02-17 19:13:29\n",
      "20,166,17515,2479,16,good,major injury,100.44,20.51,115.93,dd72e3c3-a153-454a-963c-a1ffcde39c85,2024-01-01 08:06:36\n",
      "9,135,5254,3873,16,fair,major injury,109.96,17.91,57.21,c2ab48ba-8a6e-4a65-818d-9b254578002e,2024-04-11 01:29:53\n",
      "4,57,15279,4885,20,excellent,healthy,124.65,8.74,175.17,7699486e-f419-44eb-a3bc-c50a51bb7440,2024-03-23 16:00:37\n",
      "1,128,11688,4297,15,fair,major injury,223.32,6.97,174.97,606dd79b-c3f1-4914-8cd5-26aefdfa572b,2024-01-13 22:36:53\n",
      "18,80,9759,4178,12,poor,minor injury,66.96,13.14,165.98,85b0e761-596d-4605-8dab-c76db234a697,2024-05-08 01:34:01\n",
      "9,195,5933,3879,14,good,healthy,4.1,23.53,114.68,08678f25-ef6f-4ee5-9746-12b4130bc8b9,2024-02-10 09:23:42\n",
      "3,100,10647,697,14,fair,major injury,108.61,20.82,172.81,c68c042c-bbed-4ac8-aac8-d89948c701c6,2024-05-20 00:43:22\n",
      "3,83,13715,72,5,fair,major injury,115.07,15.36,56.41,f447b746-9122-4312-a417-06ae7c48464f,2024-03-11 04:44:36\n",
      "6,125,16154,4063,14,fair,major injury,19.82,8.98,161.74,528db23d-4101-48dd-8b97-1b10879b4e88,2024-03-30 14:39:32\n",
      "6,199,18348,3355,18,excellent,minor injury,228.66,24.19,143.05,edb3da2c-7c83-4a0d-a734-7816001621a2,2024-03-11 12:59:42\n",
      "15,143,1455,1602,1,excellent,healthy,2.69,22.87,74.24,68849f95-02f6-4c84-8c26-be882b336798,2024-01-08 21:09:57\n",
      "12,164,10970,199,6,fair,minor injury,238.29,11.09,120.06,9939ab2f-8bbf-4ac8-96f1-a7a330ee355f,2024-03-27 13:53:14\n",
      "3,191,12310,4289,1,excellent,healthy,13.73,24.07,179.66,588cb27e-1735-4d9e-a8b6-b20210813664,2024-09-24 04:07:42\n",
      "20,86,4036,3358,0,poor,major injury,140.52,28.92,74.32,e525bd23-e86a-4244-a4fb-4bef98f91dd7,2024-04-25 18:03:22\n",
      "5,137,17498,607,14,good,healthy,104.88,29.71,187.57,26616590-140e-43c1-9d62-7266873572e6,2024-02-21 00:40:47\n",
      "9,121,7835,692,17,poor,minor injury,50.38,20.0,167.37,c6bbad33-5a96-4498-ad96-dc6cedc1987b,2024-04-02 01:47:42\n",
      "11,189,1182,4885,9,good,minor injury,96.34,23.79,51.27,6b226b8a-4513-47d7-9de1-16ae360686f0,2023-12-07 21:17:09\n",
      "17,151,17109,3286,2,poor,minor injury,158.72,23.28,195.41,f0b9317d-e21e-4ef8-8e0a-b021855c8d19,2024-02-15 11:09:19\n",
      "14,68,18477,2962,1,fair,major injury,75.42,25.28,101.72,3a74265e-0e19-4524-8aa1-b9e85beb2720,2024-01-25 07:07:09\n",
      "9,69,5887,645,3,good,minor injury,78.9,5.87,142.36,4b8f6b42-726d-451e-a345-2215d3ed2b93,2023-12-05 11:07:44\n",
      "13,114,595,957,10,fair,major injury,46.86,16.68,52.38,370ee2f7-fc9f-4efc-b65f-d90e1f3431a4,2023-12-10 18:22:07\n",
      "7,142,14777,2439,18,poor,major injury,19.2,9.9,74.54,4e86e175-cb11-4925-8ad2-218f7722fb46,2024-08-22 01:25:55\n",
      "13,195,3003,4231,10,good,minor injury,134.25,7.34,158.06,0a4da15f-c079-4517-bec2-86e89ed8fd3b,2024-09-27 02:12:02\n",
      "5,112,6506,4829,3,good,minor injury,185.42,24.39,188.04,f4c93813-4b42-4536-a480-d5a8528a020b,2023-11-09 18:13:14\n",
      "9,86,5974,1894,10,poor,minor injury,217.05,23.48,193.8,e814c1a3-e7e5-49cf-a1ba-df3852555a0f,2024-04-26 11:36:05\n",
      "17,196,6396,434,13,poor,minor injury,187.91,8.82,83.25,d7ca0c3d-134a-47c5-ac3e-a6171ff8c200,2024-07-24 16:36:45\n",
      "11,174,1042,3367,6,fair,healthy,37.74,23.87,151.25,21dc5b7d-fc00-4f15-81ad-f1a099ba6009,2024-06-22 12:27:53\n",
      "18,146,2329,3150,12,fair,minor injury,43.49,15.53,109.56,c6a4e2f0-d2f7-44b5-b3f7-fded3ecca57f,2024-08-19 17:19:35\n",
      "14,133,16988,3064,16,fair,major injury,108.09,10.5,90.54,5ea434dc-84e3-4006-818d-05328a7b6806,2024-01-22 21:37:06\n",
      "13,158,16728,1268,18,fair,minor injury,198.55,29.66,166.24,772e863b-e1fa-401a-a178-23358db04939,2024-08-20 22:06:17\n",
      "7,147,9903,3025,9,excellent,major injury,70.09,18.52,93.69,1b4396c1-8c4c-47a8-acd3-1e5441bc1a01,2024-09-22 11:49:45\n",
      "20,77,6770,318,2,poor,major injury,128.92,9.58,178.52,f1b9a156-f9bc-478d-9313-cb54522d7f33,2023-11-14 10:29:35\n",
      "14,196,6182,4151,12,poor,minor injury,158.91,15.11,200.0,e5b9a651-6a6e-4eee-b63c-31c517f4b618,2024-10-08 17:51:43\n",
      "15,61,3162,3272,20,excellent,minor injury,9.13,17.35,197.26,39f0b75f-14f8-412b-b542-9d1a438ffe27,2024-07-14 10:05:17\n",
      "11,139,430,1720,16,good,major injury,138.72,17.82,58.85,81b70633-b640-4dd8-b6b0-7df3ddb3cd0d,2024-07-30 02:50:07\n",
      "3,97,4463,791,9,poor,major injury,218.82,27.81,62.11,ae4d678d-765b-48e6-b758-1752bc58ac52,2023-12-28 12:55:09\n",
      "8,82,14541,3308,16,excellent,minor injury,149.18,27.63,159.64,69d8d054-861b-4df0-bdca-4b73470cbbab,2024-03-15 02:59:22\n",
      "9,155,15023,3340,0,good,major injury,27.19,7.6,184.52,64c154bf-0505-4a08-813a-9404b85c2bc8,2024-01-01 16:28:06\n",
      "19,163,6596,3311,9,fair,healthy,67.11,26.78,171.3,046b3e9c-a8be-4174-9a89-f0a216e55621,2024-07-23 19:35:42\n",
      "18,51,16108,2973,19,good,minor injury,205.63,20.5,116.03,2ab053f6-15f2-4d47-8335-8989b9cbf67f,2024-08-24 01:51:41\n",
      "13,169,18478,4162,7,excellent,healthy,118.94,21.08,153.12,1b62bcf3-b269-4806-998e-5742b9e75b42,2023-12-25 14:16:17\n",
      "16,170,3041,111,17,fair,major injury,177.34,19.13,162.68,69976b60-fa28-4c4d-861b-cf41b55f9c78,2024-01-05 10:37:54\n",
      "18,169,13076,4752,4,good,healthy,189.13,15.4,84.71,9aa6923b-8f4e-4e06-a5b9-81b308e5932e,2024-02-08 00:19:09\n",
      "16,123,5155,1268,9,fair,healthy,153.43,9.84,154.2,d77b6419-6c77-4042-b0ec-616b10c4c209,2023-12-05 19:30:06\n",
      "6,91,9037,922,1,excellent,major injury,130.01,17.25,132.49,8d62ab4c-e14a-45c7-9ee9-86e9d9539a86,2023-12-06 21:44:16\n",
      "8,176,1800,2481,12,poor,minor injury,235.21,8.88,79.1,19cfc4b9-df80-41c8-835d-b4d9679d08ee,2024-08-22 03:32:43\n",
      "10,162,3642,3769,1,excellent,minor injury,64.87,26.09,187.68,b86b2cc5-5b2e-480a-adcb-de374f1bb053,2024-09-29 01:57:56\n",
      "10,129,1755,2081,9,fair,major injury,196.58,27.08,196.5,78e8746c-3a47-4f2c-8d9a-b005231cae8d,2023-11-01 08:26:06\n",
      "3,194,19575,4032,19,excellent,major injury,87.7,20.28,56.72,3fe97527-3216-45e6-ad63-86e8a49113fd,2024-02-14 03:14:56\n",
      "7,199,2065,1536,11,fair,healthy,139.01,18.39,71.77,3e187046-aaea-4aef-8b97-8f106ca4c130,2024-07-30 05:04:04\n",
      "20,196,10394,1752,0,poor,healthy,15.41,25.02,194.74,7b0fa0cc-af60-467c-a5a8-62cc5ea3f7dc,2024-08-15 15:00:19\n",
      "6,132,5601,1448,16,good,healthy,178.98,17.58,159.34,d4d8bcae-58f9-4214-bde9-08e76eaa8c50,2024-07-13 07:10:09\n",
      "20,82,17644,4152,4,poor,minor injury,77.2,18.1,151.41,94f67604-6c3a-478d-8c9c-bb9f6ad026d9,2024-08-02 21:40:07\n",
      "5,59,8630,2399,2,fair,healthy,25.84,16.45,133.74,a5357791-5fdb-46ee-bb49-735b2e7d7066,2024-01-18 01:46:57\n",
      "9,101,10242,1838,4,excellent,major injury,82.08,24.37,182.3,4134bd9e-ca40-422d-b603-7056ce4e2a71,2024-01-20 14:13:30\n",
      "21,145,132,1349,13,fair,healthy,72.21,23.53,126.44,d760514e-3d78-4f5d-84d8-9c7faa2aed2c,2024-01-14 07:41:36\n",
      "4,166,6277,1791,17,fair,healthy,26.08,15.31,126.99,4ba087ba-c9a5-421f-abef-7514431c42ac,2024-04-06 07:21:32\n",
      "4,197,8000,4987,18,excellent,minor injury,152.6,9.94,123.94,1ffe9da1-cff1-4177-8ca2-21a73d0d6378,2023-12-03 11:11:27\n",
      "18,154,356,4784,0,fair,healthy,214.35,24.76,70.17,47fa3443-b9ea-4782-9287-37a551b49ac6,2023-10-25 10:30:20\n",
      "13,94,6304,1762,13,fair,minor injury,186.58,6.56,128.36,95a8a3ba-aa44-49ab-96df-cedd34d8a42b,2024-03-25 11:38:30\n",
      "19,92,7920,2104,0,excellent,major injury,131.07,24.19,125.66,7beecdbd-f5a4-4559-bbd6-5334ddf18a5d,2024-04-06 06:40:23\n",
      "22,78,3352,461,3,poor,healthy,72.85,19.97,72.72,89fca9f8-8928-4ea7-acdc-9be10042c65c,2024-04-21 02:29:40\n",
      "1,137,228,1375,19,excellent,minor injury,225.4,17.22,82.39,381b5ac6-dbf6-4f59-aab1-949b1107f55e,2024-09-01 21:23:28\n",
      "18,146,15153,828,15,fair,major injury,203.97,23.9,181.17,1946aaa8-1bb2-4ade-8ed4-ec73766ba5de,2024-03-13 05:41:40\n",
      "15,156,2953,4270,1,excellent,major injury,119.04,14.03,79.9,a9b2d37d-8221-4943-834e-e1d62f540613,2024-01-06 19:31:28\n",
      "7,101,16990,2449,14,poor,major injury,239.15,14.03,147.04,4c063ffb-a323-48c2-bcd5-1825a6411a23,2024-01-16 12:41:03\n",
      "17,165,4534,313,9,fair,major injury,15.59,26.77,90.56,d2ce61da-6e2d-4425-ae06-9337000eb1cc,2024-02-24 17:34:25\n",
      "3,88,7327,2371,15,fair,minor injury,230.17,27.68,85.87,cc28fd8b-028d-4bc9-817e-3f9fc5e9407b,2024-07-08 22:51:09\n",
      "21,157,8098,475,17,good,major injury,5.51,7.06,114.21,149fcaa5-b2c6-459b-91d2-0553ce6c9e36,2023-11-10 11:01:50\n",
      "13,144,7107,1821,0,good,major injury,167.17,24.29,146.71,e890ef89-1492-4932-8de6-4da5bc7e58da,2024-03-27 16:54:53\n",
      "7,162,15626,2711,8,poor,healthy,56.3,19.56,162.49,cb3bf7ac-6ba2-43d3-9a89-51acf0c67322,2024-10-13 05:07:12\n",
      "12,121,9472,1634,10,poor,major injury,108.69,12.17,174.68,c0045f51-01eb-49bc-8340-f98d9abd2c40,2024-01-06 17:47:15\n",
      "6,98,16717,3049,0,excellent,minor injury,167.22,26.41,177.78,64c67057-36c7-47e8-962e-5409eeb71105,2024-08-16 01:32:38\n",
      "13,151,10058,4191,20,good,major injury,44.78,9.27,156.77,371ff11d-9eeb-4450-9e10-2355d6531152,2023-12-23 20:19:46\n",
      "18,168,11954,1263,1,fair,minor injury,56.25,23.68,81.35,331e11e9-22a0-4c55-914b-a0c678640693,2024-06-20 06:28:47\n",
      "14,166,952,3655,6,poor,healthy,23.09,15.32,101.2,fd1b2582-f813-4148-bfee-a0745d35fd95,2024-06-06 00:26:31\n",
      "8,189,18980,560,16,fair,major injury,183.92,7.02,80.73,15d20e1a-d2e5-483d-ab95-d7943f66124a,2024-03-15 17:44:13\n",
      "1,155,18512,4433,4,good,major injury,60.31,16.75,150.73,9dc537f3-e06d-49dd-bd9e-1c1f7815e0d1,2024-03-05 01:43:15\n",
      "21,111,8223,3705,11,fair,minor injury,121.33,6.62,70.16,2afce5db-733d-4e55-b1dd-348624eff4ef,2024-09-16 17:13:26\n",
      "14,190,1871,3104,2,excellent,minor injury,225.02,21.08,179.36,7afde63e-076b-4279-9a2c-ecdf26d03714,2023-10-18 22:32:45\n",
      "6,108,3878,1800,2,excellent,major injury,178.9,7.06,92.27,53f4ce83-2961-4a7e-a6e5-d2f1b4ec0fa3,2023-10-15 02:39:46\n",
      "5,154,7645,4893,13,excellent,major injury,12.39,25.0,144.72,47e56beb-5c54-4332-9a6e-4fb9891c95b0,2024-06-11 19:33:10\n",
      "1,90,19163,836,19,good,healthy,82.82,20.1,107.05,e575bf3c-5231-4143-9b08-16e5405bcb65,2023-12-12 16:19:06\n",
      "16,68,14949,736,16,fair,minor injury,41.85,13.08,73.66,40fa54d0-d074-410f-86f2-55b1799585a8,2024-09-24 09:41:04\n",
      "5,112,10362,1330,1,excellent,minor injury,128.51,16.9,58.0,640df58a-4a6e-4ba7-886b-464c6dc69cbc,2024-02-22 03:01:29\n",
      "4,110,9872,257,5,poor,minor injury,215.16,21.98,177.71,1fa4b234-4315-4b9d-bc65-c3254edb7443,2023-12-31 19:04:45\n",
      "21,191,14080,1935,20,fair,major injury,86.42,12.69,59.24,b2ffd43e-9a8b-455e-b60f-c32f280d9ee9,2023-11-23 03:14:49\n",
      "16,177,4227,1627,9,fair,minor injury,74.75,7.02,133.89,61e25d23-1964-45cd-b5d6-13e50df2fbe9,2024-07-01 06:18:27\n",
      "7,174,1227,958,15,good,major injury,188.53,22.73,95.33,74af5c3b-4d79-44ef-976d-079374db5846,2024-02-09 18:04:18\n",
      "15,150,10828,964,7,poor,major injury,179.41,14.73,94.47,77cd7c92-37b7-4a16-9f62-78d58bfbb6b8,2024-06-08 15:06:22\n",
      "17,153,10453,400,3,poor,major injury,202.45,14.67,184.01,4491e641-9d05-4269-b89c-1bdc8d143334,2024-09-10 08:50:39\n",
      "21,177,19170,538,12,poor,healthy,153.46,6.42,130.18,8ebd822c-5a41-4823-a479-1151c1088248,2024-01-03 19:14:38\n",
      "12,107,15851,4039,19,poor,minor injury,205.18,17.85,142.61,ac507eb6-55d5-4ce6-b614-ea2d0e15a578,2024-02-23 05:56:44\n",
      "10,147,18066,1060,9,poor,minor injury,179.22,19.68,132.55,ca291bbd-dd97-4019-9120-9eb295959dd9,2024-07-22 23:04:57\n",
      "15,158,7297,747,4,excellent,healthy,235.56,15.76,77.11,7d7178a7-e1d1-48f6-aae8-87a2a0d22460,2024-06-26 22:58:09\n",
      "16,195,12802,2376,12,good,minor injury,221.72,10.05,124.78,ef418b47-24ed-4635-8c0b-95806626d378,2024-07-30 16:27:07\n",
      "18,74,10832,1824,1,fair,healthy,181.47,26.4,168.84,b3c297d1-bc75-4893-b78f-ee2499be07a3,2024-05-19 19:10:27\n",
      "16,99,17025,4342,0,poor,healthy,148.33,16.43,179.45,42cfb429-ae72-4fae-8226-55bb1989c2b9,2024-04-15 22:32:32\n",
      "22,89,2697,4522,7,excellent,minor injury,144.97,29.16,162.27,a633b4c0-5b5e-43af-86cc-1c7c6a036902,2024-04-21 06:53:20\n",
      "12,151,5479,2216,16,fair,healthy,45.68,25.13,136.63,7e622e1a-de42-44a2-ba87-888e90de11c2,2024-01-09 07:59:43\n",
      "17,94,6727,3557,4,fair,minor injury,208.08,20.85,97.7,93c0075a-541c-4bb8-92da-5e0affe5e6e3,2024-06-20 07:57:17\n",
      "21,108,19641,2241,10,good,major injury,206.85,26.63,87.17,ee2491af-cbe8-41db-a841-0dccd94fcdd6,2023-12-21 00:11:06\n",
      "14,88,19191,1478,19,fair,major injury,210.34,19.74,79.67,634e115d-cb0f-40f1-bf72-010722fe087e,2024-04-01 21:43:24\n",
      "19,163,4123,3437,9,fair,minor injury,28.8,18.59,114.3,f9103404-fce4-468c-b12a-1ca71c5a39be,2024-03-10 09:43:38\n",
      "19,108,15772,2425,17,good,minor injury,38.85,23.3,168.26,eaa7133e-c469-40f6-acd2-918e83aab54a,2023-11-17 08:17:37\n",
      "9,176,12450,4033,8,poor,minor injury,120.44,22.57,148.19,72869964-b837-496a-ad7c-7f5cbd93bac6,2023-10-30 15:20:41\n",
      "4,142,11664,4726,13,fair,minor injury,88.9,5.76,95.16,a80597df-cf34-4ebe-9807-64083d1a98aa,2024-08-30 04:16:36\n",
      "17,82,7661,2945,2,poor,major injury,67.64,11.65,154.89,8e6ff53c-0069-4c89-aaf7-10d349a6951a,2024-05-29 17:23:00\n",
      "9,111,513,1085,17,good,healthy,113.73,20.28,186.94,b8699182-e5e3-4964-aca8-7137726d74e3,2024-03-11 06:55:45\n",
      "19,186,12980,1325,5,poor,healthy,67.83,23.72,78.55,1d5024e3-f83d-4e53-986a-c4a55f2aa651,2024-05-18 03:13:06\n",
      "10,167,7738,1055,9,excellent,minor injury,164.39,28.41,64.91,f801c167-daf5-454f-8bed-790832090f67,2024-07-18 01:31:48\n",
      "12,99,14731,4356,5,excellent,minor injury,92.99,15.86,51.47,0c681dd9-d112-4c73-aed7-521a64037a35,2024-01-18 23:43:50\n",
      "5,153,2981,1017,17,excellent,minor injury,33.39,16.63,126.65,563726f7-6a79-45f6-88b9-baf77a9a561f,2024-02-20 23:29:46\n",
      "22,178,11372,4650,4,excellent,major injury,204.01,22.15,141.73,120a3aaf-1e74-4171-83d2-df1ff299f420,2024-10-05 01:23:23\n",
      "3,124,9947,2727,14,fair,major injury,236.37,11.41,155.37,88638b4a-5b16-4449-819f-e4f4279d9ca5,2024-02-04 01:28:18\n",
      "18,155,4801,549,14,good,minor injury,52.12,7.01,136.19,db5cdaa2-180e-4fd2-a0fe-75e42a9bcee1,2024-05-17 05:58:44\n",
      "20,132,17249,4932,14,fair,major injury,95.27,24.83,141.53,cac1fee8-4bae-4c29-bce8-89bc4e2230c8,2024-07-12 11:29:23\n",
      "6,147,14907,4729,7,good,major injury,178.99,20.6,114.78,faa120c9-ba43-4988-961a-b5a17a433242,2024-03-05 16:58:10\n",
      "14,63,2578,1862,17,fair,healthy,104.89,9.98,53.57,fe0e0938-782b-4e3d-8825-8bd4ef9b7189,2024-04-26 17:22:03\n",
      "20,90,15932,1397,10,poor,healthy,179.33,11.74,145.92,5c8950c9-cb09-4b0e-9d35-47e05d86ca75,2024-02-29 00:12:17\n",
      "6,159,8378,468,10,good,minor injury,2.28,23.16,167.22,e715de37-d7e2-47b0-8921-e07d4b35bf89,2024-03-31 11:37:56\n",
      "19,143,3106,3550,16,fair,major injury,92.74,7.34,169.06,0448162d-ad9f-4b29-b2d6-6fef57139a50,2024-07-03 22:22:25\n",
      "19,148,3209,3821,3,fair,healthy,164.02,12.83,170.87,766e5203-4062-446f-b175-8ce383ff8a78,2024-06-30 19:13:19\n",
      "17,193,16382,3504,13,poor,healthy,202.8,18.59,63.8,1d6914e7-5551-424c-bff6-70ed33e9f4b1,2024-03-27 08:48:52\n",
      "2,146,17999,3738,15,fair,healthy,161.65,15.16,155.28,6f9ed136-f30f-4a54-8c1c-6decaebee015,2024-09-29 01:38:03\n",
      "6,61,8228,4875,14,fair,healthy,144.52,22.64,57.83,c69b5b51-a56a-4af8-9d29-0c31ec63419a,2024-04-25 05:40:38\n",
      "6,188,5274,765,11,poor,minor injury,127.32,18.94,140.16,a50ee48e-d643-4a40-8136-c085f2618d1b,2024-03-12 05:33:08\n",
      "20,177,1158,4991,17,excellent,healthy,72.51,13.8,66.94,b2857f65-3978-4b9f-b37c-c315f9c524e7,2023-11-11 01:49:09\n",
      "11,142,12256,4047,10,excellent,healthy,37.15,10.2,63.84,993c3610-fe70-4298-8d75-b20ac9c8f6f8,2024-08-26 13:29:29\n",
      "17,139,8536,2021,6,fair,major injury,42.21,13.72,119.11,4d0bfbff-f021-4db8-82b3-2be7cb0f2169,2024-04-07 16:02:00\n",
      "18,71,3270,438,15,poor,healthy,11.48,19.27,141.18,35d7601c-9aea-40d8-b5c5-b9d8c3ee059f,2024-07-17 08:17:30\n",
      "2,94,1864,3023,2,poor,major injury,180.47,21.52,186.65,2b38e287-9957-49e3-b085-69f854b55a1c,2024-01-10 09:40:16\n",
      "5,148,3945,4299,12,good,major injury,15.29,29.68,149.51,a85dde0e-9016-4aa0-b646-64aefd7ca560,2024-08-30 12:53:34\n",
      "22,115,2877,594,10,poor,healthy,67.6,9.75,149.4,11941128-2570-490b-a7c1-ed15005f7844,2024-05-24 08:39:28\n",
      "3,125,19598,922,2,excellent,minor injury,61.94,22.56,172.58,7811b803-b17d-4704-bf02-67f5c83a63e5,2024-07-29 13:02:00\n",
      "15,200,14799,2095,1,fair,minor injury,55.95,14.69,199.53,3901b8b2-475a-4be6-923c-52d83b1f96ff,2024-01-19 09:14:28\n",
      "12,176,9397,944,18,good,major injury,165.74,19.47,193.92,c90897c3-4fc5-4e20-b5ce-6982a50872cd,2024-07-09 15:21:54\n",
      "7,181,12189,4875,17,poor,major injury,181.38,18.76,75.88,99e77132-f4cc-4384-97b4-c772caf11b62,2024-06-10 21:06:31\n",
      "17,72,17975,709,4,good,healthy,157.51,21.22,183.62,678bb743-7b46-4439-a6b5-5d588920c737,2023-12-12 22:35:10\n",
      "7,67,7259,4882,4,excellent,healthy,72.25,11.56,115.86,ad3e78d1-ca30-4f8b-9726-b33cda56e2ea,2023-12-16 23:32:15\n",
      "7,142,14899,4379,6,excellent,healthy,235.45,10.9,63.46,d029a257-e38f-4463-b9ae-6f56e31c7db5,2023-12-24 22:58:27\n",
      "12,60,18007,216,9,excellent,healthy,198.82,13.48,79.47,96bf1adf-7958-4d31-ad0c-58f70416b010,2023-12-12 08:44:51\n",
      "5,118,17199,1393,9,good,healthy,216.14,24.02,195.51,f8cffe06-6a10-4c21-8c4c-05422cf375f4,2024-03-30 12:12:53\n",
      "8,74,17130,210,14,poor,major injury,93.92,7.43,86.48,f0ebd0d4-5d4c-4006-ac55-77dcebb0ac07,2024-04-12 16:32:01\n",
      "20,159,2655,3928,2,poor,major injury,197.58,16.95,66.99,7c8cb5f2-06ec-451e-9d69-c1e22c026952,2024-09-30 14:23:26\n",
      "22,77,9066,1188,15,excellent,minor injury,43.98,22.66,173.31,a74740dd-281e-44d0-8812-92e7616b8bea,2024-06-19 03:21:34\n",
      "6,126,5883,4574,2,fair,minor injury,158.7,19.85,63.46,14462cc1-4c69-4cdb-acf6-79119cbd485c,2024-08-25 03:27:55\n",
      "6,150,4466,3166,11,excellent,minor injury,132.72,21.25,117.54,a52a2e44-e43f-4024-b155-24794594b8e3,2024-02-26 09:29:02\n",
      "19,95,1577,3035,8,poor,major injury,120.58,19.73,198.05,265fcd40-f4f2-498e-bf7c-bd17e6ef5aae,2023-12-10 19:41:58\n",
      "10,106,5118,4296,17,good,healthy,28.95,16.81,56.27,3ee14054-ea89-4f01-a0a2-918b878022c0,2024-02-11 00:01:49\n",
      "7,186,16825,3024,14,fair,major injury,233.61,21.11,63.88,c03f6e91-6804-4850-9010-4a5fa21c11f6,2024-03-07 07:31:32\n",
      "15,130,3625,780,3,excellent,major injury,213.71,18.77,172.6,5f69cdfa-aab1-40bd-a378-3844d92a1b05,2023-10-27 15:20:57\n",
      "15,108,19802,1587,9,good,major injury,11.99,19.52,87.62,07cadd6b-bfac-4632-a239-8118fbdd2920,2023-12-16 19:09:32\n",
      "13,59,12755,241,20,fair,minor injury,40.48,28.06,111.4,7a2d6dc6-f05e-4742-bf85-80fb9a4190ae,2023-11-27 07:07:15\n",
      "14,187,907,1873,19,fair,healthy,26.42,13.87,140.59,84e50a3e-a13e-4558-97c0-c399d0e99bb1,2024-09-03 17:50:14\n",
      "9,168,16573,2341,7,excellent,minor injury,64.87,12.03,197.27,34eae424-9bb3-445e-b257-249690557b5d,2024-07-07 09:05:24\n",
      "12,58,17268,4002,9,excellent,major injury,29.85,8.0,170.84,d6378088-d73b-472d-97e9-c6cf00be7ebb,2024-01-08 14:40:25\n",
      "14,145,140,1528,9,good,major injury,63.18,14.63,163.32,9b4294f3-3d42-477c-a1e5-8a4235d1691f,2024-06-10 09:21:24\n",
      "5,132,13074,3086,19,good,major injury,123.15,21.7,79.5,29adef5b-7312-49f8-a438-4c23d659db2b,2024-01-06 16:22:39\n",
      "17,63,15744,2999,16,fair,healthy,85.29,29.67,116.77,bc93c9a2-8691-4a79-aeca-a9b17dd92cf0,2024-04-27 22:36:04\n",
      "10,109,6242,4473,19,excellent,major injury,10.57,19.73,98.24,e6f48146-2d41-4ed5-9783-4bba2eb42e58,2023-12-15 02:40:30\n",
      "22,78,19585,4054,18,poor,major injury,179.07,8.87,168.99,c50e1148-3a54-46f9-9957-8df768b8e07f,2024-05-18 12:19:34\n",
      "2,140,15017,1292,5,excellent,major injury,232.58,16.31,66.72,52497f81-7607-4029-8668-5aff29da4bdb,2023-10-19 13:07:11\n",
      "19,126,6992,747,7,excellent,major injury,218.97,29.32,173.28,ea22ff9b-14c7-4960-b78b-619ba0a7d0a6,2024-09-25 01:27:23\n",
      "2,180,15140,4301,15,poor,major injury,40.22,29.29,79.44,e1ecbd43-b1ab-4d15-9aaf-83f3690f0caf,2024-04-03 21:22:10\n",
      "4,146,10906,3992,19,poor,healthy,115.79,16.76,112.22,368fe2f3-4274-443c-a18a-f0ce793ac3b2,2024-09-23 00:21:23\n",
      "11,80,9041,3532,1,good,major injury,77.33,13.03,73.98,9a1b9596-216a-4029-b14d-a5f899ae6f33,2024-06-30 19:59:25\n",
      "9,95,7480,2583,1,excellent,major injury,92.73,12.66,195.43,5471662b-1b39-428a-bea6-8a5441a1f450,2024-09-26 10:51:20\n",
      "22,144,751,3342,8,fair,minor injury,22.02,26.39,61.97,af449a7e-39c1-4ff8-ba17-1e6007608d9d,2023-10-19 01:02:02\n",
      "7,142,12348,1663,6,fair,minor injury,62.61,12.38,141.03,f7a52907-9bf6-4ee7-a512-08351f5d9399,2023-11-02 06:37:07\n",
      "1,179,3710,3702,7,poor,healthy,25.47,27.28,123.34,1b30459e-dc50-4753-bea7-8d3891324312,2023-12-08 05:10:23\n",
      "18,169,12665,2518,6,excellent,minor injury,165.56,9.45,116.32,c95f4a36-7a73-4360-864e-ed3f1ce3850d,2024-07-11 21:50:11\n",
      "4,55,5053,3003,2,poor,minor injury,25.48,10.41,116.97,0abe4ee7-ae9a-465b-9649-c1a09a1dab39,2024-07-12 05:32:41\n",
      "22,100,9479,3975,18,fair,healthy,31.88,24.81,62.78,422ddf85-d8f5-4d79-93da-2c6adddfa985,2024-05-12 05:43:23\n",
      "15,54,17027,2715,10,excellent,healthy,238.75,16.83,87.6,85ebdd49-a1d0-4ef5-be85-3a465abf1252,2024-09-03 18:20:32\n",
      "4,118,15916,1208,14,fair,major injury,169.99,11.14,110.64,f93ee9e3-62b6-453f-99b4-e42de0ada081,2024-01-09 01:24:18\n",
      "12,85,7318,798,19,good,healthy,170.36,9.39,91.46,a98d1647-0ba7-4ff4-be7f-541a17e465d3,2024-08-04 21:59:22\n",
      "1,156,1407,4160,5,good,minor injury,116.88,6.91,164.92,54e6b569-8502-4b93-b0a4-ee6cb2816eeb,2024-08-05 16:59:26\n",
      "5,60,4406,4873,12,fair,healthy,33.42,13.69,88.7,7aaf35fa-bf4a-424b-9aa9-f9982b0b2b9a,2024-10-10 13:06:39\n",
      "13,134,2176,4417,18,excellent,minor injury,63.08,16.42,138.31,9ceba668-fdc2-4292-b740-921e9afc4cff,2024-04-30 00:01:57\n",
      "2,185,5078,2217,17,fair,minor injury,68.33,21.01,123.24,15e4e961-1197-414b-b27d-e1b184697f26,2024-10-14 10:55:19\n",
      "5,159,10919,2091,13,good,healthy,103.05,28.36,68.19,c8a20fd2-5ca8-42fa-836d-760dd7542953,2024-05-23 21:37:07\n",
      "7,88,17825,1370,17,fair,major injury,122.39,20.44,178.3,c4d1b935-c7e5-4035-a27e-0e8ff4fb4dda,2024-02-25 04:12:39\n",
      "2,199,999,1342,0,poor,healthy,129.24,10.55,95.74,342665ef-fdce-4fac-8158-90802c6c58b4,2024-05-18 21:39:30\n",
      "7,62,13964,4826,15,excellent,major injury,101.1,10.96,109.29,ffaf2f6a-8579-410b-9f24-0fc4537ee4c4,2024-05-03 04:30:45\n",
      "10,173,5139,3558,13,fair,healthy,106.06,17.92,182.01,2aaa49e8-d1cc-48e9-a812-d5611080cb05,2024-01-24 12:33:54\n",
      "18,152,13441,762,16,poor,healthy,200.69,19.24,195.41,3658d761-43e0-4c4c-93b2-80e0a204217d,2023-12-05 22:56:21\n",
      "21,96,12374,4863,4,poor,healthy,227.11,20.61,67.78,2157d166-671a-492f-a49a-30cebf6b1042,2024-09-03 21:04:27\n",
      "15,105,14537,3481,1,good,minor injury,51.76,25.0,95.66,c5e9ab83-a6a3-4105-bede-ef2d8330a152,2024-01-20 19:51:05\n",
      "10,141,1536,1223,8,poor,minor injury,101.43,15.15,85.94,cbbe1817-2f75-454a-af16-7f173471dcea,2024-06-03 15:38:19\n",
      "15,131,5096,2380,8,poor,minor injury,16.77,26.93,156.42,b716f968-8628-4eca-9592-0eda2800da25,2024-08-20 12:23:49\n",
      "13,53,17309,892,9,good,minor injury,78.44,17.97,189.5,ce6668ed-5912-44c3-a0e2-43f94c6574f6,2024-05-06 19:02:30\n",
      "13,155,16074,3617,12,fair,healthy,197.67,28.13,151.98,770d7c7e-82e2-4be1-9db9-d5c1cc80d13c,2024-08-11 17:27:33\n",
      "20,125,12870,1845,19,excellent,healthy,208.27,16.65,150.85,3aad25c8-3298-4aeb-b87d-b5611a4ba24a,2023-11-10 23:31:50\n",
      "15,64,5496,4211,8,excellent,healthy,4.07,5.62,50.42,9089881c-12dc-4d00-9dd4-cf564ea5f7eb,2024-06-12 09:54:29\n",
      "14,105,5989,3174,2,fair,minor injury,150.41,18.15,71.41,5f845f34-1baf-47cc-ad03-0e2c19633ac3,2023-11-30 14:22:25\n",
      "16,92,13687,1161,9,poor,major injury,127.98,15.02,129.46,73402eba-e25c-4702-a006-c2a52f62f51c,2024-06-13 14:21:46\n",
      "15,182,11620,3471,14,poor,healthy,71.66,26.21,192.47,c66cdae4-89f4-4dc4-9452-5e27d252d48c,2024-08-06 11:22:10\n",
      "21,189,4660,2474,14,good,major injury,91.52,5.41,87.86,39eb145f-a2d8-4cce-bcb4-79b3366cdb10,2024-08-27 10:13:06\n",
      "3,175,17233,1645,6,fair,healthy,2.73,29.71,183.97,2c6c1358-226b-400a-927c-871ed77ada40,2024-09-27 01:57:59\n",
      "1,91,9780,1990,15,fair,minor injury,231.41,12.99,137.91,a0370e12-b808-415f-b446-68667bf260c0,2024-01-30 03:00:27\n",
      "1,150,18040,2097,9,good,minor injury,182.14,16.54,129.33,7cfdd566-fe2d-4598-a38b-bd1ca5bfa8b1,2024-04-09 11:13:45\n",
      "19,99,16157,753,0,excellent,healthy,221.01,22.29,59.89,844f641b-d4b0-4675-b150-cc801c1bbe23,2024-09-30 00:06:19\n",
      "4,135,811,845,15,poor,minor injury,18.1,17.48,152.01,3421e662-98a0-4f21-84cd-8db30f2a973d,2024-10-10 13:01:40\n",
      "5,130,19046,1266,11,fair,major injury,120.15,9.29,118.88,a6d8dd8e-41af-40b6-ab7b-b346a80e0d72,2024-07-19 05:27:31\n",
      "22,102,19225,4542,17,good,major injury,39.05,10.14,122.82,9e0a7701-1314-41c5-802e-7d10588f20f2,2023-12-23 20:53:58\n",
      "6,63,2293,3341,11,excellent,minor injury,92.57,5.22,145.16,459d443e-d97b-417f-a54c-726ce1127ef4,2024-02-25 10:09:22\n",
      "17,152,18047,3613,16,excellent,minor injury,51.86,22.45,141.77,123d3c57-1671-4f45-a130-217a1f7021ba,2023-12-09 19:50:32\n",
      "3,110,11530,1528,17,poor,healthy,191.03,14.77,158.75,9767b4de-7c84-42df-8e88-c35e7c54f284,2023-12-19 10:53:52\n",
      "13,182,2265,4455,1,fair,healthy,90.22,5.23,66.7,6894fb35-2e8f-4613-a2a3-a7cb873a589f,2024-07-07 21:37:27\n",
      "17,186,1163,4797,12,excellent,healthy,128.79,15.13,100.82,49455e66-e7e9-492c-bf55-f1382631587a,2024-07-21 16:57:20\n",
      "19,53,3144,4050,12,good,minor injury,6.69,20.48,109.4,9cad4224-24ed-4d09-8f83-7656f9210bdf,2023-11-11 11:40:59\n",
      "19,139,7577,1011,1,poor,healthy,147.28,9.04,97.76,2434dc13-973f-4910-b8a5-a4a40412dbe9,2024-06-23 21:18:46\n",
      "5,151,3904,1943,3,excellent,minor injury,113.26,22.43,144.98,78e80dbe-681a-4ee3-b1a9-02913aa3acec,2024-01-30 02:41:23\n",
      "9,144,5062,4683,19,good,major injury,18.98,22.11,156.11,8cabc5bd-27eb-4f26-bc52-8d975f0065a7,2024-07-04 19:02:46\n",
      "5,61,14604,2915,7,good,minor injury,162.19,19.23,194.93,3fb21c78-63fc-4eed-a0c5-c60e507e6502,2024-05-29 03:49:03\n",
      "15,137,12166,4769,11,fair,minor injury,96.09,5.01,193.76,604ff4e5-2517-4f88-8203-957355abac7f,2024-02-20 15:53:03\n",
      "11,102,5428,1354,12,good,major injury,71.54,5.67,90.27,2b44c38e-471d-4cd2-ba42-5eedfe59a7ea,2024-06-09 05:18:55\n",
      "18,64,9266,4230,12,fair,minor injury,149.23,9.37,65.01,453accc8-e72c-40cf-b35a-cef04c2efe28,2024-09-30 22:12:23\n",
      "2,93,17196,2136,7,poor,healthy,88.11,8.63,147.7,2bad8a98-9be9-4e2a-afcf-1f06857591d5,2024-04-01 12:39:37\n",
      "14,160,9166,578,7,excellent,minor injury,70.14,20.58,188.2,4fc96b7a-10c7-4a60-a7ed-07daadadf518,2024-08-28 23:17:47\n",
      "22,90,13353,3324,7,excellent,minor injury,196.0,8.47,55.52,ff140d50-7c51-41ea-9d24-381602fb95a1,2024-08-06 08:39:19\n",
      "11,124,8484,3856,6,excellent,healthy,186.25,11.96,121.09,06e69579-433e-4ee9-8ad4-e3bed080895d,2024-01-26 10:13:33\n",
      "3,73,5729,4027,0,fair,healthy,52.89,7.21,198.86,003e9250-90f8-4367-9316-f6c255385110,2024-02-25 03:34:40\n",
      "4,53,1134,1872,2,excellent,minor injury,181.33,18.73,183.96,c6d1aad1-be7a-4f84-b236-e8a9af654aca,2024-01-28 00:23:57\n",
      "6,68,12689,3791,19,good,minor injury,191.62,21.85,181.87,153b91ea-9ec5-45fa-af3c-5cd4f21e3392,2024-07-23 10:32:59\n",
      "2,96,944,328,19,poor,major injury,202.18,18.85,108.73,94e78f4c-598d-4a22-ab47-8753835d933c,2024-01-30 15:39:11\n",
      "1,98,15584,1135,14,good,healthy,64.58,21.93,96.14,30f43a51-6d66-4f28-909d-d832e81bc2c7,2024-08-22 04:53:50\n",
      "4,89,4667,4023,5,good,minor injury,117.24,29.36,115.14,a5ff7324-42f3-45cc-84a8-21a4afc29e6f,2023-10-23 17:56:23\n",
      "16,185,7352,545,5,poor,minor injury,74.2,29.65,106.94,29e48318-4d7f-423b-a5bd-f386fab04a70,2024-02-08 18:08:57\n",
      "6,195,16820,4978,16,excellent,major injury,61.53,20.06,192.9,d73fa1d2-9dbe-4dc0-b2d9-1184ffe1fe9e,2024-09-02 06:48:48\n",
      "10,188,1340,1226,1,poor,major injury,205.68,16.1,190.2,a16bbd8b-4a82-404b-b776-a4f85a953b6c,2024-09-08 21:59:59\n",
      "15,54,9826,3945,19,poor,major injury,77.12,13.2,163.52,85911099-e5a2-4670-8047-318b1340544c,2024-04-09 15:29:45\n",
      "4,173,8448,1197,20,excellent,healthy,147.91,14.14,113.11,568aa57e-878c-4074-a2ee-bed07cee6556,2024-07-13 03:27:55\n",
      "9,87,14492,1029,15,poor,major injury,177.18,21.02,195.61,f30306eb-b246-4320-81fb-150ef1d25efd,2023-11-26 12:22:29\n",
      "18,104,17808,1098,7,good,healthy,156.4,5.44,154.27,658faf99-bcbd-46fe-95e3-bfd349933001,2024-08-08 16:26:01\n",
      "22,133,2538,4824,14,poor,minor injury,15.47,11.01,158.1,d3c0701b-107d-4a2e-8886-29e7ac6e94b7,2023-10-18 14:35:09\n",
      "20,81,1097,4999,5,poor,minor injury,53.98,11.54,195.73,c370fabd-fa15-447c-afd4-e0292a8af099,2024-02-23 02:22:14\n",
      "11,193,11037,2222,19,excellent,healthy,93.53,25.24,108.32,0e484789-32ad-4f36-8b92-3269634a3d80,2024-07-24 07:32:35\n",
      "11,197,16720,2274,1,good,minor injury,77.04,12.89,194.21,a5e44814-f07a-47d6-8ce0-898459e7d784,2024-07-12 02:56:56\n",
      "17,55,17664,2503,11,excellent,healthy,121.49,14.29,65.37,8ddfe300-817c-47be-b22e-fb2d1daed0d9,2024-03-29 09:22:04\n",
      "4,82,4878,1743,17,poor,healthy,53.48,5.03,138.59,8bc15687-7d5d-4d44-9db6-d98c74d6658f,2024-04-01 18:23:15\n",
      "18,164,16861,1338,5,fair,major injury,136.75,28.04,143.2,a79b7ff4-72ec-4526-90d4-99ebc89a5dd6,2024-08-12 01:04:42\n",
      "11,182,15986,2090,2,fair,major injury,43.91,13.91,59.39,d8e6ecd0-5782-40a9-b76f-b12b1375fab9,2023-11-16 10:30:07\n",
      "4,133,4333,73,16,good,minor injury,108.01,25.32,66.58,6a2ddb8c-bef8-4f9b-80d3-ee61566085ae,2024-06-19 16:41:06\n",
      "1,75,3917,1993,1,excellent,minor injury,95.53,26.43,167.56,e294ccbb-8fc7-4625-823d-60dccda0bc8d,2024-06-05 02:10:30\n",
      "18,131,13784,2098,15,good,healthy,138.98,19.11,80.04,afdf06ec-37e5-481d-be7f-e08415db785c,2023-11-30 23:52:45\n",
      "7,173,5993,3027,1,excellent,minor injury,232.56,12.64,94.1,a7ca94f3-6a38-4aed-8521-5fc061749533,2024-08-21 17:59:07\n",
      "8,185,12652,1782,4,fair,minor injury,187.36,14.28,176.37,67421d72-f9f5-468d-b04b-fadc938d1931,2024-02-16 20:32:40\n",
      "20,88,7551,4733,7,excellent,healthy,215.52,6.21,98.76,a67b284d-8e8e-4818-a4bd-7f69a8d1e44f,2024-05-05 20:20:04\n",
      "14,110,15922,3482,3,fair,minor injury,1.54,9.7,191.92,6d77277a-d1da-49bb-aee3-3277898d0bcd,2024-09-25 23:15:56\n",
      "3,165,10902,1367,13,good,minor injury,41.44,8.78,82.92,049360bc-8292-4604-8695-eae17c223435,2024-05-26 10:14:47\n",
      "5,68,9875,1371,18,good,healthy,94.6,6.7,167.26,19af8c32-8cb2-48f0-b864-9e3c13a5af93,2024-03-06 22:52:59\n",
      "20,63,3544,3184,18,poor,major injury,133.53,27.29,195.62,67f3c177-9307-481b-bf0f-6df39531f1d5,2024-05-20 22:40:59\n",
      "12,130,3351,4546,16,excellent,minor injury,175.3,12.58,117.0,961db0e9-2a4a-4b65-a78d-d6d952978807,2023-10-19 01:14:59\n",
      "22,149,5516,4001,1,fair,minor injury,161.8,12.81,80.68,2647d0ac-75bc-466d-afac-68c177514f0e,2024-01-08 04:15:49\n",
      "8,182,1369,482,5,good,healthy,196.45,14.83,141.47,c1001c7d-9c74-4970-b0e0-a80523e3868b,2024-03-25 21:06:20\n",
      "15,182,10184,2335,19,excellent,major injury,66.57,22.18,185.3,6d2c749d-3758-436e-9d92-b8b5a90d0db1,2023-12-27 15:24:06\n",
      "15,166,13650,2532,12,poor,healthy,38.56,14.17,63.22,00277ba1-4888-47d9-9c45-ce5cea08300b,2024-08-20 06:42:25\n",
      "18,174,17457,933,2,good,healthy,100.2,9.6,135.39,2f053dce-5195-4c40-94b9-432537593899,2023-11-08 07:53:50\n",
      "5,111,3220,2977,0,fair,minor injury,205.93,29.26,57.81,1a7d736a-5ee4-46c7-bc79-58154c5a7e37,2024-04-23 01:04:57\n",
      "11,112,19196,1680,12,fair,healthy,187.41,19.52,118.96,65f112b7-4d1a-43bc-b9dd-9297ed10383e,2024-03-19 06:24:04\n",
      "4,167,2319,3152,4,good,minor injury,47.86,9.36,138.33,59af05a3-c076-46ad-ad4b-0331c58ac58c,2023-11-05 08:08:55\n",
      "19,57,1663,711,8,fair,major injury,0.3,20.93,151.28,4d201c16-2b68-46c8-8b7c-950f4b6a70e9,2024-03-14 19:17:02\n",
      "17,198,6779,3094,17,poor,major injury,42.61,22.57,125.86,8f085101-6b58-4ac7-8ccb-b54a577277dd,2024-03-14 19:51:16\n",
      "15,108,13882,4579,17,good,healthy,83.07,27.99,133.16,39f13286-d75d-4f5a-b574-312564cd560a,2024-01-16 13:37:42\n",
      "1,103,5041,4617,11,fair,major injury,65.79,14.26,181.65,4cc926c1-0973-4eda-9fce-e696ed7a525d,2024-08-09 05:57:56\n",
      "17,74,16611,3371,19,fair,major injury,236.95,11.1,188.53,c78d96ad-c57f-4f55-8756-bfb2a2f1b1f5,2024-09-07 14:02:31\n",
      "10,82,7830,3868,14,fair,healthy,136.98,11.63,109.97,42d3ab3e-c9be-4181-8aa4-0c50a9bb4b58,2024-04-04 12:36:25\n",
      "5,157,10,3114,2,fair,major injury,176.55,9.21,179.02,bf639b19-7989-4714-82f6-15b1c0aa2397,2024-10-14 07:19:07\n",
      "11,98,7608,4371,4,good,healthy,15.61,5.84,139.57,b87386d1-b268-426a-a341-6676e1d627f8,2024-01-23 03:04:22\n",
      "9,144,13082,182,5,excellent,healthy,6.6,29.78,198.25,97ba1c04-2e08-49d4-bdd4-82b9c111042d,2024-01-14 14:21:49\n",
      "13,88,15570,2543,18,good,healthy,65.66,15.07,192.58,7ef0027a-b003-4a1f-a569-161af1bec5f1,2024-01-30 11:25:32\n",
      "13,197,10555,1413,1,poor,major injury,158.44,19.35,182.12,46c89d81-cb4b-43e5-9c7e-8daa52f54ea8,2024-04-08 22:53:56\n",
      "16,185,5392,2272,7,poor,major injury,109.01,13.05,170.16,f80d58de-4bf7-4889-9d10-4a0f070d3840,2024-04-27 01:24:45\n",
      "6,122,16004,475,1,fair,healthy,178.79,5.96,179.28,10e34785-8c08-4484-b549-68a5660f2b3f,2024-03-11 10:37:52\n",
      "21,197,876,1674,3,good,major injury,119.25,26.5,182.18,667a52da-6da0-47bf-98ec-f172dc2a2817,2024-03-18 04:33:06\n",
      "8,149,5622,1447,8,excellent,minor injury,77.81,26.36,185.75,fc7237f7-a6bb-47c4-8032-9aa6d4d1a473,2024-02-04 22:33:09\n",
      "7,163,3418,4934,14,poor,major injury,139.21,16.89,74.48,190b32f7-76f7-4fcc-b6d3-27a1ca204d00,2024-08-17 13:28:46\n",
      "5,106,12937,2442,19,fair,healthy,85.26,11.75,84.58,2f75fad0-cbae-4ef0-a138-c43fdd20a66a,2024-02-23 11:23:11\n",
      "4,170,13241,1991,15,fair,major injury,26.51,18.32,177.58,063e86f0-5de6-4a2b-b89a-55d1ed516e75,2023-11-30 11:41:03\n",
      "6,198,12034,4742,10,excellent,healthy,55.27,15.82,162.64,8649ec7f-c35f-4965-a743-71265728ae5b,2024-05-01 02:17:35\n",
      "15,162,889,1247,3,excellent,major injury,36.08,18.86,177.6,fa613ce9-cc06-4acf-a306-4b8173713dcb,2024-02-17 18:33:48\n",
      "9,130,204,4506,9,excellent,minor injury,183.06,21.01,189.03,f14691f5-f499-4c61-a674-22c39424afbe,2024-05-18 19:47:33\n",
      "5,136,13222,4891,5,excellent,minor injury,47.89,24.5,60.55,1c853fea-e896-4916-b958-ced564ecd401,2024-03-14 19:21:49\n",
      "17,75,13018,3001,14,fair,major injury,78.66,16.15,80.77,d688c3c8-23f8-467e-a23f-2148834828d1,2024-05-16 01:30:05\n",
      "9,85,3451,4417,4,good,major injury,120.29,6.07,189.07,da4df102-b2ab-4265-97b4-5e4ac90b458a,2023-12-23 03:09:18\n",
      "1,85,6251,171,16,good,minor injury,202.7,26.83,71.62,e6ba43bc-b80a-4e78-80ad-efc7a73c841c,2024-06-24 07:55:33\n",
      "15,122,13160,3508,10,excellent,minor injury,62.93,15.64,103.32,c35309dc-ad45-4ac8-929d-98f7837e9f8a,2024-01-26 19:06:47\n",
      "6,95,2466,4168,20,good,healthy,181.09,25.77,121.88,590d90a7-5f86-4eaa-b426-c9858ea7b940,2024-03-12 23:01:34\n",
      "22,176,5807,4392,13,good,minor injury,207.57,5.71,132.88,0e89192f-b7d4-4058-82ef-b224e2cbed3e,2024-07-18 07:26:15\n",
      "8,73,4222,4533,18,fair,healthy,43.95,22.36,195.12,4415aca0-e710-4508-9f2e-bc2f8af2c728,2024-05-03 05:33:24\n",
      "11,169,4603,4847,5,excellent,healthy,26.57,7.42,189.32,3f366027-2cb5-4343-83ed-e4af3daadb5b,2023-12-19 23:17:02\n",
      "5,52,6952,1988,12,good,minor injury,89.06,15.22,126.91,3cc8e414-d6c1-4b09-86f4-1cc67196a772,2024-02-19 00:47:24\n",
      "18,76,11908,3102,14,fair,minor injury,190.69,6.18,183.02,51967238-59d9-476b-8e69-74d3531c1fe3,2023-12-15 17:47:46\n",
      "1,156,1838,971,4,poor,minor injury,68.44,25.8,143.0,5bfb74c6-fe6e-4163-a728-0f999b8ce732,2024-10-06 07:23:24\n",
      "20,74,2614,2273,3,excellent,major injury,121.75,20.37,54.14,eac9104e-afa5-431f-b654-b0a37eac60ec,2024-06-03 21:59:29\n",
      "11,120,15548,4566,2,good,minor injury,45.41,8.71,86.15,ac82c9e0-5c5c-419b-aaea-538e9fd8ea74,2023-11-23 09:42:09\n",
      "12,162,17383,876,1,fair,healthy,124.76,9.25,158.89,03dc2795-a998-494c-a14c-9f4129573ab6,2024-04-17 01:55:15\n",
      "9,62,16033,2586,18,good,minor injury,85.16,19.42,180.23,0dc18d50-2399-4d47-950d-4107f1cdd217,2024-02-06 13:10:12\n",
      "15,196,18681,4775,5,poor,major injury,205.95,18.8,161.68,3bd480b7-6a11-4af0-9522-a3d502767bab,2023-11-11 23:50:21\n",
      "11,57,11926,4150,8,fair,major injury,191.99,28.28,134.79,cb62bed0-55f5-4585-856e-2a336f3a68e2,2024-08-10 02:13:09\n",
      "6,112,4658,827,13,good,major injury,145.55,11.23,115.38,1b85c5db-231e-48ff-a0fe-d6925b479c4b,2024-08-02 13:21:09\n",
      "3,150,845,946,20,good,minor injury,220.08,14.11,98.51,4ff9fee9-7603-45b9-82f2-50ad9d6d9013,2024-01-16 22:17:05\n",
      "8,50,5301,4146,12,poor,minor injury,69.01,14.79,112.04,e24093b1-ae7e-465d-b953-adc213b5f22e,2023-11-09 22:05:22\n",
      "10,56,9619,198,2,good,healthy,7.98,20.26,181.87,6d0cbd0b-570a-421d-9f0f-1894c632ae2a,2023-11-15 06:23:25\n",
      "19,85,10643,290,14,poor,minor injury,72.03,16.55,176.58,3ace2a72-b9cc-4f95-803c-c28f00b72c7b,2024-04-21 16:06:41\n",
      "12,133,13492,3566,16,fair,major injury,143.62,5.9,86.36,4181e1bc-b6fd-4637-a18a-e1acba049779,2024-09-06 04:53:34\n",
      "10,69,9928,1571,4,good,minor injury,85.63,28.22,154.76,8386bde9-594c-406b-acfa-aa8412e69e18,2024-05-19 20:54:45\n",
      "5,90,9682,2649,3,excellent,healthy,236.46,13.92,132.47,15d9c909-cc59-4b22-9cc8-3cee35bcda9a,2023-12-29 02:30:16\n",
      "10,89,18249,1050,1,excellent,major injury,239.25,8.66,143.07,3480c9ab-46bf-446f-844a-4613a5eaf5bc,2023-11-12 15:05:16\n",
      "4,67,8602,2269,9,fair,minor injury,234.04,24.84,81.58,1610e91f-d06d-4671-b84c-e33488cdf25e,2024-07-27 05:21:49\n",
      "12,71,13610,1166,9,fair,major injury,159.69,6.38,160.99,a10b4fb4-0eca-4b3a-9796-c349303bea8e,2023-10-24 10:18:06\n",
      "8,70,9322,1210,11,fair,major injury,182.12,8.89,137.28,9b97c297-c230-40f0-9d2b-383e50d3758a,2024-08-29 08:57:03\n",
      "4,62,9050,2061,13,good,major injury,116.72,26.77,144.42,971bf87b-01c1-4555-bf77-d4488b1de928,2024-05-10 03:50:30\n",
      "12,124,15705,1085,1,good,minor injury,224.78,26.86,116.66,51bd56b3-1c5a-4450-bfc8-01df0d7bafc9,2024-02-27 23:59:50\n",
      "13,50,4963,1121,0,fair,healthy,23.03,14.37,190.5,d2aad94a-73bb-42ee-b5af-b4195eb25bfa,2024-07-09 03:35:07\n",
      "7,55,15587,3456,8,good,healthy,162.96,9.71,90.71,679804a2-585e-4ed5-82b1-eaae851fe63a,2024-04-22 04:48:32\n",
      "17,144,7381,3113,7,poor,healthy,140.0,29.96,101.57,fca39c99-1d78-4b0d-b3a1-3b9191fc2313,2024-06-20 05:09:33\n",
      "11,178,16292,1047,11,excellent,minor injury,199.27,8.26,162.43,ba4e84e5-57fd-4d24-af86-9c52ab822c89,2024-07-17 02:43:00\n",
      "14,151,1142,1692,6,good,healthy,119.76,17.92,158.46,0306c60e-11d5-4742-8662-990dcab02287,2024-06-09 23:56:28\n",
      "1,170,19373,4181,0,excellent,major injury,124.42,7.11,177.48,c27dcfbe-094c-45d9-b779-5695a6eb92c5,2023-10-18 22:43:53\n",
      "22,117,13173,3865,2,poor,healthy,184.55,20.52,199.75,e656862e-dd9c-4610-836e-f71de768e8d8,2023-12-11 19:21:44\n",
      "19,142,8141,4987,7,poor,minor injury,222.38,8.29,172.47,bd71c356-cf27-40de-a31a-0f1919cfb661,2024-04-03 20:12:08\n",
      "20,188,774,4914,1,excellent,minor injury,170.79,17.99,180.36,a287629f-f53b-401c-b5ff-2b192ff0fd77,2024-07-11 07:20:55\n",
      "12,168,14606,1386,10,fair,major injury,210.07,19.86,167.05,42c92998-b6e2-4bb0-909f-795728b93639,2024-09-21 13:04:40\n",
      "22,164,16240,3943,3,fair,healthy,199.11,15.29,58.02,461793d5-e421-4422-a870-149f45c8909c,2024-01-29 14:49:16\n",
      "14,200,4852,1077,18,excellent,major injury,208.55,8.63,87.03,b55a5d42-16fc-4338-8ed8-1569c8ae3c6d,2024-07-06 19:16:20\n",
      "12,75,15828,2194,1,fair,minor injury,152.47,15.38,117.93,5dad0c0f-a409-40f0-8408-ab5e32c8388c,2024-08-05 01:43:09\n",
      "9,85,18286,1566,3,fair,minor injury,146.74,10.97,117.74,8c609d6b-4747-4825-bb20-25e88eb8ebe1,2024-06-16 14:06:41\n",
      "11,87,16522,748,15,good,healthy,111.08,14.63,135.27,30a1b855-63ae-424f-ad0a-ede4fae374b5,2024-07-25 22:25:21\n",
      "3,151,14572,3407,15,poor,major injury,131.94,18.19,168.08,aabf7224-f2ca-4e62-b71e-bcd1556ea530,2024-06-30 20:59:23\n",
      "10,70,4588,4165,4,poor,healthy,186.93,21.12,117.49,12c34936-ee9f-4754-b485-aa562907bae1,2024-04-21 16:43:29\n",
      "17,58,14326,1252,10,fair,major injury,223.71,29.2,120.08,b76ba459-bbf5-4020-9db5-e7c9f6f102cb,2023-11-13 09:14:45\n",
      "7,132,10185,827,9,poor,healthy,226.47,28.93,181.25,b70abf48-8fde-4cd3-ad20-3d571336645b,2024-09-22 06:12:09\n",
      "13,86,3222,2832,7,excellent,major injury,149.82,8.53,158.5,34558ea9-cdcf-494a-aaf2-56e6b1d3204b,2024-01-09 16:33:30\n",
      "11,186,19822,1303,4,poor,healthy,196.45,29.4,196.04,a80774c4-dfc6-4155-bdeb-673ded54958e,2023-12-29 11:45:44\n",
      "4,91,5208,3110,19,fair,minor injury,99.56,29.89,136.29,df8d3da8-f5fb-4bd0-9967-dd6f31cb52e9,2024-02-11 22:22:56\n",
      "14,95,6841,3887,17,good,major injury,77.38,12.79,74.56,ebed0b67-65cd-4056-806f-a52f83351d14,2024-07-24 15:09:11\n",
      "21,177,6144,4899,9,fair,healthy,0.96,23.52,162.16,4955c819-35f8-401b-b2a9-f8c50ffbbded,2024-05-09 07:30:23\n",
      "1,95,12448,3877,3,fair,minor injury,96.3,11.33,50.35,f2735190-b42d-4abe-9ff1-c68bb6dea1e1,2024-05-31 09:19:34\n",
      "13,144,9503,1361,20,fair,healthy,203.5,13.47,184.05,22eb8ea3-8dd4-4a1f-8ef0-2eb6172f99df,2024-02-24 19:06:10\n",
      "10,116,13000,1314,9,fair,minor injury,231.65,19.37,109.24,24781f59-4d36-47ea-b1d7-04f5814c55ee,2024-06-13 02:24:57\n",
      "6,195,12382,1424,14,good,healthy,28.42,27.31,138.68,f1d80c68-25c2-42ca-8295-3f7368bf034a,2024-05-23 15:21:32\n",
      "22,56,1553,4225,1,excellent,healthy,6.39,27.96,57.78,7f51ef9e-aebf-4c2c-843e-c180e64cc5a6,2023-12-22 06:28:20\n",
      "19,86,7627,506,9,good,minor injury,223.56,20.26,95.19,670c35f2-746f-4e3d-98b2-9f742618be82,2024-01-21 22:12:45\n",
      "9,72,10501,3436,9,excellent,minor injury,107.45,18.61,78.89,d094480a-ae93-4fbf-bbf6-56d1027a29e8,2024-10-05 04:51:03\n",
      "15,71,6656,317,1,poor,healthy,188.86,15.45,196.7,862637da-49ce-4784-bf89-31e8ec4cb422,2023-10-31 11:02:13\n",
      "6,187,5768,3102,16,poor,healthy,211.78,7.52,61.72,8ee677a3-ecbd-41aa-bcc7-c9f532b1d134,2024-01-07 07:58:21\n",
      "5,86,13440,2888,17,good,healthy,4.91,5.9,106.51,4833ddea-cc2b-4b02-ad25-382f0e879fa8,2024-03-12 17:16:25\n",
      "6,126,17865,4930,12,excellent,major injury,153.89,8.34,182.09,e52560f3-7121-4b77-9a61-4abb854219af,2024-07-08 05:10:18\n",
      "2,167,821,4400,2,good,major injury,55.0,19.45,78.98,ea874660-461a-4aa3-92e7-9d6cc3c798e5,2023-11-09 12:41:49\n",
      "15,63,10926,1933,15,excellent,minor injury,58.53,17.06,180.74,17829ea3-a8c3-4235-b5f0-ee1b4251e751,2024-04-23 14:07:25\n",
      "13,61,13251,4156,4,excellent,healthy,169.03,22.0,142.65,60b2e3f7-521d-415c-98af-8dc933fa97fc,2023-12-09 05:37:21\n",
      "11,66,9699,1450,2,good,healthy,43.62,11.32,194.27,c04b5ae0-35ec-43e9-b859-eee598af75a1,2024-02-08 11:28:19\n",
      "16,192,15044,3405,0,poor,minor injury,233.84,13.79,142.59,07378a61-869f-49cf-9582-637fd2773d5f,2024-06-25 04:55:03\n",
      "15,177,7191,21,13,fair,major injury,50.25,18.26,88.97,84bf6da7-079b-4704-81b3-817ac4317ce7,2023-12-21 08:43:05\n",
      "9,120,12733,2993,11,poor,minor injury,43.24,25.95,103.91,2fc3be84-39e0-48a9-a9ef-b955170a84e6,2024-07-16 01:02:08\n",
      "8,98,2593,3308,7,poor,minor injury,202.58,5.78,154.18,0e2cb85a-36b0-4965-8b71-11334c7725e8,2024-04-11 04:54:03\n",
      "5,128,1958,4865,1,poor,major injury,220.91,12.9,182.84,22abdd80-7c11-468e-84dd-5b5f19d96480,2024-05-26 07:50:22\n",
      "3,138,3251,2477,10,fair,minor injury,74.84,14.65,143.92,4a23511a-7483-4742-95ab-c325c6221a97,2024-05-30 07:32:22\n",
      "3,61,11588,4769,7,fair,minor injury,208.0,7.44,157.6,20ae2d88-338e-476f-a73a-65bc38cb494c,2024-07-21 07:21:27\n",
      "17,149,242,221,11,fair,healthy,36.58,21.1,118.7,dd6a8b5a-cad9-4b4d-9e52-8e5db0981296,2023-12-09 17:06:06\n",
      "19,186,275,3931,12,good,healthy,79.02,6.2,131.46,ba87435c-54a8-40f0-a06e-b1fbac4e5b0e,2024-02-24 10:11:30\n",
      "5,113,7935,934,12,good,major injury,115.92,24.92,173.28,ff342361-da3a-418f-9eed-0a581e94c45b,2024-07-09 05:24:27\n",
      "8,160,3702,2705,10,excellent,healthy,60.84,27.07,54.93,52202287-1efb-4612-9d15-eec8e80f2f59,2023-11-14 04:57:01\n",
      "3,70,5409,3966,5,fair,healthy,38.35,21.88,95.29,a7851947-ac2e-4009-ba36-c02a93753cc1,2023-11-06 10:24:45\n",
      "10,97,11687,3338,19,good,healthy,123.38,19.0,64.23,e8bfeeee-75ae-4499-a110-71737b06b178,2023-10-15 18:19:09\n",
      "21,92,13803,4538,17,poor,major injury,141.26,24.41,196.54,5d4972d6-15db-474c-9dfd-96b3541d3faf,2023-11-12 15:55:25\n",
      "9,162,317,2632,13,good,healthy,40.4,26.83,107.25,3a8bf1c7-7fe5-4d1d-b554-8a0cb958692f,2024-05-08 22:14:57\n",
      "19,134,17386,1587,0,good,healthy,61.42,26.24,187.11,f38d60b2-0fb1-4014-bcb5-2aa432d7b27e,2024-01-27 09:58:22\n",
      "7,171,8813,182,20,poor,healthy,38.86,8.69,194.87,bb29667f-dade-4edb-89fd-e2ba987dd996,2024-04-29 08:15:28\n",
      "2,71,1457,219,15,good,healthy,97.09,23.67,124.31,900ea48d-0dcc-4a54-a029-220f96dced4d,2024-10-07 10:36:35\n",
      "2,112,9299,4327,8,excellent,major injury,184.5,18.4,124.7,57a13297-b973-4c2e-a10f-abc774d856ea,2023-11-05 13:46:14\n",
      "21,186,88,4397,20,excellent,major injury,60.89,21.28,159.8,f52b6df6-760d-400f-9e87-e45cee673dd9,2023-11-10 09:46:10\n",
      "1,157,11402,4489,15,excellent,major injury,14.32,24.94,122.37,fb52e283-74c4-4cb3-bd26-747f776ef5b1,2024-07-12 03:44:19\n",
      "5,98,18407,707,2,good,major injury,108.0,23.9,197.22,19b7733a-ae32-41bf-b300-f4ffd521b0cf,2024-05-02 13:16:03\n",
      "1,87,15714,2454,18,poor,major injury,92.66,9.5,165.02,571d3e38-48b0-4bde-920e-a37d237d53e2,2024-06-10 15:52:14\n",
      "7,181,748,4479,19,excellent,healthy,143.09,6.25,109.5,0f67483f-8bda-4d2f-ac36-be27c1377e4e,2024-08-12 21:07:50\n",
      "10,169,7186,1716,13,fair,healthy,119.14,8.99,80.85,4f6d697e-348d-4d0b-b500-1c4bd7778474,2023-11-13 00:06:24\n",
      "7,128,390,2751,0,poor,major injury,107.05,12.89,158.21,34b3e5b9-d750-4cee-9949-37c3483fea91,2024-10-11 19:45:07\n",
      "16,197,13241,4347,3,good,major injury,164.32,22.34,81.43,414eeec5-0741-4983-b9aa-78172bb48d9e,2023-10-24 06:47:50\n",
      "1,142,13692,1836,13,good,minor injury,222.42,19.24,77.91,baa92baf-238b-4dd6-a295-9641b86dcd8b,2023-12-20 16:35:42\n",
      "6,155,3459,2748,7,fair,minor injury,19.34,21.28,153.82,bbff2f66-1428-46fa-9cd1-367b933a87b2,2024-02-05 13:48:11\n",
      "14,67,8816,1217,15,good,major injury,161.39,22.31,51.63,76353681-a3a5-4c24-9967-d7bb636e5b7c,2023-11-27 03:37:42\n",
      "8,68,19938,3991,9,fair,healthy,150.16,15.13,77.34,6f5f0333-f7e0-4aa8-91a7-7058d7a96814,2024-06-16 13:40:14\n",
      "7,145,7311,3471,9,fair,minor injury,109.66,12.82,168.72,d5ce14f1-088d-4f44-ad80-cdb07b5e21a8,2024-07-31 09:21:29\n",
      "13,120,13371,1647,16,good,healthy,190.23,27.23,57.48,8880e6f6-78bd-4c46-92ea-dc2e4bb4433f,2024-06-12 21:14:54\n",
      "17,152,18997,3891,14,excellent,healthy,201.53,12.33,54.74,0719cd9a-ed6e-4d5e-8711-897adafa1acd,2023-11-11 14:42:26\n",
      "11,123,14104,1800,19,good,healthy,70.02,11.08,73.83,596fa174-cce7-44de-ada5-8f61f872d2f7,2024-06-24 23:07:48\n",
      "15,82,675,4799,19,poor,healthy,185.37,20.07,127.44,1e885e1c-f720-4479-9ca6-39a1c39116ab,2024-07-03 12:30:31\n",
      "10,95,10794,278,16,excellent,healthy,50.52,17.64,149.14,ef5d3d4d-7d3f-40f8-b7ae-1498a8b1b7bd,2024-09-23 08:14:40\n",
      "10,113,11211,192,8,good,minor injury,230.2,12.95,113.21,98df4573-2637-4390-a3c9-da871b9ab2f8,2024-06-18 23:32:01\n",
      "16,113,4708,1691,11,good,minor injury,129.07,5.37,145.65,18672258-7499-4bed-bc2c-462b67606131,2024-03-26 05:02:09\n",
      "14,107,12347,3461,17,poor,healthy,213.8,7.34,109.0,56dfdc76-c88d-4352-92ca-3e9b97dc5525,2024-09-28 03:10:45\n",
      "13,115,18090,2372,0,fair,major injury,133.98,9.93,193.23,231c34d8-2647-4426-aff8-470f01ae3ff7,2024-07-27 08:46:12\n",
      "21,102,2660,1547,5,fair,major injury,81.78,6.75,131.26,8ff60cc9-f757-4af5-85b2-6290d360da30,2023-12-24 13:12:03\n",
      "5,74,17299,4609,7,poor,healthy,165.89,23.77,52.05,c06b6d2a-d1c5-408f-b79f-9110b42e8e66,2024-02-14 21:59:37\n",
      "3,181,14714,3050,5,excellent,major injury,92.54,12.64,126.79,3e811849-6647-416c-b86d-fea426f38987,2024-07-11 16:23:03\n",
      "1,76,17749,3084,5,fair,healthy,9.03,23.11,176.9,430c6cce-1cb2-4ccc-9b2e-0947a256f95e,2024-06-29 04:35:52\n",
      "19,101,6401,137,6,poor,major injury,236.99,7.7,135.41,8d3ddaa2-bbbc-4afe-b29d-f07973fe49ff,2024-03-24 12:38:11\n",
      "22,132,3337,4508,15,fair,minor injury,84.06,14.7,157.39,2c6cedd3-7d13-473b-9098-8a707b769538,2024-03-17 22:47:03\n",
      "1,190,5277,4732,15,fair,healthy,179.9,22.12,62.96,92cfc00c-764f-460f-af20-9b80db90f05f,2024-01-20 10:03:20\n",
      "22,52,11436,4474,15,poor,major injury,30.12,13.6,68.23,03992404-d45c-4c7d-a59d-bb8e30951d37,2024-04-24 23:04:14\n",
      "14,143,8031,2365,10,excellent,healthy,44.74,13.62,172.22,b3552e84-72ce-4f96-9128-b5b7242102e6,2024-02-03 14:56:47\n",
      "8,51,19099,4609,19,poor,major injury,39.64,21.7,162.81,ae6e8456-0606-424e-b892-4969e367683e,2024-07-26 07:52:39\n",
      "4,66,12061,3251,18,good,minor injury,178.27,25.0,81.04,79370d6f-a5e3-4ea8-8d29-6ecf8d9509ea,2024-01-07 13:19:11\n",
      "9,184,157,2667,2,good,minor injury,126.27,23.28,164.9,7c5800fe-f49e-4ea3-be89-c28e78694196,2024-09-13 17:32:17\n",
      "3,163,12581,4450,7,poor,major injury,201.98,12.11,168.76,f08922c2-8c41-49d0-a87c-a50c3c9be098,2024-03-10 09:07:28\n",
      "12,106,1439,4601,10,fair,minor injury,150.67,12.34,93.85,8e612108-38c3-4e27-b0f4-bb71054e52b0,2024-06-25 16:37:38\n",
      "3,181,19096,1933,5,excellent,minor injury,108.03,8.03,71.13,73f89d39-082c-45bd-828f-55d0c2236845,2024-04-05 20:06:30\n",
      "19,99,17756,474,15,poor,major injury,161.89,7.34,147.47,51a1fc31-1efb-4c44-ae03-7a5a2c1d21b7,2024-05-01 10:11:40\n",
      "3,143,18160,1305,7,fair,healthy,118.28,23.42,163.23,2250b666-4f46-4e87-a512-f1e15a93e954,2024-10-12 20:28:24\n",
      "20,196,18360,4872,9,poor,healthy,119.31,29.48,156.15,cd9d350e-e0ea-46ad-8a01-b482bc537e90,2024-05-21 23:15:42\n",
      "14,186,15497,4560,4,fair,major injury,113.39,11.08,151.29,db223f41-8261-47df-b24f-4405beef0ce0,2023-12-17 05:51:44\n",
      "17,194,18448,1021,11,fair,minor injury,205.49,8.72,90.45,9ffb31e1-ad8b-4da9-a536-bd010466bd34,2024-08-15 15:44:43\n",
      "10,145,10301,1459,19,good,minor injury,167.54,21.86,158.03,2b5aa3ed-735e-428a-bf2f-a9acdf15d1fb,2024-10-10 07:17:31\n",
      "17,168,2811,4526,3,excellent,minor injury,131.61,18.12,143.93,d5321342-87fe-4b8c-9c11-5afc4b4da5b5,2024-09-01 18:41:11\n",
      "19,173,13041,963,6,fair,major injury,75.09,27.81,56.38,bfbf98ea-9a28-4b8a-9cdc-aa5a752d0427,2023-10-29 07:42:37\n",
      "3,183,8798,928,12,excellent,minor injury,108.56,12.03,82.04,25eb7945-23da-4a5e-9810-fa697c01b3ff,2024-02-23 13:37:09\n",
      "8,113,6713,4231,1,excellent,minor injury,6.62,8.7,139.24,511cf625-4dce-4f2f-bf48-e055bbdc8300,2024-07-21 09:06:43\n",
      "14,97,7662,3750,8,good,major injury,32.98,28.07,128.16,abae7e40-5ccf-434a-a7f5-9ff9c8423ab3,2024-08-04 03:30:22\n",
      "11,120,2012,260,7,excellent,healthy,143.68,13.14,73.65,7050bc2a-d60d-4972-b0bd-5cd903fab90a,2024-07-12 20:46:03\n",
      "16,101,6673,1405,5,good,minor injury,74.74,24.46,151.97,964a0620-171d-4ebf-95cc-75e905aff984,2024-03-28 22:40:18\n",
      "4,125,19009,2372,16,excellent,minor injury,98.73,20.29,159.14,f5b39c0a-fcd5-4e1e-9c9e-3992835927e4,2024-07-06 12:49:41\n",
      "7,183,10343,2872,9,poor,healthy,41.15,29.07,117.48,d43cef88-07e1-4347-931b-295e29da672c,2024-07-01 11:43:07\n",
      "17,109,8089,541,6,good,major injury,143.77,19.21,59.39,2f6d1648-189f-484d-8c2b-127fe74cc22b,2024-07-14 17:47:26\n",
      "4,141,10761,3656,11,excellent,minor injury,238.58,8.22,85.83,a56a29c7-ae41-41cc-ba7b-a8b501398051,2024-05-31 17:59:22\n",
      "11,199,9186,307,13,poor,major injury,119.81,18.35,117.59,79a265e9-a84b-4962-b5ec-8e87448d0cbe,2024-05-06 21:58:46\n",
      "6,132,13428,4773,9,poor,minor injury,99.29,20.31,144.49,a1b2c55c-d821-4475-a083-d46a4b23ffd1,2024-05-22 17:28:13\n",
      "17,67,8817,2881,5,poor,major injury,84.66,29.43,155.52,c15c9b8a-d18b-4ac5-9f30-86c5651d7452,2024-06-10 12:16:09\n",
      "14,163,16361,1845,0,fair,minor injury,117.6,15.12,145.51,33ac4190-707d-4da4-8298-9f0f99e74adb,2023-10-31 04:56:54\n",
      "9,139,13598,3659,14,fair,healthy,158.49,13.1,107.29,7f548798-e064-453e-8f09-c7f17485e331,2024-02-14 20:23:03\n",
      "14,197,4352,237,8,good,major injury,154.58,15.33,169.69,361eb6f4-0d8e-4fc3-8653-de0316fc6a48,2023-10-15 11:51:48\n",
      "2,54,17129,4422,3,poor,major injury,65.0,7.08,157.04,2520830a-c24f-4347-b576-ddf2e18fbba9,2024-07-19 22:50:19\n",
      "16,66,9393,846,12,excellent,major injury,42.48,9.78,90.35,ae61cb25-5307-47a7-9b8b-b2a2b90b3830,2024-04-15 12:03:37\n",
      "11,168,8460,2185,14,excellent,major injury,59.22,29.25,182.34,a12c77fe-5598-4ed1-8100-c30b548f445d,2024-03-15 15:37:02\n",
      "6,172,17481,2101,9,poor,minor injury,138.7,11.39,89.84,168871cb-6a06-419e-9da4-a284a777177b,2024-05-29 13:19:54\n",
      "1,70,2147,3907,18,excellent,healthy,0.77,19.96,77.25,7f9130e2-5399-4422-84eb-c524134d068b,2023-11-06 16:20:39\n",
      "15,190,6016,2044,19,poor,minor injury,209.13,8.21,150.84,6c9596f0-d293-4158-ab78-4f375f53a6ee,2024-07-25 19:17:31\n",
      "2,71,9627,1961,19,good,healthy,112.59,17.61,98.12,ccc24a0e-50f1-411c-a3f9-b4f8b1bb3892,2024-02-01 00:18:46\n",
      "11,157,13406,322,15,excellent,minor injury,226.26,29.2,199.21,babf6c6d-2d7a-4802-9a96-05c63e287d6b,2024-06-25 23:56:22\n",
      "7,122,14748,76,19,excellent,major injury,74.03,8.07,81.77,1d99a125-80a4-47b8-b9a8-893644a13600,2024-03-29 08:46:32\n",
      "6,126,14141,1484,13,good,healthy,32.37,17.48,140.09,3b619207-675e-4f54-bc96-8c24fb1bb969,2024-03-27 20:49:30\n",
      "4,117,3733,1756,19,fair,minor injury,190.58,11.06,175.7,83e6723b-174d-414f-8ea8-370ff32d6ea5,2024-05-31 23:18:30\n",
      "1,137,16184,2385,4,good,minor injury,156.51,20.98,123.04,6ab7e7bf-eb1b-4231-8dff-2ba89b2ee05e,2024-02-26 15:09:15\n",
      "15,115,10637,1068,5,fair,minor injury,73.22,6.89,157.79,a998d157-bd09-4ff5-8d67-9779cb9ccd5b,2024-07-19 07:42:29\n",
      "21,107,4430,3470,18,fair,major injury,20.98,18.12,64.97,e76d3002-ad99-44a9-a42e-d19903b122f6,2024-01-05 07:00:32\n",
      "8,198,18898,2396,5,good,major injury,92.5,23.51,50.43,45983f2f-a834-4838-b337-54e49eee55e4,2024-04-12 06:00:57\n",
      "1,119,11749,4823,16,excellent,minor injury,37.93,24.42,182.33,6dfd9332-3074-4591-9535-2a3268ff9df1,2023-12-20 23:34:43\n",
      "18,144,6306,2948,17,fair,major injury,120.4,16.85,107.19,a3b246b8-770b-482a-9b41-2f38edac2270,2024-05-08 13:23:53\n",
      "6,196,16570,1712,17,fair,major injury,225.43,5.13,114.86,efceccb0-7934-4137-8f7a-8d0f1c7ab229,2024-01-16 22:46:40\n",
      "20,138,8568,1682,15,excellent,healthy,21.24,15.5,51.66,1495f2a6-8274-4e51-bf8e-a7ee857cbd9e,2023-10-25 09:14:56\n",
      "13,190,12443,4601,2,poor,healthy,21.88,29.7,110.51,8db36572-5d09-42ad-99dc-4daee1da260a,2024-09-02 01:24:59\n",
      "21,157,16680,3939,1,fair,minor injury,174.55,17.36,55.2,37fed3ce-1e8f-4493-8bf3-db9b91389e32,2024-02-23 22:27:40\n",
      "7,141,4156,388,7,excellent,major injury,125.6,26.72,111.24,56519345-5bd8-433a-842b-3b73bebbaacb,2024-01-31 02:42:31\n",
      "3,110,4791,2714,12,poor,healthy,37.66,16.23,159.69,798d72d9-2625-4791-9967-72b2b14cd300,2024-09-04 14:44:29\n",
      "11,142,76,1860,2,poor,minor injury,82.53,15.3,195.9,79b54c5a-a171-4898-a021-1442d7ded8fe,2023-11-21 11:53:37\n",
      "4,124,86,2119,0,good,minor injury,176.6,28.24,82.6,0e131722-7428-4cad-b52d-91b344e270bb,2024-03-05 08:02:30\n",
      "15,108,5804,4654,2,good,healthy,28.2,18.89,107.13,813caef8-7abb-42b1-b650-fe564a720b8f,2024-07-28 05:30:48\n",
      "8,73,13836,3067,7,good,healthy,182.24,5.72,61.09,3186b309-cfad-45b8-bab5-5366b47f8dab,2023-12-12 07:53:50\n",
      "20,54,17308,961,0,fair,major injury,89.89,25.72,102.48,3096d6e9-0edc-4840-a317-ad7a02170e2d,2024-05-13 02:26:24\n",
      "4,76,12959,427,10,poor,minor injury,87.05,19.08,76.11,2d00bb1c-2027-4dcd-89fa-aa436eb0a92e,2024-04-13 01:46:16\n",
      "1,122,18533,4431,10,good,healthy,182.49,15.01,167.4,293d0f98-5c72-4958-bd4c-062ffec69155,2024-02-09 04:44:17\n",
      "20,140,6923,2025,8,good,minor injury,214.89,17.2,102.17,17de81a7-ab85-4a2f-859a-a32690e5000a,2024-08-31 13:29:48\n",
      "9,188,14775,1347,9,good,major injury,238.45,13.34,74.59,73733c07-65a5-40ef-afe8-ff976196d5d6,2024-07-16 02:43:54\n",
      "21,109,18076,3483,3,poor,minor injury,104.94,27.15,195.49,dcd8e2ae-73da-4ffb-a2cf-4c2ac010cc1b,2024-06-19 17:48:41\n",
      "17,157,14345,1021,19,excellent,healthy,143.82,23.23,143.33,03e5f2ac-cfda-4354-a8ce-0a6c7a1d78ec,2024-09-14 13:17:34\n",
      "13,76,9666,4436,18,good,healthy,220.22,19.4,198.61,5c825465-692a-46f6-a00e-808afdd37af3,2024-08-28 13:38:05\n",
      "3,83,1247,4764,19,fair,major injury,22.98,8.6,176.15,774529de-f353-416e-8369-d58c21cdb72d,2023-12-22 23:32:06\n",
      "22,138,4947,3462,11,good,healthy,9.04,6.34,99.76,c26dfd7c-580c-43d2-9cde-7fc1cfab5828,2024-07-27 05:48:14\n",
      "14,116,17144,3959,20,poor,minor injury,192.89,29.81,187.39,03228849-1712-4111-b93b-b61175635d58,2023-11-02 17:10:53\n",
      "16,139,14218,2969,4,poor,healthy,49.81,16.04,73.88,4ddae2ee-dc5a-48b7-9510-aed62ff4af71,2023-10-20 06:06:26\n",
      "12,125,11068,1084,0,excellent,minor injury,6.7,21.77,195.04,3fb4c51e-9fd2-4ca5-92c3-cec9ed0e6238,2024-10-10 04:08:37\n",
      "1,94,7550,4486,7,good,healthy,64.38,17.86,191.0,a138212a-8474-4591-bfd5-70c6d102b244,2024-04-29 22:24:46\n",
      "10,133,19041,1704,9,good,major injury,59.39,15.51,157.39,cda60488-84df-492c-8c99-51d5b7dab519,2024-04-24 13:25:40\n",
      "8,80,18031,4862,17,poor,healthy,179.72,15.31,76.66,13044964-a53f-43ec-95f0-b2c29c5f339a,2023-12-08 15:47:32\n",
      "9,159,15210,1519,4,good,major injury,74.8,12.25,191.82,3bdbe2be-da71-49c9-9016-42baba03f031,2024-07-05 22:41:30\n",
      "18,74,17600,1897,16,good,major injury,42.14,18.52,85.09,07dfc829-d910-4b0e-a50c-41b84a1d4798,2024-04-05 10:00:01\n",
      "13,111,7770,2303,17,poor,minor injury,144.41,18.22,138.39,10f3ff1f-9871-4ab0-87c6-a0766f752653,2023-10-29 23:19:44\n",
      "10,157,2220,2681,8,excellent,minor injury,10.9,29.49,128.4,50d32ed4-0d74-4bb9-984e-853e0567d666,2024-02-16 17:25:11\n",
      "9,164,7072,502,5,excellent,healthy,2.18,24.46,180.66,396e1ffb-8a2d-47cb-bca4-09cb9505486a,2024-01-06 07:03:44\n",
      "5,126,4392,3471,6,poor,major injury,91.44,13.2,157.92,e70ffc49-b7f0-4960-8b23-3b3761ac97f9,2023-10-25 11:28:05\n",
      "14,111,16547,3697,16,good,healthy,67.95,24.63,93.23,b6a46d1e-52bb-4be5-b8d9-398a6995884c,2024-10-14 09:04:17\n",
      "7,126,8482,2302,13,fair,minor injury,211.67,18.51,177.7,8354fad3-abc1-44a1-af74-93549d298797,2024-04-30 20:01:43\n",
      "12,158,18827,3580,6,excellent,minor injury,94.84,9.81,87.55,42e691d3-53f0-4e6b-af74-b1c2d43beccc,2024-04-20 10:50:20\n",
      "1,127,10565,4039,8,fair,major injury,205.14,22.23,77.01,9bc10359-cba9-4f2a-8fb6-16da50796025,2023-10-18 13:31:04\n",
      "21,56,1561,3040,5,good,healthy,194.14,20.83,120.42,fdb4f3ed-b993-4cd0-a393-47efe02d20cd,2024-06-25 07:16:23\n",
      "4,122,13874,1709,15,good,healthy,84.84,7.18,57.98,ffefa5c2-4033-4456-b132-795a8e050953,2024-08-03 11:30:00\n",
      "3,102,7574,3434,16,fair,major injury,88.37,15.29,173.67,7b02ebe6-f770-44d3-8509-c21fb45eadc4,2024-04-08 20:31:43\n",
      "2,100,3167,1318,11,poor,major injury,188.76,7.45,144.38,a46bb934-fa7f-4a7a-8cfa-1a306194e893,2024-02-21 07:56:05\n",
      "16,108,8745,4209,13,good,healthy,39.65,27.75,87.1,daabf776-5de4-4362-acd4-dba6c87fa433,2024-08-23 14:51:08\n",
      "15,197,12719,815,3,good,healthy,48.32,16.32,136.07,f120c33d-a31d-41e2-92ed-e4ce61719c8d,2024-08-17 07:53:15\n",
      "14,179,5133,2570,3,good,healthy,139.78,12.84,138.41,f323add8-32bd-4285-b0e4-2088182fdf0f,2024-09-11 00:29:38\n",
      "12,64,11959,2474,17,poor,minor injury,170.82,13.94,53.78,e2f6f8e3-cb44-4b06-81f5-b289ccefbf7d,2023-12-04 23:54:13\n",
      "17,112,14959,3109,8,good,healthy,149.9,23.82,149.25,08221b9b-4910-4399-9c67-5bd213c4261c,2024-05-24 18:47:33\n",
      "10,57,184,2014,8,excellent,healthy,100.77,10.3,128.88,d299f0f4-c85b-4484-b1c3-19ebf3d658e4,2024-08-04 00:54:48\n",
      "20,135,5408,3060,14,excellent,minor injury,34.1,24.68,186.26,d93ef0e1-4ff6-45a6-80cd-fa6b88ce5df6,2023-11-05 00:46:07\n",
      "2,90,18445,3526,1,fair,healthy,211.32,21.27,84.29,4709e477-adc9-4dc0-93ca-04006933ca5f,2024-08-12 12:10:39\n",
      "10,152,10463,3422,4,excellent,healthy,159.59,18.24,62.14,7ec751c0-ca0a-4f6a-a0b9-eb40e9a9eae7,2023-10-21 11:35:12\n",
      "19,169,10358,682,3,poor,healthy,26.31,29.84,104.12,98d930df-75ed-4b73-8b11-8efad5a14275,2024-05-15 08:54:49\n",
      "18,93,5026,375,14,excellent,major injury,111.77,7.64,152.89,4dc68d3a-1f18-40b1-bc55-accd7f276d3d,2024-08-24 02:37:52\n",
      "13,130,13288,3975,2,poor,healthy,228.06,17.48,191.55,fda93a6e-6e75-4a76-8fe8-1712373cf3b4,2024-01-12 04:10:04\n",
      "6,171,12838,765,3,poor,minor injury,145.25,6.52,74.66,e4ecb06e-f490-4b62-a45f-d193e09f433c,2023-10-18 19:44:57\n",
      "16,187,19968,3626,10,excellent,healthy,125.98,20.16,125.28,2aab6c81-4175-45fd-b527-2925a3258021,2024-03-27 17:27:44\n",
      "3,169,3283,2736,15,good,minor injury,38.64,9.03,56.19,dc4b972b-b8b0-4f58-a2ae-de796f6975fe,2024-06-29 10:30:48\n",
      "14,66,14080,1041,5,fair,major injury,198.69,16.21,192.51,2824f40a-7bf7-4db1-9ece-6c35a3bbbeb4,2023-10-30 12:47:35\n",
      "6,143,19505,2638,9,good,healthy,0.14,16.73,117.45,9f2f8373-e4a3-400c-9a83-e565622419e5,2024-01-01 17:25:42\n",
      "1,124,5551,1556,19,good,major injury,157.07,14.72,124.54,ac70d8d0-745b-4379-b0d8-c5e59802da45,2024-06-23 14:52:34\n",
      "3,124,13163,4173,4,fair,healthy,103.81,9.8,68.44,a66b2579-6043-4ba6-8e4e-1778d21786f3,2024-09-04 20:30:50\n",
      "16,91,7015,4526,5,good,minor injury,160.19,17.5,197.89,5b517cd2-6b9f-4584-9676-5b112584e879,2024-03-09 00:14:52\n",
      "10,85,12061,3356,11,good,major injury,49.05,14.22,78.82,3875e14b-593c-4bf6-a898-df08be5b1d3c,2024-09-14 17:02:59\n",
      "22,157,17200,4725,6,fair,major injury,96.36,12.62,99.72,34363c4a-b574-45f2-b67e-467b9e1356db,2024-03-16 14:18:48\n",
      "4,60,19562,2174,3,excellent,minor injury,85.11,10.47,87.16,828e3599-87b9-4c1e-9d34-c4d18c1678d1,2024-03-13 18:49:15\n",
      "19,124,8630,4049,6,poor,minor injury,47.58,8.36,170.44,81d074eb-ec3b-4ea5-bd63-8746f1b9e90a,2024-03-28 12:10:11\n",
      "9,114,3898,207,7,poor,minor injury,87.3,26.17,180.81,ccc54c2a-b0c6-44c0-88e8-43222867c2b0,2023-11-21 02:08:59\n",
      "5,193,147,698,18,good,healthy,161.58,8.17,188.17,d6aa5e20-1453-4e0e-9e14-62de0f50576b,2024-07-02 09:17:11\n",
      "19,183,774,1510,2,fair,major injury,190.89,25.65,136.37,9c7b055f-6fa3-4800-b47b-f3339d1639aa,2024-05-16 20:55:55\n",
      "5,88,2419,2652,1,good,healthy,95.41,15.44,67.08,53bacc23-909f-4b55-bf28-9c5520b0bfd2,2024-02-23 18:26:59\n",
      "19,57,8598,1603,9,fair,major injury,146.68,29.6,139.59,d504d5d9-af5e-44bf-a008-2af79f200f98,2023-12-17 05:54:31\n",
      "3,77,300,1930,0,fair,minor injury,198.86,19.16,133.64,c920913f-b22f-41ee-a612-7d28c8b33222,2024-02-09 23:19:18\n",
      "1,112,4622,3341,8,poor,major injury,3.17,12.6,104.75,f72ab633-59b4-40f7-a35d-173b6fec091b,2024-08-06 21:56:14\n",
      "16,94,12806,3439,7,excellent,major injury,125.24,22.55,90.32,8838e7df-e1ee-471e-8769-995f7c209528,2024-05-08 13:36:34\n",
      "15,186,1556,2653,15,good,major injury,216.99,18.26,90.59,bab89909-9ca5-4eab-b7a6-b12cef90cd3e,2024-01-14 06:51:34\n",
      "6,63,143,1923,1,good,major injury,83.26,8.91,62.1,b40c4423-d935-492f-91f6-9a28066ef60f,2024-05-23 06:36:00\n",
      "5,166,19512,3576,12,excellent,major injury,114.87,7.56,111.67,73b56755-f569-4cc0-a1b3-586033ea49c0,2024-02-12 05:03:37\n",
      "1,121,5803,1161,6,excellent,major injury,93.21,5.16,107.57,71fa787d-c52b-4bb2-b3d4-1d6a417d4eb9,2023-12-03 20:19:37\n",
      "8,54,2420,3615,17,excellent,healthy,210.47,8.81,178.13,57480134-012c-4d97-b2ef-8f49e5a91525,2024-08-07 21:15:51\n",
      "15,100,16475,2666,15,excellent,healthy,94.15,27.87,56.01,0b15889d-3d92-49c7-a7d1-d76e3270b838,2024-06-22 02:21:47\n",
      "2,187,1706,4941,11,good,minor injury,48.62,6.74,80.99,efd4d1de-1776-494f-a310-e8a5eeb17433,2024-09-01 00:02:09\n",
      "11,118,12669,982,1,poor,minor injury,104.43,7.69,144.69,165079bf-c85e-45d9-b681-336e7b209b9b,2024-01-02 18:11:27\n",
      "10,182,8996,1809,6,poor,healthy,63.14,9.63,62.61,1fbc0f8c-ed30-4bf5-815e-e8767c6e8d05,2024-02-20 21:23:06\n",
      "2,197,814,2957,12,poor,minor injury,138.0,15.79,192.74,749c4b23-3725-461e-bd49-25c26bc23d15,2023-10-28 18:05:51\n",
      "20,61,6250,135,11,good,healthy,143.9,28.34,113.73,6a61f637-84e5-4253-8d9f-c21a8f408dd5,2024-05-22 06:58:59\n",
      "20,82,6850,1809,8,good,major injury,155.8,8.48,142.05,50d72bfe-1910-4db3-8de8-6fb2a237eead,2024-08-24 20:59:29\n",
      "17,173,3365,3234,7,poor,healthy,117.53,7.44,67.97,b4fb80a0-276c-442a-b886-ac8d5f5274a8,2024-06-21 21:47:50\n",
      "5,142,14863,1579,7,excellent,major injury,186.45,23.39,61.77,5133b791-fd43-499a-8f2d-6a59b753e6d5,2024-05-20 02:05:38\n",
      "3,86,15086,3360,12,fair,minor injury,91.83,28.15,169.8,453d2718-11d8-4bc7-9520-3740b2fae9cc,2023-11-08 15:40:30\n",
      "19,152,5875,4587,3,poor,major injury,85.18,23.98,138.6,2c1f8323-694b-418f-8191-81686f567a66,2024-03-16 00:05:51\n",
      "18,195,3376,2062,16,fair,major injury,41.74,15.17,122.96,9f2f0f87-df1e-4182-8317-68fbbacebaf9,2024-03-29 18:34:03\n",
      "2,80,8613,2004,18,fair,major injury,98.03,25.44,123.27,7bcd293e-96e7-46c4-a209-aae422033695,2024-06-06 01:16:40\n",
      "7,139,5940,813,1,excellent,major injury,128.46,10.93,159.51,ddd60cfa-57d9-435f-8537-bae4779109f7,2024-09-02 02:44:55\n",
      "4,164,18014,855,13,poor,major injury,155.56,23.9,117.15,92409553-b47b-4a34-a28a-8a8aa93a246b,2024-07-06 02:13:49\n",
      "2,159,19997,4721,1,fair,minor injury,144.37,18.78,112.33,577e9f9f-0b3b-4235-8fef-33437a492dc1,2023-12-23 06:45:43\n",
      "16,69,3874,2218,2,poor,healthy,189.69,16.02,101.08,81782a31-4669-4cf0-bf81-9f29717bd82b,2023-12-04 06:30:18\n",
      "3,111,18140,1723,8,excellent,healthy,7.53,18.34,177.74,360eb8aa-ff29-4181-8914-b2df253d57a8,2024-03-02 09:31:34\n",
      "15,144,1733,1075,8,excellent,major injury,162.55,18.27,129.99,60c7c44c-e4e0-4b05-adc0-dbc27873951c,2024-04-11 10:08:14\n",
      "8,171,13010,3859,10,poor,major injury,219.6,14.97,128.81,363a2eb4-e12d-4b81-845c-a58a610d48b1,2024-01-05 20:23:14\n",
      "22,126,12340,3558,0,poor,healthy,120.34,24.61,139.37,05a06b87-32f3-41ab-99a9-8a96e5c18a94,2024-07-11 02:47:46\n",
      "5,184,15564,4279,5,excellent,healthy,205.27,14.37,173.99,831f34ed-8167-435a-8f9d-946eacde6b67,2024-01-29 03:37:00\n",
      "9,189,16106,1525,15,excellent,minor injury,191.1,6.44,125.18,99a2ca98-d9f6-44ea-b828-7c385c0cbb27,2024-09-25 10:30:14\n",
      "22,123,15483,1409,16,poor,healthy,214.3,28.62,62.31,95c75c34-a3d0-429f-a2a6-fd448efb4107,2024-06-26 05:15:10\n",
      "17,118,17367,3758,4,fair,minor injury,136.17,29.48,83.96,24ed051c-5491-40dc-83b0-9a0eaa43fd59,2024-01-10 18:31:14\n",
      "17,151,12721,3022,18,good,minor injury,193.67,23.98,126.24,8d206125-0d0f-470c-8d4f-6e451d7b1d97,2024-09-13 17:55:37\n",
      "21,178,16402,75,12,poor,healthy,120.71,26.09,57.23,74e558c2-9223-4f02-b15a-d924b03aff7b,2023-12-24 12:30:09\n",
      "17,51,14654,1173,4,fair,healthy,208.91,23.15,125.81,ed33543a-3d8a-4839-92c9-ab6c149dffa4,2024-07-28 14:29:28\n",
      "17,117,8493,1772,12,fair,healthy,36.19,7.99,199.1,337b4010-f096-48fb-a417-7910c7e395a7,2024-03-20 14:46:14\n",
      "19,116,8919,1876,19,poor,minor injury,163.91,9.9,54.24,5de91c94-0394-44d4-9b75-9719b243218c,2024-09-10 23:09:35\n",
      "15,165,3435,3919,0,good,minor injury,232.7,20.55,91.82,0b94057f-8f93-4ab5-94b0-700ded5059cb,2024-03-30 04:33:58\n",
      "12,161,2639,2155,16,excellent,healthy,70.92,24.83,153.0,02c70cf9-103a-4034-89ef-85f7f1fe78f9,2024-03-18 02:47:23\n",
      "8,153,14189,2682,7,excellent,minor injury,149.44,27.07,125.58,978ea361-f8f9-4e13-a362-857fc217c1cf,2024-01-09 05:35:02\n",
      "3,59,6361,842,10,fair,major injury,162.38,6.37,69.69,178e3977-3e8b-4996-b842-baa9fdc132bb,2023-12-23 04:58:53\n",
      "2,117,5379,1132,6,poor,minor injury,170.47,6.41,88.46,d8085040-087e-471c-80db-e8c54f54b111,2023-12-29 15:51:41\n",
      "18,76,17498,3338,4,excellent,healthy,172.99,26.2,165.67,49f99c70-a78d-4c95-83f1-542bf255d86c,2024-09-01 02:10:44\n",
      "14,155,16233,4701,20,excellent,major injury,198.62,6.15,127.97,a7734118-f85b-46f1-b3e2-6edc9a5313b5,2024-01-13 11:55:28\n",
      "4,142,2393,1251,3,good,major injury,110.09,21.31,193.81,0be0a5cb-d399-4d53-b012-9b1d3f662e92,2024-04-05 23:28:38\n",
      "6,188,15272,4710,18,good,major injury,152.17,24.62,106.19,c5a65559-a7d0-4f55-8481-ec87d6a86ce0,2024-01-12 07:03:16\n",
      "17,74,1854,1672,4,good,major injury,152.76,7.66,90.5,dcc5fcd8-010e-4047-963a-5f6577ed70d7,2024-06-17 01:53:52\n",
      "16,80,7927,2063,6,excellent,minor injury,143.71,13.77,152.47,63a62e5e-6837-4211-85e5-48b7ad96b1b5,2024-07-01 20:53:12\n",
      "10,111,2503,4886,16,excellent,major injury,65.57,9.83,133.87,e1e05ae7-0d24-404f-b891-d3b0edb37250,2024-04-22 06:25:50\n",
      "6,120,6090,1358,12,excellent,minor injury,140.17,10.06,63.7,a044f3d1-9033-45cf-9a46-81d1dbe5dc20,2024-09-18 20:12:30\n",
      "14,63,3154,3960,1,poor,minor injury,220.61,11.04,61.48,e9a098de-be9a-4b55-b49f-5b1408e153c1,2023-11-23 17:33:57\n",
      "14,184,225,933,13,excellent,healthy,16.74,8.18,174.95,4474a39e-3041-4f01-a3fc-eaa41b52297e,2023-12-01 20:41:34\n",
      "13,156,17594,4408,20,good,major injury,65.47,14.54,152.94,da10a1bc-b11f-4a33-9962-6326364be2f3,2023-12-26 23:04:46\n",
      "6,139,11852,2633,18,fair,healthy,83.87,14.68,83.17,f5c7986c-07fc-4ea6-8c8d-35d0fe65e74b,2024-09-06 01:53:05\n",
      "20,165,6157,346,17,excellent,minor injury,68.04,29.92,162.29,e7f076b3-b7c2-464d-b4de-4c40bbb77ef7,2024-01-06 15:13:14\n",
      "5,145,3439,513,20,fair,major injury,39.22,13.5,58.84,d858b76b-fee9-4997-bd91-9ffbf4a93af5,2024-02-25 04:51:49\n",
      "5,167,4692,2066,18,good,healthy,53.89,5.72,112.65,e7e7d532-9db9-4dce-9ef8-734f249b6770,2024-01-21 00:20:37\n",
      "7,150,1461,2051,2,poor,healthy,24.48,27.11,174.81,ac2bd283-654c-48e0-993e-236d3e04188e,2024-03-12 18:14:34\n",
      "7,52,16682,345,19,good,healthy,64.57,13.93,63.38,9fef5ca3-1dad-4fe8-b0f9-c991968f94a4,2024-09-27 13:55:10\n",
      "6,168,17961,3424,12,good,healthy,84.4,13.08,143.13,5fff56b4-d051-4215-9db0-70d0f4d7f5c7,2024-01-22 23:54:29\n",
      "7,129,1479,3989,16,fair,healthy,71.22,27.76,51.08,0904182a-e180-49a1-96f5-2d0462b2273f,2024-01-19 00:58:19\n",
      "19,157,4759,4213,6,excellent,minor injury,196.49,13.34,139.18,34a33819-98ed-4e6d-bb3e-cc8233a59600,2024-06-29 06:13:46\n",
      "13,134,11272,1079,3,excellent,minor injury,184.2,29.53,78.63,de8f0816-4f5b-460f-869d-0fe5dd089cd0,2023-12-09 10:22:21\n",
      "18,169,5295,718,11,excellent,minor injury,159.56,8.35,154.73,001fade2-9037-4303-89e5-504f6b7789de,2024-04-04 22:25:36\n",
      "6,94,11300,2587,19,poor,minor injury,215.62,28.97,62.75,3d0d8a8b-7d86-4002-9b55-e3b83e9d1073,2024-03-18 20:00:57\n",
      "22,199,18566,2561,5,fair,minor injury,123.46,7.58,64.26,4f13c442-ddac-4537-86c7-b5eb7c9a3469,2024-03-30 12:27:40\n",
      "19,140,17366,3121,14,poor,healthy,146.8,23.84,198.11,d4316bf3-f03c-40ec-adbc-d8290b787f27,2024-08-16 08:14:32\n",
      "9,116,11044,2642,10,good,healthy,68.21,16.64,164.31,e034eafc-706b-4b9f-b3b0-5e112e570b78,2024-07-08 15:26:53\n",
      "3,108,17619,4831,19,excellent,minor injury,191.33,17.35,107.76,781af624-7ca0-4a34-8968-284f570106aa,2024-08-17 15:57:48\n",
      "10,99,15085,3832,20,good,healthy,227.16,8.17,113.51,94ed5468-cf66-4dc4-b6d5-888ad4d7b7a0,2024-08-03 14:09:45\n",
      "16,82,519,3763,11,fair,minor injury,6.41,27.95,156.32,816da7a9-0522-457a-82e1-5aed02417e38,2023-11-15 16:41:39\n",
      "9,126,6019,1032,1,poor,minor injury,31.24,7.12,160.33,d3043fc2-beb6-4dd1-a1cc-51fbbb332a0e,2024-08-26 06:49:43\n",
      "1,161,2735,1748,16,poor,minor injury,158.88,28.63,116.07,fa6841ea-bd7b-4e96-bed5-cb4c41c0a376,2023-12-20 05:26:40\n",
      "11,98,7348,940,0,poor,healthy,47.62,18.65,82.41,7c617f20-e80e-409a-84c0-b030b95f4c9c,2024-09-11 14:56:44\n",
      "4,148,6679,1024,11,excellent,minor injury,189.42,10.65,174.41,f47cb8f0-e6e1-469b-9740-1d282bcb2d14,2024-05-07 22:54:35\n",
      "12,58,14132,676,15,excellent,minor injury,210.35,24.71,55.63,b6175374-f90f-4135-91fd-579e057b245d,2024-06-30 17:12:27\n",
      "3,174,11439,438,4,poor,healthy,17.35,9.47,120.67,d56eefb3-847b-4eaa-866d-3225d2c9dccb,2023-12-15 14:39:14\n",
      "20,143,19452,2182,20,poor,major injury,190.37,23.53,87.77,e5e5a244-f553-4fac-899a-df8d7d2e13e0,2024-03-24 17:37:14\n",
      "20,107,1161,4941,14,excellent,minor injury,18.96,18.92,162.43,ce551174-2bc2-46ad-a332-9763265959f5,2024-10-04 16:51:24\n",
      "12,78,9181,4998,17,fair,minor injury,148.54,15.62,74.12,e0b7e614-7425-4f7d-9947-a714eb44c46f,2024-10-10 15:54:16\n",
      "21,61,5107,1541,8,excellent,major injury,12.5,13.7,105.58,f6e0d5f4-c8de-4b71-916e-0bf86f0063d6,2024-04-02 09:18:12\n",
      "11,143,9163,4425,2,excellent,major injury,50.77,7.55,160.99,e5037184-ddf2-4d7f-83d6-347dc597724c,2024-03-05 10:06:29\n",
      "15,161,3505,2943,6,good,minor injury,134.94,27.52,72.62,d26f3351-4fad-4e0d-b2dd-91988803b386,2024-09-27 06:49:13\n",
      "18,127,13157,2277,9,fair,major injury,179.36,16.72,110.87,f12a7d77-b43b-41bc-a856-afbd1436c709,2023-11-23 21:59:28\n",
      "9,68,11718,1363,5,fair,healthy,105.34,28.38,96.9,7d522198-84ec-43be-8d54-e61ca0520432,2024-03-03 23:35:32\n",
      "19,124,17111,2591,2,excellent,minor injury,51.97,29.28,123.16,4bb8ebf2-9ab2-4470-9c82-06cb222e56fb,2024-04-19 06:52:47\n",
      "18,188,15876,1792,1,good,minor injury,191.93,8.54,137.43,18a84118-8fd3-48eb-ab9b-cfe3d39c0e7d,2023-11-28 14:35:34\n",
      "4,127,11737,2441,16,fair,minor injury,165.71,21.58,192.38,cb4031e0-4962-4fa1-9108-efa17088a4e0,2024-08-10 05:08:48\n",
      "5,129,7235,4494,4,good,major injury,95.11,22.12,94.54,7c044781-311b-42b6-aaa4-dad12ed610a4,2024-09-11 12:52:51\n",
      "7,55,8482,1963,5,fair,major injury,206.34,22.98,65.06,dc1b8e66-c7ea-429c-895e-7784c64b10c7,2023-11-02 13:47:29\n",
      "22,107,5111,2495,15,poor,minor injury,55.24,7.96,173.21,6ccd605d-d5ef-437d-9a7c-2328b2fc253e,2023-11-11 16:01:39\n",
      "6,123,6037,4542,10,poor,minor injury,184.56,8.68,196.77,ac232a62-35a2-4a29-81e4-a0e669825f01,2024-06-12 15:00:38\n",
      "\n",
      "----------------\n",
      "\n",
      "File_Name: stream.py\n",
      "File_Path: backend\\tests\\streaming\\stream.py\n",
      "Code_contents:\n",
      "from concurrent.futures import thread\n",
      "import websockets\n",
      "import requests\n",
      "import json\n",
      "import random\n",
      "import time\n",
      "from datetime import datetime\n",
      "from fastapi import APIRouter\n",
      "\n",
      "router = APIRouter()\n",
      "# Define the WebSocket URL with placeholders for device_id and run_id\n",
      "WEBSOCKET_ENDPOINT_TEMPLATE = \"ws://localhost:8000/send-stream/{device_id}/{run_id}\"\n",
      "\n",
      "DURATION_SECONDS = 500  # Total duration to send data\n",
      "INTERVAL_SECONDS = 0.5  # Interval between data sends\n",
      "MAX_STR_LEN = 3\n",
      "BASE_URL = \"http://localhost:8000\"\n",
      "GEN_TEST_DATA_ENDPOINT = \"/generate-test-data\"\n",
      "\n",
      "def generate_padded_string(schema_type, num):\n",
      "    numstr = str(num)\n",
      "    numlen = len(numstr)\n",
      "    strnum = schema_type +\"_\"+ (\"0\" * (MAX_STR_LEN - numlen)) + numstr\n",
      "    return strnum\n",
      "\n",
      "def generate_string(schema_type, num):\n",
      "    numstr = str(num)\n",
      "    strnum = schema_type + \"_\"+ numstr\n",
      "    return strnum\n",
      "\n",
      "def generate_heart_rate():\n",
      "    return random.randint(55, 150)\n",
      "\n",
      "def check_if_device_exists(name):\n",
      "\n",
      "    url = BASE_URL + \"/devices/\" + name\n",
      "\n",
      "    response = requests.get(url)\n",
      "    status = response.status_code\n",
      "    \n",
      "    if status == 200:\n",
      "        return True\n",
      "    else:\n",
      "        return False\n",
      "\n",
      "def create_device(num, schema_type):\n",
      "    strnum = generate_string(schema_type, num)\n",
      "\n",
      "    if schema_type == \"gps\":\n",
      "        if not check_if_device_exists(strnum):\n",
      "            # Define the payload (device registration details)\n",
      "            payload = {\n",
      "                \"device_name\": strnum,\n",
      "                \"schema\": {\n",
      "                    \"device_name\": strnum,\n",
      "                    \"schema\": {\n",
      "                        \"latitude\": \"float\",\n",
      "                        \"longitude\": \"float\",\n",
      "                        \"timestamp\": \"string\"\n",
      "                    }\n",
      "                }\n",
      "            }   \n",
      "    elif schema_type == \"heart_rate\":\n",
      "        if not check_if_device_exists(strnum):\n",
      "            # Define the payload (device registration details)\n",
      "            payload = {\n",
      "                \"device_name\": strnum,\n",
      "                \"schema\": {\n",
      "                    \"device_name\": strnum,\n",
      "                    \"schema\": {\n",
      "                        \"heart_rate\": \"int\",\n",
      "                        \"timestamp\": \"string\"\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "\n",
      "    url = BASE_URL + \"/register-device\"\n",
      "    # Send a POST request with the JSON payload\n",
      "    response = requests.post(url, json=payload)\n",
      "\n",
      "        # Print the status code and response\n",
      "    print(f\"Request: {payload}\")\n",
      "    print(f\"Status Code: {response.status_code}\")\n",
      "    print(f\"Response JSON: {response.json()}\")\n",
      "\n",
      "async def send_synthetic_data(device_id, run_id, schema_type):\n",
      "    # Format the WebSocket endpoint with the actual device_id and run_id\n",
      "    websocket_endpoint = WEBSOCKET_ENDPOINT_TEMPLATE.format(device_id=device_id, run_id=run_id)\n",
      "\n",
      "    async with websockets.connect(websocket_endpoint) as websocket:\n",
      "\n",
      "        # Initialize the starting position at the center of the pitch for GPS\n",
      "        init_lat = 48.8413634\n",
      "        init_lon = 2.2530693\n",
      "        message_count = 0  # Counter to track the number of messages sent\n",
      "        now = datetime.datetime.now()\n",
      "\n",
      "        if schema_type == \"gps\":\n",
      "            data = {\n",
      "                \"latitude\":  round(init_lat + random.randrange(1, 1000, 1) * 0.0001 * pow(-1, message_count),7),\n",
      "                \"longitude\": round(init_lon + random.randrange(1, 1000, 1) * 0.0001 * pow(-1, message_count), 7),\n",
      "                \"timestamp\": str(now)\n",
      "            }\n",
      "\n",
      "        elif schema_type == \"heart_rate\":\n",
      "            heart_rate = generate_heart_rate()\n",
      "            data = {\n",
      "                \"heart_rate\": heart_rate,\n",
      "                \"timestamp\": str(now)\n",
      "            }\n",
      "\n",
      "            # Convert data to JSON string\n",
      "            data_str = json.dumps(data)\n",
      "\n",
      "            # Send data over WebSocket\n",
      "            await websocket.send(data_str)\n",
      "            print(f\"Sent data from {device_id} (run {run_id}): {data_str}\")\n",
      "\n",
      "            # Increment the message count\n",
      "            message_count += 1\n",
      "\n",
      "            # Wait for the specified interval before sending the next message\n",
      "            thread.sleep(INTERVAL_SECONDS)\n",
      "\n",
      "@router.post(GEN_TEST_DATA_ENDPOINT)\n",
      "def main():\n",
      "    for player in range(1, 21, 1):\n",
      "        create_device(player, \"gps\")\n",
      "        create_device(player, \"player_heart_rate\")\n",
      "        for run in range(1, 11, 1):\n",
      "            run_id = generate_padded_string(\"run\", run)\n",
      "            device_id = generate_string(\"gps\", player)\n",
      "            send_synthetic_data(device_id, run_id, \"gps\")\n",
      "            device_id = generate_string(\"player_heart_rate\", player)\n",
      "            send_synthetic_data(device_id, run_id, \"player_heart_rate\")\n",
      "\n",
      "----------------\n",
      "\n",
      "File_Name: file_management.py\n",
      "File_Path: utils\\file_management.py\n",
      "Code_contents:\n",
      "import os\n",
      "import json\n",
      "from typing import Dict\n",
      "\n",
      "from fastapi import HTTPException\n",
      "\n",
      "def kafka_topic_name(device_id: str, run_id: str) -> str:\n",
      "    \"\"\"Returns the Kafka topic name based on the device_id and run_id.\"\"\"\n",
      "    return f\"{device_id}_{run_id}\"\n",
      "\n",
      "\n",
      "def create_folder(folder_path: str):\n",
      "    \"\"\"Create a folder if it does not exist.\"\"\"\n",
      "    os.makedirs(folder_path, exist_ok=True)\n",
      "\n",
      "\n",
      "def save_json_file(file_path: str, data: dict):\n",
      "    \"\"\"Save a dictionary as a JSON file.\"\"\"\n",
      "    with open(file_path, \"w\") as file:\n",
      "        json.dump(data, file, indent=4)\n",
      "\n",
      "\n",
      "def convert_model_to_json(model):\n",
      "    \"\"\"Convert a Pydantic model to a JSON serializable dictionary.\"\"\"\n",
      "    return json.loads(model.model_dump_json())\n",
      "\n",
      "\n",
      "def load_json_file(file_path: str):\n",
      "    \"\"\"Loads a JSON file and returns its content as a dictionary.\"\"\"\n",
      "    try:\n",
      "        with open(file_path, \"r\") as json_file:\n",
      "            return json.load(json_file)\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=f\"Failed to load JSON file: {e}\")\n",
      "\n",
      "\n",
      "def device_exists(schema_path: str, device_name: str, raise_error_if_not_found: bool = False):\n",
      "    \"\"\"\n",
      "    Checks if a device with the given name exists and returns the schema if it does.\n",
      "    Optionally raises an HTTPException if the device is not found.\n",
      "    \"\"\"\n",
      "    schema_file_path = os.path.join(schema_path, f\"{device_name}.json\")\n",
      "    \n",
      "    if os.path.exists(schema_file_path):\n",
      "        return load_json_file(schema_file_path)\n",
      "    \n",
      "    if raise_error_if_not_found:\n",
      "        raise HTTPException(status_code=404, detail=f\"Device '{device_name}' not found.\")\n",
      "    \n",
      "    return None\n",
      "\n",
      "def validate_data(data: dict, schema: dict) -> bool:\n",
      "    \"\"\"\n",
      "    Validates the data against the provided schema.\n",
      "    Prints expected vs. received data types for each key.\n",
      "    Returns True if data is valid, False otherwise.\n",
      "    \"\"\"\n",
      "    # Check for extra or missing keys\n",
      "    if set(data.keys()) != set(schema.keys()):\n",
      "        print(\"Mismatch in keys: \", f\"Expected {set(schema.keys())}, but got {set(data.keys())}\")\n",
      "        return False\n",
      "\n",
      "    for key, expected_data_type in schema.items():\n",
      "        if key not in data:\n",
      "            print(f\"Missing key: {key} in data\")\n",
      "            return False\n",
      "\n",
      "        received_value = data[key]\n",
      "        received_data_type = type(received_value).__name__\n",
      "\n",
      "        if expected_data_type == \"float\":\n",
      "            if not isinstance(received_value, (float, int)):  # Allow int for float\n",
      "                print(f\"Key: '{key}', Expected: float, Received: {received_data_type}\")\n",
      "                return False\n",
      "        elif expected_data_type == \"int\":\n",
      "            if not isinstance(received_value, int):\n",
      "                print(f\"Key: '{key}', Expected: int, Received: {received_data_type}\")\n",
      "                return False\n",
      "        elif expected_data_type == \"string\":\n",
      "            if not isinstance(received_value, str):\n",
      "                print(f\"Key: '{key}', Expected: string, Received: {received_data_type}\")\n",
      "                return False\n",
      "        else:\n",
      "            # Unsupported data type in schema\n",
      "            print(f\"Key: '{key}' has an unsupported type: {expected_data_type}\")\n",
      "            return False\n",
      "\n",
      "    # If all keys and data types match\n",
      "    return True\n",
      "\n",
      "\n",
      "def validate_schema_not_empty(register_device_json: Dict) -> None:\n",
      "    \"\"\"\n",
      "    Checks if the schema dictionary is empty by validating its size.\n",
      "    Raises an HTTPException if the dictionary is empty.\n",
      "\n",
      "    Args:\n",
      "        schema (Dict): The schema dictionary to check.\n",
      "\n",
      "    Raises:\n",
      "        HTTPException: If the schema is empty, raises a 400 status error with a specific message.\n",
      "    \"\"\"\n",
      "    if not register_device_json.get('schema') or len(register_device_json.get('schema')) == 0:\n",
      "        raise HTTPException(status_code=400, detail=\"Schema is empty.\")\n",
      "\n",
      "----------------\n",
      "\n",
      "File_Name: kafka_producer.py\n",
      "File_Path: utils\\kafka_producer.py\n",
      "Code_contents:\n",
      "import json\n",
      "import asyncio\n",
      "from typing import Optional, List, Dict, Union\n",
      "\n",
      "from fastapi import HTTPException\n",
      "from aiokafka import AIOKafkaConsumer\n",
      "from kafka import KafkaProducer\n",
      "\n",
      "from backend.config.config import KAFKA_BROKER_URL\n",
      "from utils.file_management import kafka_topic_name\n",
      "\n",
      "async def get_kafka_messages(\n",
      "    device_id: str,\n",
      "    run_id: str,\n",
      "    schema_fields: Dict[str, Union[type, str]],\n",
      "    limit: Optional[int] = None\n",
      ") -> Union[List[Dict[str, Union[str, int, float, bool]]], Dict[str, str]]:\n",
      "    \"\"\"\n",
      "    Asynchronously reads messages from the Kafka topic corresponding to the device_id and run_id.\n",
      "    Retrieves up to 'limit' latest messages with a 5-second timeout if no new messages.\n",
      "\n",
      "    Args:\n",
      "        device_id (str): The ID of the device.\n",
      "        run_id (str): The ID of the run associated with the device.\n",
      "        schema_fields (Dict[str, Union[type, str]]): A dictionary representing the schema fields of the messages.\n",
      "        limit (Optional[int], optional): The maximum number of messages to retrieve. Defaults to None.\n",
      "\n",
      "    Returns:\n",
      "        Union[List[Dict[str, Union[str, int, float, bool]]], Dict[str, str]]: \n",
      "        A list of messages if successful, or a message indicating no new data if timed out.\n",
      "    \"\"\"\n",
      "    topic: str = kafka_topic_name(device_id, run_id)\n",
      "\n",
      "    consumer = AIOKafkaConsumer(\n",
      "        topic,\n",
      "        bootstrap_servers=KAFKA_BROKER_URL,\n",
      "        auto_offset_reset='latest',\n",
      "        enable_auto_commit=False,\n",
      "        group_id=None,\n",
      "        value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n",
      "    )\n",
      "\n",
      "    await consumer.start()\n",
      "    messages: List[Dict[str, Union[str, int, float, bool]]] = []\n",
      "    timeout_seconds: int = 5\n",
      "\n",
      "    try:\n",
      "        while len(messages) < limit:\n",
      "            try:\n",
      "                message = await asyncio.wait_for(consumer.getone(), timeout=timeout_seconds)\n",
      "                value = message.value\n",
      "\n",
      "                if set(value.keys()) != set(schema_fields.keys()):\n",
      "                    raise ValueError(f\"Invalid message schema for message: {value}\")\n",
      "\n",
      "                messages.append(value)\n",
      "\n",
      "            except asyncio.TimeoutError:\n",
      "                # If we time out, return the messages we have gathered so far\n",
      "                break\n",
      "\n",
      "        return messages\n",
      "\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=f\"Error reading from Kafka topic: {str(e)}\")\n",
      "\n",
      "    finally:\n",
      "        await consumer.stop()\n",
      "\n",
      "\n",
      "class KafkaProducerWrapper:\n",
      "    def __init__(self, bootstrap_servers=KAFKA_BROKER_URL):\n",
      "        self.producer = KafkaProducer(\n",
      "            bootstrap_servers=bootstrap_servers,\n",
      "            value_serializer=lambda v: json.dumps(v).encode(\"utf-8\"),\n",
      "        )\n",
      "\n",
      "    def send(self, topic: str, value: dict):\n",
      "        self.producer.send(topic, value=value)\n",
      "\n",
      "    def flush(self):\n",
      "        self.producer.flush()\n",
      "\n",
      "    def close(self):\n",
      "        self.producer.close()\n",
      "\n",
      "\n",
      "def send_data_to_kafka(producer: KafkaProducerWrapper, topic: str, data: dict):\n",
      "    \"\"\"\n",
      "    Sends data to Kafka using the provided Kafka producer.\n",
      "    \"\"\"\n",
      "    producer.send(topic, value=data)\n",
      "\n",
      "\n",
      "----------------\n",
      "\n",
      "File_Name: maths_functions.py\n",
      "File_Path: utils\\maths_functions.py\n",
      "Code_contents:\n",
      "from datetime import datetime\n",
      "import math\n",
      "\n",
      "def calculate_speed_from_messages(messages):\n",
      "    \"\"\"\n",
      "    Calculate the speed using the last two messages containing GPS coordinates.\n",
      "\n",
      "    Args:\n",
      "        messages (List[Dict]): The last two Kafka messages containing 'latitude', 'longitude', and 'timestamp'.\n",
      "\n",
      "    Returns:\n",
      "        float: The calculated speed in meters per second.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        # Ensure messages are sorted correctly (the latest should be the second message)\n",
      "        point1, point2 = messages[0], messages[1]\n",
      "        lat1, lon1, time1 = point1[\"latitude\"], point1[\"longitude\"], point1[\"timestamp\"]\n",
      "        lat2, lon2, time2 = point2[\"latitude\"], point2[\"longitude\"], point2[\"timestamp\"]\n",
      "\n",
      "        # Convert timestamps to datetime objects\n",
      "        time1 = datetime.fromisoformat(time1)\n",
      "        time2 = datetime.fromisoformat(time2)\n",
      "\n",
      "        # Calculate the time difference in seconds\n",
      "        time_diff = (time2 - time1).total_seconds()\n",
      "\n",
      "        # If time difference is zero, avoid division by zero\n",
      "        if time_diff == 0:\n",
      "            raise ValueError(\"Time difference between the two points is zero.\")\n",
      "\n",
      "        # Calculate the distance using the Haversine formula\n",
      "        distance = haversine_distance(lat1, lon1, lat2, lon2)\n",
      "\n",
      "        # Calculate the speed (distance/time)\n",
      "        speed = distance / time_diff\n",
      "\n",
      "        return speed\n",
      "\n",
      "    except Exception as e:\n",
      "        raise ValueError(f\"Error calculating speed: {str(e)}\")\n",
      "\n",
      "\n",
      "def haversine_distance(lat1, lon1, lat2, lon2):\n",
      "    \"\"\"\n",
      "    Calculate the great-circle distance between two points on the Earth's surface given their latitude and longitude.\n",
      "    Returns the distance in meters.\n",
      "\n",
      "    Args:\n",
      "        lat1 (float): Latitude of the first point.\n",
      "        lon1 (float): Longitude of the first point.\n",
      "        lat2 (float): Latitude of the second point.\n",
      "        lon2 (float): Longitude of the second point.\n",
      "    \n",
      "    Returns:\n",
      "        float: The calculated distance in meters.\n",
      "    \"\"\"\n",
      "    R = 6371000  # Radius of Earth in meters\n",
      "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
      "    delta_phi = math.radians(lat2 - lat1)\n",
      "    delta_lambda = math.radians(lon2 - lon1)\n",
      "\n",
      "    a = (math.sin(delta_phi / 2) ** 2 +\n",
      "         math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2) ** 2)\n",
      "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
      "\n",
      "    distance = R * c\n",
      "    return distance\n",
      "\n",
      "def calculate_acceleration_from_messages(messages):\n",
      "    \"\"\"\n",
      "    Calculate acceleration using the last three messages containing GPS coordinates and timestamps.\n",
      "\n",
      "    Args:\n",
      "        messages (List[Dict]): The last three Kafka messages containing 'latitude', 'longitude', and 'timestamp'.\n",
      "\n",
      "    Returns:\n",
      "        float: The calculated acceleration in meters per second squared.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        # Ensure messages are sorted correctly\n",
      "        point1, point2, point3 = messages[0], messages[1], messages[2]\n",
      "        \n",
      "        # Extract latitudes, longitudes, and timestamps\n",
      "        lat1, lon1, time1 = point1[\"latitude\"], point1[\"longitude\"], point1[\"timestamp\"]\n",
      "        lat2, lon2, time2 = point2[\"latitude\"], point2[\"longitude\"], point2[\"timestamp\"]\n",
      "        lat3, lon3, time3 = point3[\"latitude\"], point3[\"longitude\"], point3[\"timestamp\"]\n",
      "\n",
      "        # Convert timestamps to datetime objects\n",
      "        time1, time2, time3 = datetime.fromisoformat(time1), datetime.fromisoformat(time2), datetime.fromisoformat(time3)\n",
      "\n",
      "        # Calculate speeds at two intervals\n",
      "        speed1 = calculate_speed_from_points(lat1, lon1, time1, lat2, lon2, time2)\n",
      "        speed2 = calculate_speed_from_points(lat2, lon2, time2, lat3, lon3, time3)\n",
      "\n",
      "        # Calculate time difference between the two intervals\n",
      "        time_diff = (time3 - time1).total_seconds()\n",
      "\n",
      "        if time_diff == 0:\n",
      "            raise ValueError(\"Time difference between the points is zero.\")\n",
      "\n",
      "        # Calculate acceleration (change in speed over time)\n",
      "        acceleration = (speed2 - speed1) / time_diff\n",
      "\n",
      "        return acceleration\n",
      "\n",
      "    except Exception as e:\n",
      "        raise ValueError(f\"Error calculating acceleration: {str(e)}\")\n",
      "\n",
      "\n",
      "def calculate_speed_from_points(lat1, lon1, time1, lat2, lon2, time2):\n",
      "    \"\"\"\n",
      "    Helper function to calculate speed between two points.\n",
      "\n",
      "    Args:\n",
      "        lat1, lon1 (float): Latitude and longitude of the first point.\n",
      "        time1 (datetime): Timestamp of the first point.\n",
      "        lat2, lon2 (float): Latitude and longitude of the second point.\n",
      "        time2 (datetime): Timestamp of the second point.\n",
      "\n",
      "    Returns:\n",
      "        float: The speed between the two points in meters per second.\n",
      "    \"\"\"\n",
      "    time_diff = (time2 - time1).total_seconds()\n",
      "    if time_diff == 0:\n",
      "        raise ValueError(\"Time difference between the two points is zero.\")\n",
      "\n",
      "    distance = haversine_distance(lat1, lon1, lat2, lon2)\n",
      "    speed = distance / time_diff\n",
      "\n",
      "    return speed\n",
      "----------------\n",
      "\n",
      "File_Name: spark_processor.py\n",
      "File_Path: utils\\spark_processor.py\n",
      "Code_contents:\n",
      "import asyncio\n",
      "import math\n",
      "from concurrent.futures import ThreadPoolExecutor\n",
      "from datetime import datetime\n",
      "\n",
      "from fastapi import HTTPException\n",
      "from pyspark.sql import SparkSession\n",
      "from pyspark.sql import functions as F\n",
      "from pyspark.sql.functions import col, from_json\n",
      "from pyspark.sql.types import StructField, StructType,  FloatType, IntegerType, StringType\n",
      "\n",
      "from utils.file_management import device_exists, kafka_topic_name\n",
      "from backend.config.config import MAX_WORKERS, SPARK_APP_NAME, SPARK_MASTER_URL, KAFKA_BROKER_URL, SCHEMA_DATA_PATH\n",
      "\n",
      "DEVICE_SCHEMA_PATH = SCHEMA_DATA_PATH\n",
      "\n",
      "# Create a ThreadPoolExecutor for concurrent Spark jobs\n",
      "executor = ThreadPoolExecutor(max_workers=MAX_WORKERS)\n",
      "\n",
      "def check_if_session_exists():\n",
      "    \"\"\"Check if a Spark session exists.\"\"\"\n",
      "    spark = SparkSession.getActiveSession()\n",
      "    if not spark:\n",
      "        return\n",
      "    return spark\n",
      "\n",
      "\n",
      "def convert_schema_to_structtype(schema_fields):\n",
      "    \"\"\"\n",
      "    Convert schema_fields dictionary into a PySpark StructType schema.\n",
      "    \"\"\"\n",
      "    struct_fields = []\n",
      "    \n",
      "    for field_name, field_type in schema_fields.items():\n",
      "        if field_type == \"float\":\n",
      "            struct_fields.append(StructField(field_name, FloatType(), True))\n",
      "        elif field_type == \"int\":\n",
      "            struct_fields.append(StructField(field_name, IntegerType(), True))\n",
      "        elif field_type == \"string\":\n",
      "            struct_fields.append(StructField(field_name, StringType(), True))\n",
      "        else:\n",
      "            raise ValueError(f\"Unsupported data type: {field_type}\")\n",
      "\n",
      "    return StructType(struct_fields)\n",
      "\n",
      "\n",
      "def get_spark_session(session_name=\"Kafka Streaming Stats\"):\n",
      "    \"\"\"Create or get an existing Spark session.\"\"\"\n",
      "    spark = check_if_session_exists()  # Check if a session exists\n",
      "    if not spark:  # If no session exists, create a new one\n",
      "        spark = SparkSession.builder \\\n",
      "            .appName(session_name) \\\n",
      "            .master(SPARK_MASTER_URL) \\\n",
      "            .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3\") \\\n",
      "            .config(\"spark.sql.warehouse.dir\", \"/tmp/spark-warehouse\") \\\n",
      "            .config(\"spark.sql.catalogImplementation\", \"in-memory\") \\\n",
      "            .config(\"spark.local.dir\", \"/tmp/spark-temp\") \\\n",
      "            .getOrCreate()\n",
      "    return spark\n",
      "\n",
      "\n",
      "def read_kafka_stream(spark, kafka_topic: str, offset: str = \"latest\"):\n",
      "    \"\"\"\n",
      "    Reads and returns a streaming DataFrame from Kafka for the given topic.\n",
      "    \"\"\"\n",
      "    return spark.readStream \\\n",
      "        .format(\"kafka\") \\\n",
      "        .option(\"kafka.bootstrap.servers\", KAFKA_BROKER_URL) \\\n",
      "        .option(\"subscribe\", kafka_topic) \\\n",
      "        .option(\"startingOffsets\", offset) \\\n",
      "        .load()\n",
      "\n",
      "\n",
      "def read_kafka_batch(spark, kafka_topic: str, offset: str = \"earliest\"):\n",
      "    \"\"\"\n",
      "    Reads and returns a batch DataFrame from Kafka for the given topic.\n",
      "    \"\"\"\n",
      "    return spark.read \\\n",
      "        .format(\"kafka\") \\\n",
      "        .option(\"kafka.bootstrap.servers\", KAFKA_BROKER_URL) \\\n",
      "        .option(\"subscribe\", kafka_topic) \\\n",
      "        .option(\"startingOffsets\", offset) \\\n",
      "        .load()\n",
      "\n",
      "\n",
      "def write_stream_to_memory(stream_df, table_name, trigger_time=5):\n",
      "    \"\"\"\n",
      "    Write the streaming DataFrame to an in-memory table with the given name.\n",
      "    \"\"\"\n",
      "    return stream_df.writeStream \\\n",
      "        .outputMode(\"append\") \\\n",
      "        .format(\"memory\") \\\n",
      "        .queryName(table_name) \\\n",
      "        .trigger(processingTime=f'{trigger_time} seconds') \\\n",
      "        .start()\n",
      "\n",
      "\n",
      "def read_kafka_data(device_id: str, schema_fields: dict, time_window_seconds: int = None):\n",
      "    \"\"\"\n",
      "    Read and process Kafka data based on the device ID and schema.\n",
      "    If time_window_seconds is provided, it filters the data to only include the last messages within that time window.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        # Create Spark session\n",
      "        spark = get_spark_session()\n",
      "        \n",
      "        # Print Spark session and configuration details\n",
      "        print(\"Spark session information:\")\n",
      "        print(f\" - App Name: {spark.sparkContext.appName}\")\n",
      "        print(f\" - Master URL: {spark.sparkContext.master}\")\n",
      "        print(f\" - Spark UI URL: {spark.sparkContext.uiWebUrl}\")\n",
      "        print(f\" - Spark Version: {spark.version}\")\n",
      "        \n",
      "        # Get Spark configuration settings\n",
      "        print(\"Spark Configuration:\")\n",
      "        for key, value in spark.sparkContext.getConf().getAll():\n",
      "            print(f\"   {key}: {value}\")\n",
      "        \n",
      "        # Print worker details\n",
      "        print(\"Spark Workers Information:\")\n",
      "        print(f\" - Executor memory: {spark.sparkContext.getConf().get('spark.executor.memory')}\")\n",
      "        print(f\" - Executor cores: {spark.sparkContext.getConf().get('spark.executor.cores')}\")\n",
      "        \n",
      "        # Convert the dictionary schema_fields into a PySpark StructType\n",
      "        struct_schema = convert_schema_to_structtype(schema_fields)\n",
      "\n",
      "        # Read data from Kafka topic in batch mode using the \"earliest\" offset\n",
      "        kafka_df = read_kafka_batch(spark, device_id)\n",
      "\n",
      "        # Convert the binary 'value' column from Kafka to a string and drop the Kafka timestamp\n",
      "        value_df = kafka_df.selectExpr(\"CAST(value AS STRING) as json_string\")\n",
      "\n",
      "        # Parse the JSON string into a DataFrame using the StructType schema\n",
      "        json_df = value_df.select(\n",
      "            from_json(col(\"json_string\"), struct_schema).alias(\"data\")\n",
      "        )\n",
      "\n",
      "        # Flatten the nested 'data' column to access individual fields\n",
      "        data_df = json_df.select(\"data.*\")\n",
      "\n",
      "        # Ensure the timestamp column is cast properly as a timestamp type\n",
      "        data_df = data_df.withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
      "\n",
      "        # If a time window is provided, filter the data based on the timestamp\n",
      "        if time_window_seconds is not None:\n",
      "            # Get the current maximum timestamp\n",
      "            max_timestamp = data_df.agg(F.max(\"timestamp\")).collect()[0][0]\n",
      "\n",
      "            # Filter the data to only include records within the specified time window\n",
      "            filtered_data_df = data_df.filter(\n",
      "                col(\"timestamp\") >= F.expr(f\"timestamp'{max_timestamp}' - interval {time_window_seconds} seconds\")\n",
      "            )\n",
      "\n",
      "            return filtered_data_df\n",
      "\n",
      "        # If no time window is specified, return the entire DataFrame\n",
      "        return data_df\n",
      "\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=f\"Error reading Kafka data: {str(e)}\")\n",
      "\n",
      "\n",
      "# Dictionary to keep track of active streaming queries by device_id\n",
      "streaming_queries = {}\n",
      "\n",
      "def start_streaming_aggregation(kafka_topic: str, schema_fields: dict, window_seconds: int, triggers: dict, table_preappend: str = None, kafka_streaming_app: str = SPARK_APP_NAME, exclude_normal: bool = False):\n",
      "    \"\"\"\n",
      "    Set up a streaming threshold check on the Kafka stream for the given Kafka topic.\n",
      "    If the query is already running, it will return the existing query.\n",
      "    \"\"\"\n",
      "    # Create Spark session\n",
      "    spark = get_spark_session(kafka_streaming_app)\n",
      "    \n",
      "    table_name = f\"{table_preappend}_{kafka_topic}\" if table_preappend else kafka_topic\n",
      "\n",
      "    # Check if a streaming query with this Kafka topic is already running\n",
      "    active_queries = [q for q in spark.streams.active if q.name == table_name]\n",
      "\n",
      "    if active_queries:\n",
      "        print(f\"Streaming query for topic {kafka_topic} is already running.\")\n",
      "        return active_queries[0]\n",
      "\n",
      "    # Convert the dictionary schema_fields into a PySpark StructType\n",
      "    struct_schema = StructType([\n",
      "        StructField(field, FloatType() if ftype == \"float\" else StringType() if ftype == \"string\" else IntegerType(), True)\n",
      "        for field, ftype in schema_fields.items()\n",
      "    ])\n",
      "\n",
      "    # Read the streaming data from Kafka\n",
      "    kafka_stream = read_kafka_stream(spark, kafka_topic)\n",
      "\n",
      "    # Convert the binary 'value' column from Kafka to a string and drop the Kafka timestamp\n",
      "    value_df = kafka_stream.selectExpr(\"CAST(value AS STRING) as json_string\")\n",
      "\n",
      "    # Parse the JSON string into a DataFrame using the StructType schema\n",
      "    json_df = value_df.select(\n",
      "        from_json(col(\"json_string\"), struct_schema).alias(\"data\")\n",
      "    )\n",
      "\n",
      "    # Flatten the nested 'data' column to access individual fields, including the timestamp from the JSON data\n",
      "    data_df = json_df.select(\"data.*\")\n",
      "\n",
      "    # Ensure the timestamp column from the JSON is cast as a timestamp type\n",
      "    data_df = data_df.withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
      "\n",
      "    status_columns = []\n",
      "    for field, (min_val, max_val) in triggers.items():\n",
      "        if field in schema_fields and schema_fields[field] in [\"float\", \"int\"]:\n",
      "            print(f\"Adding status check for field: {field} with min: {min_val} and max: {max_val}.\")\n",
      "            \n",
      "            status_column = F.when(F.col(field) < F.lit(min_val), \"low\") \\\n",
      "                             .when(F.col(field) > F.lit(max_val), \"high\") \\\n",
      "                             .otherwise(\"normal\")\n",
      "            \n",
      "            status_column_name = f\"{field}_status\"\n",
      "            data_df = data_df.withColumn(status_column_name, status_column)\n",
      "            status_columns.append(status_column_name)\n",
      "\n",
      "    combined_condition = F.lit(False)\n",
      "    for col_name in status_columns:\n",
      "        combined_condition = combined_condition | (F.col(col_name) != \"normal\")\n",
      "\n",
      "    # Apply the filter to exclude rows where all status columns are 'normal'\n",
      "    data_df = data_df.filter(combined_condition).coalesce(1)\n",
      "\n",
      "    # Write the result with status checks to an in-memory table with a unique query name for this device\n",
      "    query = write_stream_to_memory(data_df, table_name, window_seconds)\n",
      "\n",
      "    # Store the reference to the query so we can manage it later\n",
      "    streaming_queries[kafka_topic] = query\n",
      "\n",
      "    print(f\"Streaming initialized for topic: {kafka_topic}\")\n",
      "\n",
      "    return query\n",
      "\n",
      "\n",
      "def get_aggregation_function(agg_type):\n",
      "    \"\"\"Return the appropriate aggregation function based on the aggregation type.\"\"\"\n",
      "    if agg_type == 'average':\n",
      "        return F.avg\n",
      "    elif agg_type == 'max':\n",
      "        return F.max\n",
      "    else:\n",
      "        raise ValueError(f\"Unsupported aggregation type: {agg_type}\")\n",
      "\n",
      "\n",
      "def generate_aggregations(schema_fields, agg_type):\n",
      "    \"\"\"\n",
      "    Generate dynamic aggregation expressions based on schema and aggregation type.\n",
      "    \"\"\"\n",
      "    agg_func = get_aggregation_function(agg_type)\n",
      "    \n",
      "    aggregations = []\n",
      "    for field, field_type in schema_fields.items():\n",
      "        if field_type == \"float\" or field_type == \"int\":  # Aggregate only numeric fields\n",
      "            aggregations.append(agg_func(F.col(field)).alias(f\"{agg_type}_{field}\"))\n",
      "    return aggregations\n",
      "\n",
      "\n",
      "# Function to process Kafka stream and calculate dynamic aggregates\n",
      "def get_kafka_batch_aggregates(device_id: str, schema_fields: dict, agg_type: str):\n",
      "    \"\"\"\n",
      "    Process the Kafka batch data for the given device ID and schema fields.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        # Read the processed Kafka DataFrame using the new utility function (no time window for aggregation)\n",
      "        data_df = read_kafka_data(device_id, schema_fields)\n",
      "\n",
      "        # Dynamically generate aggregation expressions based on aggregation type\n",
      "        aggregations = generate_aggregations(schema_fields, agg_type)\n",
      "\n",
      "        # Perform aggregation\n",
      "        aggregated_df = data_df.agg(*aggregations)\n",
      "\n",
      "        # Collect the result as a dictionary\n",
      "        result = aggregated_df.collect()[0].asDict()\n",
      "\n",
      "        return result\n",
      "\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=f\"Error processing Kafka batch: {str(e)}\")\n",
      "\n",
      "\n",
      "def get_latest_stats(table: str, query: str):\n",
      "    \"\"\"\n",
      "    Retrieve the latest stats from the in-memory table for the given device ID based on the provided query.\n",
      "    \"\"\"\n",
      "    spark = check_if_session_exists()\n",
      "    if spark is None:\n",
      "        raise Exception(\"No active Spark session found\")\n",
      "\n",
      "    # Check if the view exists before querying\n",
      "    if not spark.catalog.tableExists(table):\n",
      "        raise Exception(f\"The table or view {table} cannot be found.\")\n",
      "\n",
      "    # Format the query to safely include the view name\n",
      "    try:\n",
      "        formatted_query = query.format(table=table)\n",
      "    except KeyError:\n",
      "        raise Exception(\"The query string must include '{table}' placeholder for the view name.\")\n",
      "\n",
      "    # Execute the SQL query\n",
      "    try:\n",
      "        stats_df = spark.sql(formatted_query)\n",
      "        return stats_df.collect()\n",
      "    except Exception as e:\n",
      "        raise Exception(f\"Error executing query: {str(e)}\")\n",
      "\n",
      "# Generic endpoint function for getting aggregated stats\n",
      "async def get_aggregated_stats(device_id: str, run_id: str, agg_type: str):\n",
      "    loop = asyncio.get_event_loop()\n",
      "    try:\n",
      "        # Retrieve the device schema from file\n",
      "        device_schema = device_exists(DEVICE_SCHEMA_PATH, device_id, raise_error_if_not_found=True)\n",
      "        schema_fields = device_schema[\"schema\"]  # Extract actual schema fields\n",
      "\n",
      "        # Get the Kafka stream and apply dynamic aggregation (run in a thread to avoid blocking)\n",
      "        kafka_topic = kafka_topic_name(device_id, run_id)\n",
      "        result = await loop.run_in_executor(executor, get_kafka_batch_aggregates, kafka_topic, schema_fields, agg_type)\n",
      "\n",
      "        # Format the result dynamically\n",
      "        response = {\"device_id\": device_id, \"aggregation\": agg_type}\n",
      "        for field in schema_fields.keys():\n",
      "            if schema_fields[field] in [\"float\", \"int\"]:  # Include only numeric fields in the response\n",
      "                response[f\"{agg_type}_{field}\"] = result.get(f\"{agg_type}_{field}\", None)\n",
      "\n",
      "        return response\n",
      "\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=f\"Failed to fetch {agg_type} stats: {str(e)}\")\n",
      "\n",
      "\n",
      "# Function to start the streaming aggregation for a device\n",
      "def initialize_streaming(device_id: str, run_id: str, triggers: dict, window_seconds: int = 5, table_preappend: str = None, exclude_normal: bool = False):\n",
      "    \"\"\"\n",
      "    Initialize the streaming aggregation for the given device and run ID if it's not already running.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        # Retrieve the device schema from file\n",
      "        device_schema = device_exists(DEVICE_SCHEMA_PATH, device_id, raise_error_if_not_found=True)\n",
      "        schema_fields = device_schema[\"schema\"]  # Extract actual schema fields\n",
      "\n",
      "        # Create the Kafka topic from device_id and run_id\n",
      "        kafka_topic = kafka_topic_name(device_id, run_id)\n",
      "\n",
      "        # Start the streaming aggregation with the triggers and optional table_preappend\n",
      "        start_streaming_aggregation(kafka_topic, schema_fields, window_seconds, triggers, table_preappend, exclude_normal)\n",
      "\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=f\"Failed to start streaming aggregation: {str(e)}\")\n",
      "    \n",
      "----------------\n",
      "\n",
      "File_Name: __init__.py\n",
      "File_Path: utils\\__init__.py\n",
      "Code_contents:\n",
      "\n",
      "----------------\n",
      "\n",
      "\n",
      "Required Libraries:\n",
      ".kafka_topics\n",
      "aiokafka\n",
      "asyncio\n",
      "backend.api.get_historical_stats\n",
      "backend.api.get_live_stats\n",
      "backend.api.kafka_topics\n",
      "backend.api.register_device\n",
      "backend.api.send_stream\n",
      "backend.config.config\n",
      "backend.models.schemas\n",
      "backend.tests.streaming.stream\n",
      "concurrent.futures\n",
      "confluent_kafka.admin\n",
      "datetime\n",
      "fastapi\n",
      "json\n",
      "kafka\n",
      "math\n",
      "os\n",
      "pydantic\n",
      "pyspark.sql\n",
      "pyspark.sql.functions\n",
      "pyspark.sql.types\n",
      "random\n",
      "requests\n",
      "sse_starlette.sse\n",
      "starlette.responses\n",
      "time\n",
      "typing\n",
      "utils.file_management\n",
      "utils.kafka_producer\n",
      "utils.maths_functions\n",
      "utils.spark_processor\n",
      "websockets\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def get_project_info(folder_path, ignore_extensions=None, code_subfolders=None, output_modules=False):\n",
    "    if ignore_extensions is None:\n",
    "        ignore_extensions = []\n",
    "    else:\n",
    "        # Ensure all extensions start with a dot and are lowercase\n",
    "        ignore_extensions = [\n",
    "            ext.lower() if ext.startswith('.') else f'.{ext.lower()}' \n",
    "            for ext in ignore_extensions\n",
    "        ]\n",
    "    \n",
    "    if code_subfolders is None:\n",
    "        code_subfolders = []\n",
    "    else:\n",
    "        # Normalize subfolder paths (remove trailing slashes)\n",
    "        code_subfolders = [os.path.normpath(subfolder) for subfolder in code_subfolders]\n",
    "    \n",
    "    project_structure = []\n",
    "    file_details = []\n",
    "    libraries = set()  # To collect unique library imports\n",
    "\n",
    "    # Precompute absolute paths for code_subfolders for quick checks\n",
    "    code_subfolders_abs = [\n",
    "        os.path.normpath(os.path.join(folder_path, subfolder)) \n",
    "        for subfolder in code_subfolders\n",
    "    ]\n",
    "\n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # Exclude the .git and __pycache__ folders from the walk\n",
    "        if '.git' in dirs:\n",
    "            dirs.remove('.git')\n",
    "        if '__pycache__' in dirs:\n",
    "            dirs.remove('__pycache__')\n",
    "\n",
    "        # Compute the relative path from the folder_path\n",
    "        relative_root = os.path.relpath(root, folder_path)\n",
    "        if relative_root == \".\":\n",
    "            relative_root = \"\"\n",
    "\n",
    "        # Add directories to the project structure\n",
    "        for dir_name in dirs:\n",
    "            if '__pycache__' not in dir_name:  # Skip __pycache__ folders\n",
    "                dir_path = os.path.join(relative_root, dir_name)\n",
    "                project_structure.append(os.path.join(dir_path, \"\"))  # Adding a trailing slash for directories\n",
    "\n",
    "        # Add files to the project structure\n",
    "        for file_name in files:\n",
    "            # Skip .pyc files and other ignored extensions\n",
    "            if '__pycache__' in file_name or file_name.endswith('.pyc'):\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(relative_root, file_name)\n",
    "            project_structure.append(file_path)\n",
    "\n",
    "            # Determine the file extension\n",
    "            _, file_ext = os.path.splitext(file_name.lower())\n",
    "\n",
    "            # Determine if the current file is inside any of the specified code_subfolders\n",
    "            # A file is inside a code_subfolder if its absolute path starts with any of the code_subfolders' absolute paths\n",
    "            full_file_path = os.path.normpath(os.path.join(root, file_name))\n",
    "            include_content = False\n",
    "            for subfolder_abs in code_subfolders_abs:\n",
    "                # Ensure the subfolder path is a prefix of the file path\n",
    "                # Add a separator to prevent partial matching (e.g., 'src' vs 'src_utils')\n",
    "                if full_file_path.startswith(subfolder_abs + os.sep):\n",
    "                    include_content = True\n",
    "                    break\n",
    "                elif full_file_path == subfolder_abs:\n",
    "                    include_content = True\n",
    "                    break\n",
    "\n",
    "            # Include file details only if it's in specified subfolders and not ignored\n",
    "            if include_content and file_ext not in ignore_extensions:\n",
    "                try:\n",
    "                    with open(full_file_path, 'r', encoding='utf-8') as f:\n",
    "                        content = f.read()\n",
    "                except (UnicodeDecodeError, PermissionError):\n",
    "                    content = \"<Unable to read file contents>\"\n",
    "\n",
    "                relative_file_path = os.path.relpath(full_file_path, folder_path)\n",
    "                file_info = f\"\"\"File_Name: {file_name}\n",
    "File_Path: {relative_file_path}\n",
    "Code_contents:\n",
    "{content}\n",
    "----------------\n",
    "\"\"\"\n",
    "                file_details.append(file_info)\n",
    "\n",
    "                # If output_modules is True, extract libraries from imports\n",
    "                if output_modules:\n",
    "                    imports = re.findall(r'^\\s*(?:from|import)\\s+([\\w\\.]+)', content, re.MULTILINE)\n",
    "                    libraries.update(imports)\n",
    "\n",
    "    # Create the project structure string\n",
    "    structure_str = \"Project Structure:\\n\" + \"\\n\".join(project_structure) + \"\\n\\n\"\n",
    "\n",
    "    # Create the file details string\n",
    "    if file_details:\n",
    "        details_str = \"File Details:\\n\" + \"\\n\".join(file_details)\n",
    "    else:\n",
    "        details_str = \"File Details:\\n<No files to display>\\n----------------\"\n",
    "\n",
    "    # Combine everything into the final output\n",
    "    final_output = structure_str + details_str\n",
    "\n",
    "    # If output_modules is True, add library list for requirements.txt format\n",
    "    if output_modules:\n",
    "        modules_list = \"\\n\".join(sorted(libraries))\n",
    "        final_output += f\"\\n\\nRequired Libraries:\\n{modules_list}\\n\"\n",
    "\n",
    "    return final_output\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    folder = \"./\"  # Replace with your project path\n",
    "    ignore = ['.png', '.jpg', '.md', '.pic', '.pyc', 'pyc', '.json', 'json']  # List of file extensions to ignore\n",
    "    subfolders = ['backend/', 'utils/']  # List of subfolders to include code contents from\n",
    "    project_info = get_project_info(folder, ignore_extensions=ignore, code_subfolders=subfolders, output_modules=True)\n",
    "    print(project_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to register device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering device: gps_2\n",
      "Status Code: 200\n",
      "Response JSON: {'message': \"Device 'gps_2' already exists with the same schema.\"}\n",
      "\n",
      "Registering device: accel_2\n",
      "Status Code: 200\n",
      "Response JSON: {'message': 'Schema for accel_2 saved successfully!'}\n",
      "\n",
      "Registering device: wind_2\n",
      "Status Code: 200\n",
      "Response JSON: {'message': 'Schema for wind_2 saved successfully!'}\n",
      "\n",
      "Registering device: player_temperature_2\n",
      "Status Code: 200\n",
      "Response JSON: {'message': \"Device 'player_temperature_2' already exists with the same schema.\"}\n",
      "\n",
      "Registering device: player_heart_rate_2\n",
      "Status Code: 200\n",
      "Response JSON: {'message': \"Device 'player_heart_rate_2' already exists with the same schema.\"}\n",
      "\n",
      "Status Code: 200\n",
      "Response JSON: {'device_name': 'gps_1', 'schema': {'device_name': 'gps_1', 'schema': {'latitude': 'float', 'longitude': 'float', 'timestamp': 'string'}}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL of the FastAPI endpoint\n",
    "url = \"http://127.0.0.1:8000/register-device\"\n",
    "\n",
    "# Define the payloads for each sensor\n",
    "devices = [\n",
    "    {\n",
    "        \"device_name\": \"gps_2\",\n",
    "        \"schema\": {\n",
    "            \"latitude\": \"float\",\n",
    "            \"longitude\": \"float\",\n",
    "            \"timestamp\": \"string\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"device_name\": \"accel_2\",\n",
    "        \"schema\": {\n",
    "            \"acceleration_x\": \"float\",\n",
    "            \"acceleration_y\": \"float\",\n",
    "            \"acceleration_z\": \"float\",\n",
    "            \"timestamp\": \"string\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"device_name\": \"wind_2\",\n",
    "        \"schema\": {\n",
    "            \"speed\": \"float\",\n",
    "            \"direction\": \"float\",\n",
    "            \"timestamp\": \"string\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"device_name\": \"player_temperature_2\",\n",
    "        \"schema\": {\n",
    "            \"temperature\": \"float\",\n",
    "            \"timestamp\": \"string\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"device_name\": \"player_heart_rate_2\",\n",
    "        \"schema\": {\n",
    "            \"heart_rate\": \"int\",\n",
    "            \"timestamp\": \"string\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Loop over the devices and send a POST request for each one\n",
    "for device in devices:\n",
    "    response = requests.post(url, json=device)\n",
    "    \n",
    "    # Print the status code and response for each device\n",
    "    print(f\"Registering device: {device['device_name']}\")\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Response JSON: {response.json()}\\n\")\n",
    "\n",
    "# URL for getting all devices\n",
    "url = \"http://127.0.0.1:8000/device/gps_1\"\n",
    "\n",
    "# Send GET request to the /devices endpoint\n",
    "response = requests.get(url)\n",
    "\n",
    "# Print the status code and the response\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response JSON: {response.json()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Zookeeper:\n",
    "\n",
    "bash\n",
    "\n",
    "zookeeper-server-start.bat C:\\kafka\\kafka_2.12-3.8.0\\config\\zookeeper.properties\n",
    "\n",
    "\n",
    "Start the Kafka broker:\n",
    "\n",
    "bash\n",
    "\n",
    "kafka-server-start.bat C:\\kafka\\kafka_2.12-3.8.0\\config\\server.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to ggregation LIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success for player_heart_rate_1/run_001 with average: {'device_id': 'player_heart_rate_1', 'aggregation': 'average', 'average_heart_rate': 105.98305084745763}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Parameters: Define which sensors to use and the number of devices per sensor\n",
    "USE_SENSORS = {\"heart_rate\": True, \"temperature\": False}  # Set to True to enable a sensor type\n",
    "NUM_DEVICES = 1 # Number of devices to test for each sensor\n",
    "RUNS = [\"run_001\"]  # List of runs to test\n",
    "AGGREGATION_TYPE = \"average\"  # Aggregation type to use for the requests\n",
    "\n",
    "# Define the base FastAPI endpoint template\n",
    "url_template = \"http://localhost:8000/get-stats/{device_id}/{run_id}\"\n",
    "\n",
    "# Function to make the GET request and process the response\n",
    "def check_run(device_id, run_id, agg_type):\n",
    "    # Format the URL and add the aggregation type as a query parameter\n",
    "    url = url_template.format(device_id=device_id, run_id=run_id) + f\"?agg_type={agg_type}\"\n",
    "    try:\n",
    "        # Make the GET request to the FastAPI endpoint\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Print the response from the server\n",
    "            return f\"Success for {device_id}/{run_id} with {agg_type}: {response.json()}\"\n",
    "        else:\n",
    "            return f\"Failed for {device_id}/{run_id} with {agg_type}, status code: {response.status_code}, {response.text}\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred for {device_id}/{run_id} with {agg_type}: {e}\"\n",
    "\n",
    "# Main function to handle the request\n",
    "def main():\n",
    "    # Dynamically generate the list of devices based on enabled sensors\n",
    "    devices = {}\n",
    "    if USE_SENSORS[\"heart_rate\"]:\n",
    "        devices[\"heart_rate\"] = [f\"player_heart_rate_{i}\" for i in range(1, NUM_DEVICES + 1)]\n",
    "    if USE_SENSORS[\"temperature\"]:\n",
    "        devices[\"temperature\"] = [f\"player_temperature_{i}\" for i in range(1, NUM_DEVICES + 1)]\n",
    "\n",
    "    # Use ThreadPoolExecutor to run requests concurrently\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        # Submit tasks to the executor for each device and run combination\n",
    "        futures = {\n",
    "            executor.submit(check_run, device, run, AGGREGATION_TYPE): (device, run)\n",
    "            for sensor_type in devices\n",
    "            for device in devices[sensor_type]\n",
    "            for run in RUNS\n",
    "        }\n",
    "        \n",
    "        # Process the results as they complete\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                print(result)\n",
    "            except Exception as exc:\n",
    "                device, run = futures[future]\n",
    "                print(f\"An error occurred for {device}/{run} with {AGGREGATION_TYPE}: {exc}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to get instantaneous latest Kafka read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for player_heart_rate_1/run_001: {\n",
      "    \"device_id\": \"player_heart_rate_1\",\n",
      "    \"run_id\": \"run_001\",\n",
      "    \"messages\": [\n",
      "        {\n",
      "            \"heart_rate\": 88,\n",
      "            \"timestamp\": \"2024-12-06T17:50:29.327413\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Latest Message for player_heart_rate_1/run_001: {\n",
      "    \"heart_rate\": 88,\n",
      "    \"timestamp\": \"2024-12-06T17:50:29.327413\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Define the sensors and runs you want to check\n",
    "sensor = \"player_heart_rate_1\"\n",
    "runs = [\"run_001\"]\n",
    "limit = 1 # Fetch the latest messages with this limit\n",
    "base_url = \"http://127.0.0.1:8000/get-topic-messages/{device_id}/{run_id}?limit={limit}\"\n",
    "\n",
    "# Function to make the request and process the response\n",
    "def fetch_kafka_messages(device_id, run_id, limit):\n",
    "    url = base_url.format(device_id=device_id, run_id=run_id, limit=limit)\n",
    "    try:\n",
    "        # Make the request to the FastAPI endpoint\n",
    "        response = requests.get(url)\n",
    "        # Check the status of the response\n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            print(f\"Response for {device_id}/{run_id}:\", json.dumps(response_json, indent=4))\n",
    "            # Get the actual messages returned (if any)\n",
    "            messages = response_json.get('messages', [])\n",
    "            if messages:\n",
    "                print(f\"Latest Message for {device_id}/{run_id}:\", json.dumps(messages[0], indent=4))\n",
    "            else:\n",
    "                print(f\"No messages returned for {device_id}/{run_id}.\")\n",
    "        else:\n",
    "            print(f\"Error for {device_id}/{run_id}: {response.status_code}, {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for {device_id}/{run_id}: {e}\")\n",
    "\n",
    "# Main function to run the requests concurrently\n",
    "def main():\n",
    "    # Use ThreadPoolExecutor to run requests concurrently\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Submit tasks to the executor for each sensor and run combination\n",
    "        futures = [executor.submit(fetch_kafka_messages, sensor, run, limit) for run in runs]\n",
    "        \n",
    "        # Process the results as they complete\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # This will raise any exception from the fetch_kafka_messages function\n",
    "            except Exception as exc:\n",
    "                print(f\"An error occurred: {exc}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to start a stream and sibscribe to alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream started successfully for player_heart_rate_1/run_001\n",
      "Subscribed successfully to notifications for player_heart_rate_1/run_001\n",
      "Update for player_heart_rate_1/run_001: data: {'device_id': 'player_heart_rate_1_run_001', 'updates': [{'heart_rate': 175, 'timestamp': datetime.datetime(2024, 12, 6, 18, 40, 31, 610168), 'heart_rate_status': 'high'}]}\n",
      "Update for player_heart_rate_1/run_001: data: {'device_id': 'player_heart_rate_1_run_001', 'updates': [{'heart_rate': 184, 'timestamp': datetime.datetime(2024, 12, 6, 18, 41, 22, 284917), 'heart_rate_status': 'high'}]}\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 65\u001b[0m, in \u001b[0;36msubscribe_to_notifications\u001b[1;34m(device_id, run_id, table_preappend)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubscribed successfully to notifications for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[0;32m     66\u001b[0m     decoded_line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\aiohttp\\streams.py:35\u001b[0m, in \u001b[0;36mAsyncStreamIterator.__anext__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_func()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EofStream:\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\aiohttp\\streams.py:311\u001b[0m, in \u001b[0;36mStreamReader.readline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadline\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreaduntil()\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\aiohttp\\streams.py:343\u001b[0m, in \u001b[0;36mStreamReader.readuntil\u001b[1;34m(self, separator)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_enough:\n\u001b[1;32m--> 343\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreaduntil\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chunk\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\aiohttp\\streams.py:304\u001b[0m, in \u001b[0;36mStreamReader._wait\u001b[1;34m(self, func_name)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timer:\n\u001b[1;32m--> 304\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mCancelledError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 129\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mstop_tasks)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Run the main_streaming_test function\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main_streaming_test()\n",
      "Cell \u001b[1;32mIn[11], line 111\u001b[0m, in \u001b[0;36mmain_streaming_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_SENSORS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    107\u001b[0m     subscribe_tasks\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m    108\u001b[0m         subscribe_to_notifications(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayer_temperature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, run_id, table_preappend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUM_DEVICES \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    110\u001b[0m     )\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39msubscribe_tasks)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Step 4: Wait for 60 seconds, then stop all streams\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "from typing import Union\n",
    "\n",
    "# Parameters: Define which sensors to use and the number of devices per sensor\n",
    "USE_SENSORS = {\"heart_rate\": True, \"temperature\": False}  # Set to True to enable a sensor type\n",
    "NUM_DEVICES = 1  # Number of devices to test for each sensor\n",
    "\n",
    "# Define the base FastAPI endpoint templates\n",
    "start_stream_url_template = \"http://localhost:8000/start-stream/{device_id}/{run_id}\"\n",
    "get_notification_url_template = \"http://localhost:8000/get-notification/{device_id}/{run_id}\"\n",
    "\n",
    "# Example triggers for heart rate and temperature\n",
    "triggers = {\n",
    "    \"heart_rate\": [70, 140],  # Min and max threshold for heart rate\n",
    "    \"temperature\": [36.5, 38.0],  # Min and max threshold for temperature\n",
    "}\n",
    "\n",
    "# Asynchronous function to start the stream for a device and run\n",
    "async def start_stream(device_id, run_id, triggers, table_preappend=None):\n",
    "    url = start_stream_url_template.format(device_id=device_id, run_id=run_id)\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            # Make the POST request to the start-stream endpoint\n",
    "            payload = {\n",
    "                \"triggers\": triggers,\n",
    "                \"window_seconds\": 1,\n",
    "                \"table_preappend\": table_preappend or \"threshold\",\n",
    "                \"exclude_normal\": True\n",
    "            }\n",
    "            async with session.post(url, json=payload) as response:\n",
    "                if response.status == 200:\n",
    "                    print(f\"Stream started successfully for {device_id}/{run_id}\")\n",
    "                else:\n",
    "                    text = await response.text()\n",
    "                    print(f\"Failed to start stream for {device_id}/{run_id} with status code: {response.status}, {text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while starting the stream for {device_id}/{run_id}: {e}\")\n",
    "\n",
    "# Asynchronous function to subscribe to the notification endpoint for a device and run\n",
    "async def subscribe_to_notifications(device_id, run_id, table_preappend: Union[str, None] = None):\n",
    "    url = get_notification_url_template.format(device_id=device_id, run_id=run_id)\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            params = {\"table_preappend\": table_preappend} if table_preappend else {}\n",
    "            async with session.get(url, params=params) as response:\n",
    "                if response.status == 200:\n",
    "                    print(f\"Subscribed successfully to notifications for {device_id}/{run_id}\")\n",
    "                    async for line in response.content:\n",
    "                        decoded_line = line.decode('utf-8').strip()\n",
    "                        \n",
    "                        # Only print meaningful updates\n",
    "                        if decoded_line.startswith(\"data:\"):\n",
    "                            print(f\"Update for {device_id}/{run_id}: {decoded_line}\")\n",
    "                else:\n",
    "                    text = await response.text()\n",
    "                    print(f\"Failed to subscribe to notifications for {device_id}/{run_id} with status code: {response.status}, {text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while subscribing to notifications for {device_id}/{run_id}: {e}\")\n",
    "\n",
    "\n",
    "# Main asynchronous function to handle the test request for streaming notifications\n",
    "async def main_streaming_test():\n",
    "    # Define the run_id to be used for all tests\n",
    "    run_id = \"run_001\"\n",
    "    \n",
    "    # Step 1: Start the streams for enabled sensor types\n",
    "    start_tasks = []\n",
    "    if USE_SENSORS[\"heart_rate\"]:\n",
    "        start_tasks.extend(\n",
    "            start_stream(f\"player_heart_rate_{i}\", run_id, {\"heart_rate\": triggers[\"heart_rate\"]}, table_preappend=\"threshold\")\n",
    "            for i in range(1, NUM_DEVICES + 1)\n",
    "        )\n",
    "    if USE_SENSORS[\"temperature\"]:\n",
    "        start_tasks.extend(\n",
    "            start_stream(f\"player_temperature_{i}\", run_id, {\"temperature\": triggers[\"temperature\"]}, table_preappend=\"threshold\")\n",
    "            for i in range(1, NUM_DEVICES + 1)\n",
    "        )\n",
    "    await asyncio.gather(*start_tasks)\n",
    "\n",
    "    # Step 2: Wait for 5 seconds before subscribing to notifications\n",
    "    await asyncio.sleep(5)\n",
    "\n",
    "    # Step 3: Subscribe to notifications for enabled sensor types\n",
    "    subscribe_tasks = []\n",
    "    if USE_SENSORS[\"heart_rate\"]:\n",
    "        subscribe_tasks.extend(\n",
    "            subscribe_to_notifications(f\"player_heart_rate_{i}\", run_id, table_preappend=\"threshold\")\n",
    "            for i in range(1, NUM_DEVICES + 1)\n",
    "        )\n",
    "    if USE_SENSORS[\"temperature\"]:\n",
    "        subscribe_tasks.extend(\n",
    "            subscribe_to_notifications(f\"player_temperature_{i}\", run_id, table_preappend=\"threshold\")\n",
    "            for i in range(1, NUM_DEVICES + 1)\n",
    "        )\n",
    "    await asyncio.gather(*subscribe_tasks)\n",
    "\n",
    "# Run the main_streaming_test function\n",
    "await main_streaming_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to get current speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream stopped successfully for player_heart_rate_1/run_001\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def stop_stream(device_id, run_id):\n",
    "    url = f\"http://localhost:8000/stop-stream/{device_id}/{run_id}\"\n",
    "    try:\n",
    "        # Make the POST request to the stop-stream endpoint\n",
    "        response = requests.post(url)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"Stream stopped successfully for {device_id}/{run_id}\")\n",
    "        else:\n",
    "            text = response.text\n",
    "            print(f\"Failed to stop stream for {device_id}/{run_id} with status code: {response.status_code}, {text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while stopping the stream for {device_id}/{run_id}: {e}\")\n",
    "\n",
    "stop_stream(\"player_heart_rate_1\", \"run_001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success for gps_1/run_001: {'device_id': 'gps_1', 'run_id': 'run_001', 'acceleration': 2.4514464937988407}\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "# Define the FastAPI endpoint template for the get-speed endpoint\n",
    "get_speed_url_template = \"http://localhost:8000/get-speed/{device_id}/{run_id}?type={type}\"\n",
    "\n",
    "\n",
    "# Asynchronous function to test the get-speed endpoint\n",
    "async def test_get_speed(device_id, run_id, metric_type):\n",
    "    url = get_speed_url_template.format(device_id=device_id, run_id=run_id, type=metric_type)\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            # Make the GET request to the get-speed endpoint\n",
    "            async with session.get(url) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    # Validate that the response contains the expected fields\n",
    "                    if \"device_id\" in data and \"run_id\" in data and metric_type in data:\n",
    "                        print(f\"Success for {device_id}/{run_id}: {data}\")\n",
    "                    else:\n",
    "                        print(f\"Unexpected response structure for {device_id}/{run_id}: {data}\")\n",
    "                else:\n",
    "                    text = await response.text()\n",
    "                    print(f\"Failed for {device_id}/{run_id} with status code: {response.status}, {text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for {device_id}/{run_id}: {e}\")\n",
    "\n",
    "# Main asynchronous function to handle the test requests for multiple device and run combinations\n",
    "async def main_get_speed_test():\n",
    "    # Define a single run_id and generate test cases for 10 devices\n",
    "    run_id = \"run_001\"\n",
    "    metric_type = \"acceleration\"  # Or \"acceleration\"\n",
    "    test_cases = [{\"device_id\": f\"gps_{i}\", \"run_id\": run_id} for i in range(1, 2)]\n",
    "\n",
    "    # Create tasks to test each device_id and run_id pair concurrently\n",
    "    test_tasks = [test_get_speed(case[\"device_id\"], case[\"run_id\"], metric_type) for case in test_cases]\n",
    "    \n",
    "    # Run all tasks concurrently\n",
    "    await asyncio.gather(*test_tasks)\n",
    "\n",
    "# Run the main_get_speed_test function\n",
    "await main_get_speed_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to Clean up Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing /list-topics endpoint:\n",
      "List Topics: Success\n",
      "Response: {'message': 'Topics retrieved successfully', 'topics': []}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "BASE_URL = \"http://127.0.0.1:8000\"\n",
    "\n",
    "def test_list_topics():\n",
    "    \"\"\"\n",
    "    Test the /list-topics endpoint to ensure it returns a list of Kafka topics.\n",
    "    \"\"\"\n",
    "    response = requests.get(f\"{BASE_URL}/list-topics\")\n",
    "    if response.status_code == 200:\n",
    "        print(\"List Topics: Success\")\n",
    "        print(\"Response:\", response.json())\n",
    "    else:\n",
    "        print(\"List Topics: Failed\")\n",
    "        print(\"Error:\", response.json())\n",
    "\n",
    "def test_delete_topic_by_device_name(device_id, run_id):\n",
    "    \"\"\"\n",
    "    Test the /delete-topic/{device_id}/{run_id} endpoint to delete a specific Kafka topic.\n",
    "    \"\"\"\n",
    "    response = requests.delete(f\"{BASE_URL}/delete-topic/{device_id}/{run_id}\")\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Delete Topic {device_id}.{run_id}: Success\")\n",
    "        print(\"Response:\", response.json())\n",
    "    else:\n",
    "        print(f\"Delete Topic {device_id}.{run_id}: Failed\")\n",
    "        print(\"Error:\", response.json())\n",
    "\n",
    "def test_delete_all_topics():\n",
    "    \"\"\"\n",
    "    Test the /delete-all-topics endpoint to delete all Kafka topics.\n",
    "    \"\"\"\n",
    "    response = requests.delete(f\"{BASE_URL}/delete-all-topics\")\n",
    "    if response.status_code == 200:\n",
    "        print(\"Delete All Topics: Success\")\n",
    "        print(\"Response:\", response.json())\n",
    "    else:\n",
    "        print(\"Delete All Topics: Failed\")\n",
    "        print(\"Error:\", response.json())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run tests\n",
    "    print(\"Testing /list-topics endpoint:\")\n",
    "    test_list_topics()\n",
    "    \n",
    "    # print(\"\\nTesting /delete-topic/{device_id}/{run_id} endpoint:\")\n",
    "    # # Substitute 'test_device' and 'test_run' with actual values\n",
    "    # test_delete_topic_by_device_name(\"test_device\", \"test_run\")\n",
    "    \n",
    "    # print(\"\\nTesting /delete-all-topics endpoint:\")\n",
    "    # test_delete_all_topics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to delete all historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing /delete-all endpoint:\n",
      "Delete All Historical Data: Success\n",
      "Response: {'message': 'All historical data files and folders deleted successfully', 'deleted_items_count': 2}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "BASE_URL = \"http://127.0.0.1:8000\"\n",
    "\n",
    "def test_delete_all_historical_data():\n",
    "    \"\"\"\n",
    "    Test the /delete-all endpoint to ensure it deletes all historical data files.\n",
    "    \"\"\"\n",
    "    response = requests.delete(f\"{BASE_URL}/delete-all\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"Delete All Historical Data: Success\")\n",
    "        print(\"Response:\", response.json())\n",
    "    else:\n",
    "        print(\"Delete All Historical Data: Failed\")\n",
    "        print(\"Error:\", response.json())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Testing /delete-all endpoint:\")\n",
    "    test_delete_all_historical_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team Statistics Data: {'Total Distance Per Game': {'run_001': 47.0, 'run_002': 44.37, 'run_003': 37.76, 'run_004': 46.11, 'run_005': 46.29, 'run_006': 41.02, 'run_007': 34.35, 'run_008': 41.91, 'run_009': 37.81, 'run_010': 47.76, 'run_011': 40.45, 'run_012': 39.09, 'run_013': 36.76, 'run_014': 52.88, 'run_015': 45.11}, 'Average Speed Per Game': 9.8, 'Max Speed Per Game': 13.88}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL of the endpoint\n",
    "url = \"http://localhost:8000/team-statistics\"\n",
    "\n",
    "# Send the GET request\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Print the response data (the statistics)\n",
    "        print(\"Team Statistics Data:\", response.json())\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "        print(\"Error:\", response.text)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    # Catch any exception raised during the request (e.g., connection errors)\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Stop any existing SparkSession\n",
    "spark = SparkSession.getActiveSession()\n",
    "if spark is not None:\n",
    "    spark.stop()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestApp\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/tmp/spark-warehouse\") \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"in-memory\") \\\n",
    "    .config(\"spark.local.dir\", \"/tmp/spark-temp\") \\\n",
    "    .config(\"spark.driver.host\", \"0.0.0.0\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\",\"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\",\"10g\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master: spark://spark-master:7077\n"
     ]
    }
   ],
   "source": [
    "print(\"Master:\", spark.sparkContext.master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://0.0.0.0:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TestApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://spark-master:7077 appName=TestApp>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o82.sessionState.\n: java.lang.IllegalStateException: LiveListenerBus is stopped.\r\n\tat org.apache.spark.scheduler.LiveListenerBus.addToQueue(LiveListenerBus.scala:92)\r\n\tat org.apache.spark.scheduler.LiveListenerBus.addToStatusQueue(LiveListenerBus.scala:75)\r\n\tat org.apache.spark.sql.internal.SharedState.<init>(SharedState.scala:115)\r\n\tat org.apache.spark.sql.SparkSession.$anonfun$sharedState$1(SparkSession.scala:143)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.SparkSession.sharedState$lzycompute(SparkSession.scala:143)\r\n\tat org.apache.spark.sql.SparkSession.sharedState(SparkSession.scala:142)\r\n\tat org.apache.spark.sql.SparkSession.$anonfun$sessionState$2(SparkSession.scala:162)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:160)\r\n\tat org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:157)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJohn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m30\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJane\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m25\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMike\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m35\u001b[39m)]\n\u001b[0;32m      2\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\pyspark\\sql\\session.py:1443\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SparkSession, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreateDataFrame(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m   1441\u001b[0m         data, schema, samplingRatio, verifySchema\n\u001b[0;32m   1442\u001b[0m     )\n\u001b[1;32m-> 1443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\pyspark\\sql\\session.py:1485\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m   1483\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromRDD(data\u001b[38;5;241m.\u001b[39mmap(prepare), schema, samplingRatio)\n\u001b[0;32m   1484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1485\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_createFromLocal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mSerDeUtil\u001b[38;5;241m.\u001b[39mtoJavaArray(rdd\u001b[38;5;241m.\u001b[39m_to_java_object_rdd())\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\pyspark\\sql\\session.py:1093\u001b[0m, in \u001b[0;36mSparkSession._createFromLocal\u001b[1;34m(self, data, schema)\u001b[0m\n\u001b[0;32m   1090\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data)\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m-> 1093\u001b[0m     struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inferSchemaFromList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1094\u001b[0m     converter \u001b[38;5;241m=\u001b[39m _create_converter(struct)\n\u001b[0;32m   1095\u001b[0m     tupled_data: Iterable[Tuple] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(converter, data)\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\pyspark\\sql\\session.py:952\u001b[0m, in \u001b[0;36mSparkSession._inferSchemaFromList\u001b[1;34m(self, data, names)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkValueError(\n\u001b[0;32m    949\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANNOT_INFER_EMPTY_SCHEMA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    950\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    951\u001b[0m     )\n\u001b[1;32m--> 952\u001b[0m infer_dict_as_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jconf\u001b[49m\u001b[38;5;241m.\u001b[39minferDictAsStruct()\n\u001b[0;32m    953\u001b[0m infer_array_from_first_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jconf\u001b[38;5;241m.\u001b[39mlegacyInferArrayTypeFromFirstElement()\n\u001b[0;32m    954\u001b[0m prefer_timestamp_ntz \u001b[38;5;241m=\u001b[39m is_timestamp_ntz_preferred()\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\pyspark\\sql\\session.py:624\u001b[0m, in \u001b[0;36mSparkSession._jconf\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_jconf\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJavaObject\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    623\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Accessor for the JVM SQL-specific configurations\"\"\"\u001b[39;00m\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msessionState\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconf()\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o82.sessionState.\n: java.lang.IllegalStateException: LiveListenerBus is stopped.\r\n\tat org.apache.spark.scheduler.LiveListenerBus.addToQueue(LiveListenerBus.scala:92)\r\n\tat org.apache.spark.scheduler.LiveListenerBus.addToStatusQueue(LiveListenerBus.scala:75)\r\n\tat org.apache.spark.sql.internal.SharedState.<init>(SharedState.scala:115)\r\n\tat org.apache.spark.sql.SparkSession.$anonfun$sharedState$1(SparkSession.scala:143)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.SparkSession.sharedState$lzycompute(SparkSession.scala:143)\r\n\tat org.apache.spark.sql.SparkSession.sharedState(SparkSession.scala:142)\r\n\tat org.apache.spark.sql.SparkSession.$anonfun$sessionState$2(SparkSession.scala:162)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:160)\r\n\tat org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:157)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n"
     ]
    }
   ],
   "source": [
    "data = [(\"John\", 30), (\"Jane\", 25), (\"Mike\", 35)]\n",
    "columns = [\"Name\", \"Age\"]\n",
    "df = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o55.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (DESKTOP-5UBV34D executor driver): java.net.SocketException: Connection reset\r\n\tat java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)\r\n\tat java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)\r\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)\r\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)\r\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:774)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4333)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3316)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3316)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3539)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:315)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\nCaused by: java.net.SocketException: Connection reset\r\n\tat java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)\r\n\tat java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)\r\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)\r\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)\r\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:774)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\pyspark\\sql\\dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    960\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    961\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    962\u001b[0m     )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\emili\\anaconda3\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o55.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (DESKTOP-5UBV34D executor driver): java.net.SocketException: Connection reset\r\n\tat java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)\r\n\tat java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)\r\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)\r\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)\r\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:774)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4333)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3316)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3316)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3539)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:315)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\nCaused by: java.net.SocketException: Connection reset\r\n\tat java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)\r\n\tat java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)\r\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)\r\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)\r\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:774)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
